======================== FILE ./CMakeLists.txt
FILE: ./CMakeLists.txt
# ------------------------------------------------------------------------ #
# modelE cmake setup
# ------------------------------------------------------------------------ #
#
# Usage: cmake -DRUN=<modelE run> /path/to/my/repo [optional arguments]  
#
# Required argument:
#
#	-DRUN=<modelE run>
#       /path/to/my/repo
#
# Optional arguments (when possible a default is assigned):
#
# 	-DCMAKE_CXX_COMPILER=<c++ compiler> (default is system's compiler)
#	-DCMAKE_C_COMPILER=<c compiler> (default is system's)
#	-DCMAKE_Fortran_COMPILER=<fortran compiler> (default is system's)
#	-DCMAKE_BUILD_TYPE=Debug (or Release)
#	-DCOMPILE_WITH_TRAPS=NO (or YES)
#	-DCOMPILE_IC=NO (or YES to compile init_cond directory)
#	-DCOMPILE_DIAGS=NO (or YES to compile mk_diags directory)
#	-DCOMPILE_AUX=NO (or YES to compile aux directory)
#	-DMPI=YES (or NO)
#	-DRUNSRC=<modelE template> (default is none)
#       -DMODEL_DECKS_DIR=/path/to/my/decks (default is none)
#
# NOTE: RUN must be specified with full path.
#
# Examples:
#
#  Run cmake in a temporary directory: 
#
#    1) cmake -DRUN=/path/my/decks/ef40cc.R /path/to/my/repo
#
#    Uses specified e4f40cc.R rundeck using source code in /path/to/my/repo
#
#  It is common to create a "build" subdirectory in the source directory ,
#  cd to it and run cmake as follows:
#
#    2) cmake -DRUN=e4f0.R -DRUNSRC=E4F40.R ..
#
#    Creates e4f0.R rundeck in current directory using the specified template.
#
#  If you want to store or share your rundeck, specify where it should be 
#  created using the MODEL_DECKS_DIR option:
#
#    3) cmake -DMODEL_DECKS_DIR=/path/to/my/decks -DRUN=e4f0.R -DRUNSRC=E4F40.R ..
#
#
# ------------------------------------------------------------------------

cmake_minimum_required (VERSION 3.2)
project (ModelE)
enable_language(Fortran)

# Where to look first for project cmake modules,
# before ${CMAKE_ROOT}/Modules/ is checked
set(CMAKE_MODULE_PATH
   ${CMAKE_SOURCE_DIR}/cmake
)

include(PreventInSourceBuild)
include(setup_rpath)

# Process command line options
include(ProcessCommandLineOptions)

#
# Set some CMake defaults
include(DefineCMakeDefaults)

# Set platform settings and check for required compiler versions
include(DefinePlatformDefaults)

# Set compiler flags
#include ("cmake/PISM_CMake_macros.cmake")
#include ("cmake/GLINT2_CMake_macros.cmake")
include (ModelE_CMake_macros)
modele_set_flags()

# Find required packages
#pism_find_prerequisites()
#glint2_find_prerequisites()
modele_find_prerequisites()

# Specify all the subdirectories to build
if (COMPILE_MODEL MATCHES YES)
    add_subdirectory(model)
endif()

# Not yet on the master (dev) branch...
# add_subdirectory (pyext)

# Do we want to build aux?
if(COMPILE_AUX MATCHES YES)
   add_subdirectory(aux)
endif()

# Do we want to build mk_diags?
if(COMPILE_DIAGS MATCHES YES)
   add_subdirectory(model/mk_diags)
endif()

# Do we want to build init_cond?
if(COMPILE_IC MATCHES YES)
   add_subdirectory(init_cond)
endif()

# If PFUNIT environment variable is set then WITH_PFUNIT is set to YES
if(WITH_PFUNIT MATCHES YES)
   add_subdirectory(tests)
endif()

message(STATUS "********************************************")
message(STATUS "********** PROJECT: ${PROJECT_NAME} **********")
message(STATUS "Architecture: ${ARCHITECTURE}")
message(STATUS "System:       ${CMAKE_SYSTEM_NAME}")
message(STATUS "MODELERC:     $ENV{MODELERC}")
message(STATUS "COMPILER:     ${CMAKE_Fortran_COMPILER_ID} ${CMAKE_CXX_COMPILER_VERSION}")
message(STATUS "RUNSRC:       ${RUNSRC}")
message(STATUS "RUN:          ${RUN}")
message(STATUS "MPI:          ${MPI}")
message(STATUS "WITH_PFUNIT:  ${WITH_PFUNIT}")
if (COMPILE_WITH_DEBUG MATCHES YES)
message(STATUS "COMPILE_WITH_DEBUG: ${COMPILE_WITH_DEBUG}")
endif()
if (COMPILE_WITH_TRAPS MATCHES YES)
message(STATUS "COMPILE_WITH_TRAPS: ${COMPILE_WITH_TRAPS}")
endif()
message(STATUS "********************************************")

__EOF__
======================== FILE ./aux/CMakeLists.txt
FILE: ./aux/CMakeLists.txt
# aux

aux_set_dependencies()

include_directories(
   ${PROJECT_BINARY_DIR}/model
)

# Targets

add_executable(RMS RMS.f)
add_executable(mkdeep.exe mkdeep.f)
add_executable(RDijk2llEM RDijk2llEM.f)
add_executable(inputll2cs inputLL2CS.f regrid.f ncio.f)
target_link_libraries(inputll2cs  ${AUX_EXTERNAL_LIBS})
add_executable(ll2cs ll2cs.f regrid.f ncio.f)
target_link_libraries(ll2cs  ${AUX_EXTERNAL_LIBS})
add_executable(ncll2cs ncll2cs.f regrid.f ncio.f)
target_link_libraries(ncll2cs  ${AUX_EXTERNAL_LIBS})

list(APPEND apps RMS)
list(APPEND apps mkdeep.exe) 

foreach(app ${apps})
   #message(STATUS " ---> Add executable ${app}")
   target_link_libraries(${app} ${AUX_EXTERNAL_LIBS})
endforeach()


__EOF__
======================== FILE ./cmake/DefineCMakeDefaults.cmake
FILE: ./cmake/DefineCMakeDefaults.cmake
# Always include srcdir and builddir in include path
# This saves typing ${CMAKE_CURRENT_SOURCE_DIR} ${CMAKE_CURRENT_BINARY} in
# about every subdir
# since cmake 2.4.0
set(CMAKE_INCLUDE_CURRENT_DIR ON)

# Put the include dirs which are in the source or build tree
# before all other include dirs, so the headers in the sources
# are prefered over the already installed ones
# since cmake 2.4.1
set(CMAKE_INCLUDE_DIRECTORIES_PROJECT_BEFORE ON)

# Use colored output
# since cmake 2.4.0
set(CMAKE_COLOR_MAKEFILE ON)

# Set the default build type to release with debug info
if (NOT CMAKE_BUILD_TYPE)
  set(CMAKE_BUILD_TYPE RelWithDebInfo
    CACHE STRING
      "Choose the type of build, options are: None Debug Release RelWithDebInfo MinSizeRel."
  )
endif (NOT CMAKE_BUILD_TYPE)
__EOF__
======================== FILE ./cmake/DefinePlatformDefaults.cmake
FILE: ./cmake/DefinePlatformDefaults.cmake
# Set system vars

if (CMAKE_SYSTEM_NAME MATCHES "Linux")
    set(LINUX TRUE)
endif(CMAKE_SYSTEM_NAME MATCHES "Linux")

if (CMAKE_SYSTEM_NAME MATCHES "Darwin")
	set (OSX TRUE)
endif (CMAKE_SYSTEM_NAME MATCHES "Darwin")

if (CMAKE_SYSTEM_NAME MATCHES "FreeBSD")
    set(FREEBSD TRUE)
    set(BSD TRUE)
endif (CMAKE_SYSTEM_NAME MATCHES "FreeBSD")

if (CMAKE_SYSTEM_NAME MATCHES "OpenBSD")
    set(OPENBSD TRUE)
    set(BSD TRUE)
endif (CMAKE_SYSTEM_NAME MATCHES "OpenBSD")

if (CMAKE_SYSTEM_NAME MATCHES "NetBSD")
    set(NETBSD TRUE)
    set(BSD TRUE)
endif (CMAKE_SYSTEM_NAME MATCHES "NetBSD")

if (CMAKE_SYSTEM_NAME MATCHES "(Solaris|SunOS)")
    set(SOLARIS TRUE)
endif (CMAKE_SYSTEM_NAME MATCHES "(Solaris|SunOS)")

if (CMAKE_SYSTEM_NAME MATCHES "OS2")
    set(OS2 TRUE)
endif (CMAKE_SYSTEM_NAME MATCHES "OS2")

if (${CMAKE_Fortran_COMPILER_ID} STREQUAL "Intel")
    # require at least ifort 14.0
    if (CMAKE_CXX_COMPILER_VERSION VERSION_LESS 14.0)
        message("\n ---> IFORT COMPILER VERSION: " ${CMAKE_CXX_COMPILER_VERSION})
        message(FATAL_ERROR "---> IFORT version must be at least 14.0!")
    endif()
elseif(${CMAKE_Fortran_COMPILER_ID} STREQUAL "GNU")
    # require at least gcc 4.9.1
    if (CMAKE_CXX_COMPILER_VERSION VERSION_LESS 4.9.1)
        message("\n  ---> GNU COMPILER VERSION: " ${CMAKE_CXX_COMPILER_VERSION})
        message(FATAL_ERROR "---> GNU version must be at least 4.9.1!")
    endif()
else()
    message( FATAL_ERROR "Unrecognized compiler. Please use ifort or gfortran" )
endif()

__EOF__
======================== FILE ./cmake/FindBlitz++.cmake
FILE: ./cmake/FindBlitz++.cmake
# - Try to find BLITZ++
# Once done, this will define
#
# BLITZ++_FOUND - system has BLITZ++
# BLITZ++_INCLUDE_DIR - the BLITZ++ include directory
# BLITZ++_LIBRARY - lib to link to use BLITZ++

include(LibFindMacros)

# Use pkg-config to get hints about paths
#libfind_pkg_check_modules(BLITZ++_PKGCONF blitz)

# Include dir
find_path(BLITZ++_INCLUDE_DIR
  NAMES blitz/blitz.h
  HINTS ${BLITZ++_PKGCONF_INCLUDE_DIRS}
)

# Finally the library itself
find_library(BLITZ++_LIBRARY
  NAMES blitz
  HINTS ${BLITZ++_PKGCONF_LIBRARY_DIRS}
)

# Set the include dir variables and the libraries and let libfind_process do the rest.
# NOTE: Singular variables for this library, plural for libraries this this lib depends on.
set(BLITZ++_PROCESS_INCLUDE BLITZ++_INCLUDE_DIR )
set(BLITZ++_PROCESS_LIB BLITZ++_LIBRARY)
libfind_process(BLITZ++)
__EOF__
======================== FILE ./cmake/FindCGAL.cmake
FILE: ./cmake/FindCGAL.cmake
# - Try to find Cgal
# Input Variables
#    CGAL_ROOT
# Once done this will define
#  CGAL_FOUND - System has Cgal
#  CGAL_INCLUDE_DIRS - The Cgal include directories
#  CGAL_LIBRARIES - The libraries needed to use Cgal
##  CGAL_DEFINITIONS - Compiler switches required for using Cgal

find_path(CGAL_ROOT  modules/${CGAL_ARCH}/double/galahad_qpt_double.mod
          HINTS ${CGAL_ROOT})

message(CGAL_ROOT ${CGAL_ROOT})

find_path(CGAL_INCLUDE_DIR CGAL/basic.h
	HINTS ${CGAL_ROOT})

set(CGAL_INCLUDE_DIRS ${CGAL_INCLUDE_DIR})

find_library(CGAL_LIBRARY CGAL
	HINTS ${CGAL_ROOT}/lib)

set(CGAL_LIBRARIES ${CGAL_LIBRARY})

include(FindPackageHandleStandardArgs)
# handle the QUIETLY and REQUIRED arguments and set CGAL_FOUND to TRUE
# if all listed variables are TRUE
find_package_handle_standard_args(Cgal  DEFAULT_MSG
                                  CGAL_LIBRARIES CGAL_INCLUDE_DIRS)

mark_as_advanced(CGAL_INCLUDE_DIRS CGAL_LIBRARIES )




#
## Find the CGAL includes and client library
## This module defines
##  CGAL_INCLUDE_DIR, where to find CGAL.h
##  CGAL_LIBRARIES, the libraries needed to use CGAL.
##  CGAL_FOUND, If false, do not try to use CGAL.
#
#if(CGAL_INCLUDE_DIR AND CGAL_LIBRARIES)
#   set(CGAL_FOUND TRUE)
#
#else(CGAL_INCLUDE_DIR AND CGAL_LIBRARIES)
#
# FIND_PATH(CGAL_INCLUDE_DIR CGAL/basic.h
#      /usr/include
#      /usr/local/include
#      $ENV{ProgramFiles}/CGAL/*/include
#      $ENV{SystemDrive}/CGAL/*/include
#      )
#
#  find_library(CGAL_LIBRARIES NAMES CGAL libCGAL
#     PATHS
#     /usr/lib
#     /usr/local/lib
#     /usr/lib/CGAL
#     /usr/lib64
#     /usr/local/lib64
#     /usr/lib64/CGAL
#     $ENV{ProgramFiles}/CGAL/*/lib
#     $ENV{SystemDrive}/CGAL/*/lib
#     )
#     
#  if(CGAL_INCLUDE_DIR AND CGAL_LIBRARIES)
#    set(CGAL_FOUND TRUE)
#    message(STATUS "Found CGAL: ${CGAL_INCLUDE_DIR}, ${CGAL_LIBRARIES}")
#    INCLUDE_DIRECTORIES(${CGAL_INCLUDE_DIR} $ENV{CGAL_CFG})
#  else(CGAL_INCLUDE_DIR AND CGAL_LIBRARIES)
#    set(CGAL_FOUND FALSE)
#    message(STATUS "CGAL not found.")
#  endif(CGAL_INCLUDE_DIR AND CGAL_LIBRARIES)
#
#  mark_as_advanced(CGAL_INCLUDE_DIR CGAL_LIBRARIES)
#
#endif(CGAL_INCLUDE_DIR AND CGAL_LIBRARIES)
#
__EOF__
======================== FILE ./cmake/FindFException.cmake
FILE: ./cmake/FindFException.cmake
# Input Variables
#    FEXCEPTION_ROOT
# Produces:
#    FEXCEPTION_LIBRARY
#    FEXCEPTION_INCLUDE_DIR


FIND_PATH(FEXCEPTION_INCLUDE_DIR fexception_c.hpp
	HINTS ${FEXCEPTION_ROOT}/include)

FIND_LIBRARY(FEXCEPTION_LIBRARY NAMES fexception
	HINTS ${FEXCEPTION_ROOT}/lib)

IF (FEXCEPTION_INCLUDE_DIR AND FEXCEPTION_LIBRARY)
   SET(FEXCEPTION_FOUND TRUE)
ENDIF (FEXCEPTION_INCLUDE_DIR AND FEXCEPTION_LIBRARY)

IF (FEXCEPTION_FOUND)
   IF (NOT FEXCEPTION_FIND_QUIETLY)
      MESSAGE(STATUS "Found FEXCEPTION_LIBRARY: ${FEXCEPTION_LIBRARY}")
   ENDIF (NOT FEXCEPTION_FIND_QUIETLY)
ELSE (FEXCEPTION_FOUND)
   IF (FEXCEPTION_FIND_REQUIRED)
      MESSAGE(FATAL_ERROR "Could not find FEXCEPTION")
   ENDIF (FEXCEPTION_FIND_REQUIRED)
ENDIF (FEXCEPTION_FOUND)
__EOF__
======================== FILE ./cmake/FindFFTW.cmake
FILE: ./cmake/FindFFTW.cmake
# - Find FFTW
# Find the native FFTW includes and library
#
#  FFTW_INCLUDES    - where to find fftw3.h
#  FFTW_LIBRARIES   - List of libraries when using FFTW.
#  FFTW_FOUND       - True if FFTW found.

if (FFTW_INCLUDES)
  # Already in cache, be silent
  set (FFTW_FIND_QUIETLY TRUE)
endif (FFTW_INCLUDES)

find_path (FFTW_INCLUDES fftw3.h
  HINTS "${FFTW_ROOT}/include" "$ENV{FFTW_ROOT}/include")

string(REGEX REPLACE "/include/?$" "/lib"
  FFTW_LIB_HINT ${FFTW_INCLUDES})

find_library (FFTW_LIBRARIES
  NAMES fftw3
  HINTS ${FFTW_LIB_HINT})

if ((NOT FFTW_LIBRARIES) OR (NOT FFTW_INCLUDES))
  message(STATUS "Trying to find FFTW3 using LD_LIBRARY_PATH (we're desperate)...")

  file(TO_CMAKE_PATH "$ENV{LD_LIBRARY_PATH}" LD_LIBRARY_PATH)

  find_library(FFTW_LIBRARIES
    NAMES fftw3
    HINTS ${LD_LIBRARY_PATH})

  if (FFTW_LIBRARIES)
    get_filename_component(FFTW_LIB_DIR ${FFTW_LIBRARIES} PATH)
    string(REGEX REPLACE "/lib/?$" "/include"
      FFTW_H_HINT ${FFTW_LIB_DIR})

    find_path (FFTW_INCLUDES fftw3.h
      HINTS ${FFTW_H_HINT}
      DOC "Path to fftw3.h")
  endif()
endif()

# handle the QUIETLY and REQUIRED arguments and set FFTW_FOUND to TRUE if
# all listed variables are TRUE
include (FindPackageHandleStandardArgs)
find_package_handle_standard_args (FFTW DEFAULT_MSG FFTW_LIBRARIES FFTW_INCLUDES)

mark_as_advanced (FFTW_LIBRARIES FFTW_INCLUDES)
__EOF__
======================== FILE ./cmake/FindGALAHAD.cmake
FILE: ./cmake/FindGALAHAD.cmake
# - Try to find Galahad
# Input Variables
#    GALAHAD_ROOT
#    GALAHAD_ARCH
# Once done this will define
#  GALAHAD_FOUND - System has Galahad
#  GALAHAD_INCLUDE_DIRS - The Galahad include directories
#  GALAHAD_LIBRARIES - The libraries needed to use Galahad
##  GALAHAD_DEFINITIONS - Compiler switches required for using Galahad

find_path(GALAHAD_ROOT  modules/${GALAHAD_ARCH}/double/galahad_qpt_double.mod
          HINTS ${GALAHAD_ROOT})

message(GALAHAD_ROOT ${GALAHAD_ROOT})

set(GALAHAD_INCLUDE_DIRS ${GALAHAD_ROOT}/modules/${GALAHAD_ARCH}/double)

set(GALAHAD_LIB ${GALAHAD_ROOT}/objects/${GALAHAD_ARCH}/double)

#     -DUSE_GALAHAD @PETSC_CFLAGS@)

set(GALAHAD_COMPONENTS galahad galahad_hsl galahad_pardiso galahad_wsmp galahad_metis galahad_lapack galahad_blas)
set(GALAHAD_LIBRARIES gomp)		# Part of GCC
foreach(COMPONENT ${GALAHAD_COMPONENTS})
    string(TOUPPER ${COMPONENT} UPPERCOMPONENT)
	find_library(${UPPERCOMPONENT}_LIBRARY ${COMPONENT}
		HINTS ${GALAHAD_LIB})
	set(GALAHAD_LIBRARIES ${GALAHAD_LIBRARIES} ${${UPPERCOMPONENT}_LIBRARY})
endforeach()

include(FindPackageHandleStandardArgs)
# handle the QUIETLY and REQUIRED arguments and set GALAHAD_FOUND to TRUE
# if all listed variables are TRUE
find_package_handle_standard_args(Galahad  DEFAULT_MSG
                                  GALAHAD_LIBRARIES GALAHAD_INCLUDE_DIRS)

mark_as_advanced(GALAHAD_INCLUDE_DIRS GALAHAD_LIBRARIES )
__EOF__
======================== FILE ./cmake/FindGMP.cmake
FILE: ./cmake/FindGMP.cmake
# Copyright (c) 2008-2010 Kent State University
# Copyright (c) 2011-2012 Texas A&M University
#
# This file is distributed under the MIT License. See the accompanying file
# LICENSE.txt or http://www.opensource.org/licenses/mit-license.php for terms
# and conditions.

# FIXME: How do I find the version of GMP that I want to use?
# What versions are available?

# NOTE: GMP prefix is understood to be the path to the root of the GMP
# installation library.
set(GMP_PREFIX "" CACHE PATH "The path to the prefix of a GMP installation")


find_path(GMP_INCLUDE_DIR gmp.h
PATHS ${GMP_PREFIX}/include /usr/include /usr/local/include)

find_library(GMP_LIBRARY NAMES gmp
PATHS ${GMP_PREFIX}/lib /usr/lib /usr/local/lib)


if(GMP_INCLUDE_DIR AND GMP_LIBRARY)
get_filename_component(GMP_LIBRARY_DIR ${GMP_LIBRARY} PATH)
set(GMP_FOUND TRUE)
endif()

if(GMP_FOUND)
if(NOT GMP_FIND_QUIETLY)
MESSAGE(STATUS "Found GMP: ${GMP_LIBRARY}")
endif()
elseif(GMP_FOUND)
if(GMP_FIND_REQUIRED)
message(FATAL_ERROR "Could not find GMP")
endif()
endif()
__EOF__
======================== FILE ./cmake/FindGSL.cmake
FILE: ./cmake/FindGSL.cmake
# - Find GSL
# Find the native GSL includes and library
#
#  GSL_INCLUDES    - where to find gsl/gsl_*.h, etc.
#  GSL_LIBRARIES   - List of libraries when using GSL.
#  GSL_FOUND       - True if GSL found.


if (GSL_INCLUDES)
  # Already in cache, be silent
  set (GSL_FIND_QUIETLY TRUE)
endif (GSL_INCLUDES)

find_path (GSL_INCLUDES gsl/gsl_math.h
  HINTS "${GSL_ROOT}/include" "$ENV{GSL_ROOT}/include")

string(REGEX REPLACE "/include/?$" "/lib"
  GSL_LIB_HINT ${GSL_INCLUDES})

find_library (GSL_LIB
  NAMES gsl
  HINTS ${GSL_LIB_HINT})

find_library(GSL_CBLAS_LIB
  NAMES gslcblas
  HINTS ${GSL_LIB_HINT})

if ((NOT GSL_INCLUDES) OR (NOT GSL_LIB) OR (NOT GSL_CBLAS_LIB))
  message(STATUS "Trying to find GSL using 'gsl-config'...")
  find_program(GSL_CONFIG "gsl-config")
  if (GSL_CONFIG)
    execute_process(COMMAND ${GSL_CONFIG} --prefix
      OUTPUT_VARIABLE GSL_PREFIX
      OUTPUT_STRIP_TRAILING_WHITESPACE)

    find_path(GSL_INCLUDES gsl/gsl_math.h
      HINTS "${GSL_PREFIX}/include")

    find_library (GSL_LIB NAMES gsl
      HINTS "${GSL_PREFIX}/lib")

    find_library(GSL_CBLAS_LIB NAMES gslcblas
      HINTS "${GSL_PREFIX}/lib")
  endif()
endif()

if ((NOT GSL_LIB) OR (NOT GSL_INCLUDES))
  message(STATUS "Trying to find GSL using LD_LIBRARY_PATH (we're desperate)...")

  file(TO_CMAKE_PATH "$ENV{LD_LIBRARY_PATH}" LD_LIBRARY_PATH)

  find_library(GSL_LIB
    NAMES gsl
    HINTS ${LD_LIBRARY_PATH})

  find_library(GSL_CBLAS_LIB
    NAMES gslcblas
    HINTS ${LD_LIBRARY_PATH})

  if (GSL_LIB)
    get_filename_component(GSL_LIB_DIR ${GSL_LIB} PATH)
    string(REGEX REPLACE "/lib/?$" "/include"
      GSL_H_HINT ${GSL_LIB_DIR})

    find_path (GSL_INCLUDES gsl/gsl_math.h
      HINTS ${GSL_H_HINT}
      DOC "Path to gsl/gsl_math.h")
  endif()
endif()

if (GSL_LIB AND GSL_CBLAS_LIB)
  set (GSL_LIBRARIES "${GSL_LIB}" "${GSL_CBLAS_LIB}")
endif()

# handle the QUIETLY and REQUIRED arguments and set GSL_FOUND to TRUE if
# all listed variables are TRUE
include (FindPackageHandleStandardArgs)
find_package_handle_standard_args (GSL DEFAULT_MSG GSL_LIBRARIES GSL_INCLUDES)

mark_as_advanced (GSL_LIB GSL_CBLAS_LIB GSL_INCLUDES)
__EOF__
======================== FILE ./cmake/FindMPI.cmake
FILE: ./cmake/FindMPI.cmake
# - Find a Message Passing Interface (MPI) implementation
# The Message Passing Interface (MPI) is a library used to write
# high-performance distributed-memory parallel applications, and
# is typically deployed on a cluster. MPI is a standard interface
# (defined by the MPI forum) for which many implementations are
# available. All of them have somewhat different include paths,
# libraries to link against, etc., and this module tries to smooth
# out those differences.
#
# === Variables ===
#
# This module will set the following variables per language in your project,
# where <lang> is one of C, CXX, or Fortran:
#   MPI_<lang>_FOUND           TRUE if FindMPI found MPI flags for <lang>
#   MPI_<lang>_COMPILER        MPI Compiler wrapper for <lang>
#   MPI_<lang>_COMPILE_FLAGS   Compilation flags for MPI programs
#   MPI_<lang>_INCLUDE_PATH    Include path(s) for MPI header
#   MPI_<lang>_LINK_FLAGS      Linking flags for MPI programs
#   MPI_<lang>_LIBRARIES       All libraries to link MPI programs against
# Additionally, FindMPI sets the following variables for running MPI
# programs from the command line:
#   MPIEXEC                    Executable for running MPI programs
#   MPIEXEC_NUMPROC_FLAG       Flag to pass to MPIEXEC before giving
#                              it the number of processors to run on
#   MPIEXEC_PREFLAGS           Flags to pass to MPIEXEC directly
#                              before the executable to run.
#   MPIEXEC_POSTFLAGS          Flags to pass to MPIEXEC after other flags
# === Usage ===
#
# To use this module, simply call FindMPI from a CMakeLists.txt file, or
# run find_package(MPI), then run CMake.  If you are happy with the auto-
# detected configuration for your language, then you're done.  If not, you
# have two options:
#   1. Set MPI_<lang>_COMPILER to the MPI wrapper (mpicc, etc.) of your
#      choice and reconfigure.  FindMPI will attempt to determine all the
#      necessary variables using THAT compiler's compile and link flags.
#   2. If this fails, or if your MPI implementation does not come with
#      a compiler wrapper, then set both MPI_<lang>_LIBRARIES and
#      MPI_<lang>_INCLUDE_PATH.  You may also set any other variables
#      listed above, but these two are required.  This will circumvent
#      autodetection entirely.
# When configuration is successful, MPI_<lang>_COMPILER will be set to the
# compiler wrapper for <lang>, if it was found.  MPI_<lang>_FOUND and other
# variables above will be set if any MPI implementation was found for <lang>,
# regardless of whether a compiler was found.
#
# When using MPIEXEC to execute MPI applications, you should typically use
# all of the MPIEXEC flags as follows:
#   ${MPIEXEC} ${MPIEXEC_NUMPROC_FLAG} PROCS
#     ${MPIEXEC_PREFLAGS} EXECUTABLE ${MPIEXEC_POSTFLAGS} ARGS
# where PROCS is the number of processors on which to execute the program,
# EXECUTABLE is the MPI program, and ARGS are the arguments to pass to the
# MPI program.
#
# === Backward Compatibility ===
#
# For backward compatibility with older versions of FindMPI, these
# variables are set, but deprecated:
#   MPI_FOUND           MPI_COMPILER        MPI_LIBRARY
#   MPI_COMPILE_FLAGS   MPI_INCLUDE_PATH    MPI_EXTRA_LIBRARY
#   MPI_LINK_FLAGS      MPI_LIBRARIES
# In new projects, please use the MPI_<lang>_XXX equivalents.

#=============================================================================
# Copyright 2001-2011 Kitware, Inc.
# Copyright 2010-2011 Todd Gamblin tgamblin@llnl.gov
# Copyright 2001-2009 Dave Partyka
#
# Distributed under the OSI-approved BSD License (the "License");
# see accompanying file Copyright.txt for details.
#
# This software is distributed WITHOUT ANY WARRANTY; without even the
# implied warranty of MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.
# See the License for more information.
#=============================================================================
# (To distribute this file outside of CMake, substitute the full
#  License text for the above reference.)

# include this to handle the QUIETLY and REQUIRED arguments
include(${CMAKE_CURRENT_LIST_DIR}/FindPackageHandleStandardArgs.cmake)
include(${CMAKE_CURRENT_LIST_DIR}/GetPrerequisites.cmake)

#
# This part detects MPI compilers, attempting to wade through the mess of compiler names in
# a sensible way.
#
# The compilers are detected in this order:
#
# 1. Try to find the most generic available MPI compiler, as this is usually set up by
#    cluster admins.  e.g., if plain old mpicc is available, we'll use it and assume it's
#    the right compiler.
#
# 2. If a generic mpicc is NOT found, then we attempt to find one that matches
#    CMAKE_<lang>_COMPILER_ID. e.g. if you are using XL compilers, we'll try to find mpixlc
#    and company, but not mpiicc.  This hopefully prevents toolchain mismatches.
#
# If you want to force a particular MPI compiler other than what we autodetect (e.g. if you
# want to compile regular stuff with GNU and parallel stuff with Intel), you can always set
# your favorite MPI_<lang>_COMPILER explicitly and this stuff will be ignored.
#

# Start out with the generic MPI compiler names, as these are most commonly used.
set(_MPI_C_COMPILER_NAMES                  mpicc    mpcc      mpicc_r mpcc_r)
set(_MPI_CXX_COMPILER_NAMES                mpicxx   mpiCC     mpcxx   mpCC    mpic++   mpc++
                                           mpicxx_r mpiCC_r   mpcxx_r mpCC_r  mpic++_r mpc++_r)
set(_MPI_Fortran_COMPILER_NAMES            mpif95   mpif95_r  mpf95   mpf95_r
                                           mpif90   mpif90_r  mpf90   mpf90_r
                                           mpif77   mpif77_r  mpf77   mpf77_r)

# GNU compiler names
set(_MPI_GNU_C_COMPILER_NAMES              mpigcc mpgcc mpigcc_r mpgcc_r)
set(_MPI_GNU_CXX_COMPILER_NAMES            mpig++ mpg++ mpig++_r mpg++_r)
set(_MPI_GNU_Fortran_COMPILER_NAMES        mpigfortran mpgfortran mpigfortran_r mpgfortran_r
                                           mpig77 mpig77_r mpg77 mpg77_r)

# Intel MPI compiler names
set(_MPI_Intel_C_COMPILER_NAMES            mpiicc)
set(_MPI_Intel_CXX_COMPILER_NAMES          mpiicpc  mpiicxx mpiic++ mpiiCC)
set(_MPI_Intel_Fortran_COMPILER_NAMES      mpiifort mpiif95 mpiif90 mpiif77)

# PGI compiler names
set(_MPI_PGI_C_COMPILER_NAMES              mpipgcc mppgcc)
set(_MPI_PGI_CXX_COMPILER_NAMES            mpipgCC mppgCC)
set(_MPI_PGI_Fortran_COMPILER_NAMES        mpipgf95 mpipgf90 mppgf95 mppgf90 mpipgf77 mppgf77)

# XLC MPI Compiler names
set(_MPI_XL_C_COMPILER_NAMES               mpxlc      mpxlc_r    mpixlc     mpixlc_r)
set(_MPI_XL_CXX_COMPILER_NAMES             mpixlcxx   mpixlC     mpixlc++   mpxlcxx   mpxlc++   mpixlc++   mpxlCC
                                           mpixlcxx_r mpixlC_r   mpixlc++_r mpxlcxx_r mpxlc++_r mpixlc++_r mpxlCC_r)
set(_MPI_XL_Fortran_COMPILER_NAMES         mpixlf95   mpixlf95_r mpxlf95 mpxlf95_r
                                           mpixlf90   mpixlf90_r mpxlf90 mpxlf90_r
                                           mpixlf77   mpixlf77_r mpxlf77 mpxlf77_r
                                           mpixlf     mpixlf_r   mpxlf   mpxlf_r)

# append vendor-specific compilers to the list if we either don't know the compiler id,
# or if we know it matches the regular compiler.
foreach (lang C CXX Fortran)
  foreach (id GNU Intel PGI XL)
    if (NOT CMAKE_${lang}_COMPILER_ID OR "${CMAKE_${lang}_COMPILER_ID}" STREQUAL "${id}")
      list(APPEND _MPI_${lang}_COMPILER_NAMES ${_MPI_${id}_${lang}_COMPILER_NAMES})
    endif()
    unset(_MPI_${id}_${lang}_COMPILER_NAMES)    # clean up the namespace here
  endforeach()
endforeach()


# Names to try for MPI exec
set(_MPI_EXEC_NAMES                        mpiexec mpirun lamexec srun)

# Grab the path to MPI from the registry if we're on windows.
set(_MPI_PREFIX_PATH)
if(WIN32)
  list(APPEND _MPI_PREFIX_PATH "[HKEY_LOCAL_MACHINE\\SOFTWARE\\MPICH\\SMPD;binary]/..")
  list(APPEND _MPI_PREFIX_PATH "[HKEY_LOCAL_MACHINE\\SOFTWARE\\MPICH2;Path]")
  list(APPEND _MPI_PREFIX_PATH "$ENV{ProgramW6432}/MPICH2/")
endif()

# Build a list of prefixes to search for MPI.
foreach(SystemPrefixDir ${CMAKE_SYSTEM_PREFIX_PATH})
  foreach(MpiPackageDir ${_MPI_PREFIX_PATH})
    if(EXISTS ${SystemPrefixDir}/${MpiPackageDir})
      list(APPEND _MPI_PREFIX_PATH "${SystemPrefixDir}/${MpiPackageDir}")
    endif()
  endforeach()
endforeach()


#
# interrogate_mpi_compiler(lang try_libs)
#
# Attempts to extract compiler and linker args from an MPI compiler. The arguments set
# by this function are:
#
#   MPI_<lang>_INCLUDE_PATH    MPI_<lang>_LINK_FLAGS     MPI_<lang>_FOUND
#   MPI_<lang>_COMPILE_FLAGS   MPI_<lang>_LIBRARIES
#
# MPI_<lang>_COMPILER must be set beforehand to the absolute path to an MPI compiler for
# <lang>.  Additionally, MPI_<lang>_INCLUDE_PATH and MPI_<lang>_LIBRARIES may be set
# to skip autodetection.
#
# If try_libs is TRUE, this will also attempt to find plain MPI libraries in the usual
# way.  In general, this is not as effective as interrogating the compilers, as it
# ignores language-specific flags and libraries.  However, some MPI implementations
# (Windows implementations) do not have compiler wrappers, so this approach must be used.
#
function (interrogate_mpi_compiler lang try_libs)
  # MPI_${lang}_NO_INTERROGATE will be set to a compiler name when the *regular* compiler was
  # discovered to be the MPI compiler.  This happens on machines like the Cray XE6 that use
  # modules to set cc, CC, and ftn to the MPI compilers.  If the user force-sets another MPI
  # compiler, MPI_${lang}_COMPILER won't be equal to MPI_${lang}_NO_INTERROGATE, and we'll
  # inspect that compiler anew.  This allows users to set new compilers w/o rm'ing cache.
  string(COMPARE NOTEQUAL "${MPI_${lang}_NO_INTERROGATE}" "${MPI_${lang}_COMPILER}" interrogate)

  # If MPI is set already in the cache, don't bother with interrogating the compiler.
  if (interrogate AND ((NOT MPI_${lang}_INCLUDE_PATH) OR (NOT MPI_${lang}_LIBRARIES)))
    if (MPI_${lang}_COMPILER)
      # Check whether the -showme:compile option works. This indicates that we have either OpenMPI
      # or a newer version of LAM-MPI, and implies that -showme:link will also work.
      execute_process(
        COMMAND ${MPI_${lang}_COMPILER} -showme:compile
        OUTPUT_VARIABLE  MPI_COMPILE_CMDLINE OUTPUT_STRIP_TRAILING_WHITESPACE
        ERROR_VARIABLE   MPI_COMPILE_CMDLINE ERROR_STRIP_TRAILING_WHITESPACE
        RESULT_VARIABLE  MPI_COMPILER_RETURN)

      if (MPI_COMPILER_RETURN EQUAL 0)
        # If we appear to have -showme:compile, then we should
        # also have -showme:link. Try it.
        execute_process(
          COMMAND ${MPI_${lang}_COMPILER} -showme:link
          OUTPUT_VARIABLE  MPI_LINK_CMDLINE OUTPUT_STRIP_TRAILING_WHITESPACE
          ERROR_VARIABLE   MPI_LINK_CMDLINE ERROR_STRIP_TRAILING_WHITESPACE
          RESULT_VARIABLE  MPI_COMPILER_RETURN)

        if (MPI_COMPILER_RETURN EQUAL 0)
          # We probably have -showme:incdirs and -showme:libdirs as well,
          # so grab that while we're at it.
          execute_process(
            COMMAND ${MPI_${lang}_COMPILER} -showme:incdirs
            OUTPUT_VARIABLE  MPI_INCDIRS OUTPUT_STRIP_TRAILING_WHITESPACE
            ERROR_VARIABLE   MPI_INCDIRS ERROR_STRIP_TRAILING_WHITESPACE)

          execute_process(
            COMMAND ${MPI_${lang}_COMPILER} -showme:libdirs
            OUTPUT_VARIABLE  MPI_LIBDIRS OUTPUT_STRIP_TRAILING_WHITESPACE
            ERROR_VARIABLE   MPI_LIBDIRS ERROR_STRIP_TRAILING_WHITESPACE)

        else()
          # reset things here if something went wrong.
          set(MPI_COMPILE_CMDLINE)
          set(MPI_LINK_CMDLINE)
        endif()
      endif ()

      # Older versions of LAM-MPI have "-showme". Try to find that.
      if (NOT MPI_COMPILER_RETURN EQUAL 0)
        execute_process(
          COMMAND ${MPI_${lang}_COMPILER} -showme
          OUTPUT_VARIABLE  MPI_COMPILE_CMDLINE OUTPUT_STRIP_TRAILING_WHITESPACE
          ERROR_VARIABLE   MPI_COMPILE_CMDLINE ERROR_STRIP_TRAILING_WHITESPACE
          RESULT_VARIABLE  MPI_COMPILER_RETURN)
      endif()

      # MVAPICH uses -compile-info and -link-info.  Try them.
      if (NOT MPI_COMPILER_RETURN EQUAL 0)
        execute_process(
          COMMAND ${MPI_${lang}_COMPILER} -compile-info
          OUTPUT_VARIABLE  MPI_COMPILE_CMDLINE OUTPUT_STRIP_TRAILING_WHITESPACE
          ERROR_VARIABLE   MPI_COMPILE_CMDLINE ERROR_STRIP_TRAILING_WHITESPACE
          RESULT_VARIABLE  MPI_COMPILER_RETURN)

        # If we have compile-info, also have link-info.
        if (MPI_COMPILER_RETURN EQUAL 0)
          execute_process(
            COMMAND ${MPI_${lang}_COMPILER} -link-info
            OUTPUT_VARIABLE  MPI_LINK_CMDLINE OUTPUT_STRIP_TRAILING_WHITESPACE
            ERROR_VARIABLE   MPI_LINK_CMDLINE ERROR_STRIP_TRAILING_WHITESPACE
            RESULT_VARIABLE  MPI_COMPILER_RETURN)
        endif()

        # make sure we got compile and link.  Reset vars if something's wrong.
        if (NOT MPI_COMPILER_RETURN EQUAL 0)
          set(MPI_COMPILE_CMDLINE)
          set(MPI_LINK_CMDLINE)
        endif()
      endif()

      # MPICH just uses "-show". Try it.
      if (NOT MPI_COMPILER_RETURN EQUAL 0)
        execute_process(
          COMMAND ${MPI_${lang}_COMPILER} -show
          OUTPUT_VARIABLE  MPI_COMPILE_CMDLINE OUTPUT_STRIP_TRAILING_WHITESPACE
          ERROR_VARIABLE   MPI_COMPILE_CMDLINE ERROR_STRIP_TRAILING_WHITESPACE
          RESULT_VARIABLE  MPI_COMPILER_RETURN)
      endif()

      if (MPI_COMPILER_RETURN EQUAL 0)
        # We have our command lines, but we might need to copy MPI_COMPILE_CMDLINE
        # into MPI_LINK_CMDLINE, if we didn't find the link line.
        if (NOT MPI_LINK_CMDLINE)
          set(MPI_LINK_CMDLINE ${MPI_COMPILE_CMDLINE})
        endif()
      else()
        message(STATUS "Unable to determine MPI from MPI driver ${MPI_${lang}_COMPILER}")
        set(MPI_COMPILE_CMDLINE)
        set(MPI_LINK_CMDLINE)
      endif()

      # Here, we're done with the interrogation part, and we'll try to extract args we care
      # about from what we learned from the compiler wrapper scripts.

      # If interrogation came back with something, extract our variable from the MPI command line
      if (MPI_COMPILE_CMDLINE OR MPI_LINK_CMDLINE)
        # Extract compile flags from the compile command line.
        string(REGEX MATCHALL "(^| )-[Df]([^\" ]+|\"[^\"]+\")" MPI_ALL_COMPILE_FLAGS "${MPI_COMPILE_CMDLINE}")
        set(MPI_COMPILE_FLAGS_WORK)

        foreach(FLAG ${MPI_ALL_COMPILE_FLAGS})
          if (MPI_COMPILE_FLAGS_WORK)
            set(MPI_COMPILE_FLAGS_WORK "${MPI_COMPILE_FLAGS_WORK} ${FLAG}")
          else()
            set(MPI_COMPILE_FLAGS_WORK ${FLAG})
          endif()
        endforeach()

        # Extract include paths from compile command line
        string(REGEX MATCHALL "(^| )-I([^\" ]+|\"[^\"]+\")" MPI_ALL_INCLUDE_PATHS "${MPI_COMPILE_CMDLINE}")
        foreach(IPATH ${MPI_ALL_INCLUDE_PATHS})
          string(REGEX REPLACE "^ ?-I" "" IPATH ${IPATH})
          string(REGEX REPLACE "//" "/" IPATH ${IPATH})
          list(APPEND MPI_INCLUDE_PATH_WORK ${IPATH})
        endforeach()

        # try using showme:incdirs if extracting didn't work.
        if (NOT MPI_INCLUDE_PATH_WORK)
          set(MPI_INCLUDE_PATH_WORK ${MPI_INCDIRS})
          separate_arguments(MPI_INCLUDE_PATH_WORK)
        endif()

        # If all else fails, just search for mpi.h in the normal include paths.
        if (NOT MPI_INCLUDE_PATH_WORK)
          set(MPI_HEADER_PATH "MPI_HEADER_PATH-NOTFOUND" CACHE FILEPATH "Cleared" FORCE)
          find_path(MPI_HEADER_PATH mpi.h
            HINTS ${_MPI_BASE_DIR} ${_MPI_PREFIX_PATH}
            PATH_SUFFIXES include)
          set(MPI_INCLUDE_PATH_WORK ${MPI_HEADER_PATH})
        endif()

        # Extract linker paths from the link command line
        string(REGEX MATCHALL "(^| |-Wl,)-L([^\" ]+|\"[^\"]+\")" MPI_ALL_LINK_PATHS "${MPI_LINK_CMDLINE}")
        set(MPI_LINK_PATH)
        foreach(LPATH ${MPI_ALL_LINK_PATHS})
          string(REGEX REPLACE "^(| |-Wl,)-L" "" LPATH ${LPATH})
          string(REGEX REPLACE "//" "/" LPATH ${LPATH})
          list(APPEND MPI_LINK_PATH ${LPATH})
        endforeach()

        # try using showme:libdirs if extracting didn't work.
        if (NOT MPI_LINK_PATH)
          set(MPI_LINK_PATH ${MPI_LIBDIRS})
          separate_arguments(MPI_LINK_PATH)
        endif()

        # Extract linker flags from the link command line
        string(REGEX MATCHALL "(^| )-Wl,([^\" ]+|\"[^\"]+\")" MPI_ALL_LINK_FLAGS "${MPI_LINK_CMDLINE}")
        set(MPI_LINK_FLAGS_WORK)
        foreach(FLAG ${MPI_ALL_LINK_FLAGS})
          if (MPI_LINK_FLAGS_WORK)
            set(MPI_LINK_FLAGS_WORK "${MPI_LINK_FLAGS_WORK} ${FLAG}")
          else()
            set(MPI_LINK_FLAGS_WORK ${FLAG})
          endif()
        endforeach()

        # Extract the set of libraries to link against from the link command
        # line
        string(REGEX MATCHALL "(^| )-l([^\" ]+|\"[^\"]+\")" MPI_LIBNAMES "${MPI_LINK_CMDLINE}")
        # add the compiler implicit directories because some compilers
        # such as the intel compiler have libraries that show up
        # in the showme list that can only be found in the implicit
        # link directories of the compiler.
        if (DEFINED CMAKE_${lang}_IMPLICIT_LINK_DIRECTORIES)
          set(MPI_LINK_PATH
            "${MPI_LINK_PATH};${CMAKE_${lang}_IMPLICIT_LINK_DIRECTORIES}")
        endif ()

        # Determine full path names for all of the libraries that one needs
        # to link against in an MPI program
        foreach(LIB ${MPI_LIBNAMES})
          string(REGEX REPLACE "^ ?-l" "" LIB ${LIB})
          # MPI_LIB is cached by find_library, but we don't want that.  Clear it first.
          set(MPI_LIB "MPI_LIB-NOTFOUND" CACHE FILEPATH "Cleared" FORCE)
          find_library(MPI_LIB NAMES ${LIB} HINTS ${MPI_LINK_PATH})

          if (MPI_LIB)
            list(APPEND MPI_LIBRARIES_WORK ${MPI_LIB})
          elseif (NOT MPI_FIND_QUIETLY)
            message(WARNING "Unable to find MPI library ${LIB}")
          endif()
        endforeach()

        # Sanity check MPI_LIBRARIES to make sure there are enough libraries
        list(LENGTH MPI_LIBRARIES_WORK MPI_NUMLIBS)
        list(LENGTH MPI_LIBNAMES MPI_NUMLIBS_EXPECTED)
        if (NOT MPI_NUMLIBS EQUAL MPI_NUMLIBS_EXPECTED)
          set(MPI_LIBRARIES_WORK "MPI_${lang}_LIBRARIES-NOTFOUND")
        endif()
      endif()

    elseif(try_libs)
      # If we didn't have an MPI compiler script to interrogate, attempt to find everything
      # with plain old find functions.  This is nasty because MPI implementations have LOTS of
      # different library names, so this section isn't going to be very generic.  We need to
      # make sure it works for MS MPI, though, since there are no compiler wrappers for that.
      find_path(MPI_HEADER_PATH mpi.h
        HINTS ${_MPI_BASE_DIR} ${_MPI_PREFIX_PATH}
        PATH_SUFFIXES include Inc)
      set(MPI_INCLUDE_PATH_WORK ${MPI_HEADER_PATH})

      # Decide between 32-bit and 64-bit libraries for Microsoft's MPI
      if("${CMAKE_SIZEOF_VOID_P}" EQUAL 8)
        set(MS_MPI_ARCH_DIR amd64)
      else()
        set(MS_MPI_ARCH_DIR i386)
      endif()

      set(MPI_LIB "MPI_LIB-NOTFOUND" CACHE FILEPATH "Cleared" FORCE)
      find_library(MPI_LIB
        NAMES         mpi mpich mpich2 msmpi
        HINTS         ${_MPI_BASE_DIR} ${_MPI_PREFIX_PATH}
        PATH_SUFFIXES lib lib/${MS_MPI_ARCH_DIR} Lib Lib/${MS_MPI_ARCH_DIR})
      set(MPI_LIBRARIES_WORK ${MPI_LIB})

      # Right now, we only know about the extra libs for C++.
      # We could add Fortran here (as there is usually libfmpich, etc.), but
      # this really only has to work with MS MPI on Windows.
      # Assume that other MPI's are covered by the compiler wrappers.
      if (${lang} STREQUAL CXX)
        set(MPI_LIB "MPI_LIB-NOTFOUND" CACHE FILEPATH "Cleared" FORCE)
        find_library(MPI_LIB
          NAMES         mpi++ mpicxx cxx mpi_cxx
          HINTS         ${_MPI_BASE_DIR} ${_MPI_PREFIX_PATH}
          PATH_SUFFIXES lib)
        if (MPI_LIBRARIES_WORK AND MPI_LIB)
          list(APPEND MPI_LIBRARIES_WORK ${MPI_LIB})
        endif()
      endif()

      if (NOT MPI_LIBRARIES_WORK)
        set(MPI_LIBRARIES_WORK "MPI_${lang}_LIBRARIES-NOTFOUND")
      endif()
    endif()

    # If we found MPI, set up all of the appropriate cache entries
    set(MPI_${lang}_COMPILE_FLAGS ${MPI_COMPILE_FLAGS_WORK} CACHE STRING "MPI ${lang} compilation flags"         FORCE)
    set(MPI_${lang}_INCLUDE_PATH  ${MPI_INCLUDE_PATH_WORK}  CACHE STRING "MPI ${lang} include path"              FORCE)
    set(MPI_${lang}_LINK_FLAGS    ${MPI_LINK_FLAGS_WORK}    CACHE STRING "MPI ${lang} linking flags"             FORCE)
    set(MPI_${lang}_LIBRARIES     ${MPI_LIBRARIES_WORK}     CACHE STRING "MPI ${lang} libraries to link against" FORCE)
    mark_as_advanced(MPI_${lang}_COMPILE_FLAGS MPI_${lang}_INCLUDE_PATH MPI_${lang}_LINK_FLAGS MPI_${lang}_LIBRARIES)

    # clear out our temporary lib/header detectionv variable here.
    set(MPI_LIB         "MPI_LIB-NOTFOUND"         CACHE INTERNAL "Scratch variable for MPI lib detection"    FORCE)
    set(MPI_HEADER_PATH "MPI_HEADER_PATH-NOTFOUND" CACHE INTERNAL "Scratch variable for MPI header detection" FORCE)
  endif()

  # finally set a found variable for each MPI language
  if (MPI_${lang}_INCLUDE_PATH AND MPI_${lang}_LIBRARIES)
    set(MPI_${lang}_FOUND TRUE PARENT_SCOPE)
  else()
    set(MPI_${lang}_FOUND FALSE PARENT_SCOPE)
  endif()
endfunction()


# This function attempts to compile with the regular compiler, to see if MPI programs
# work with it.  This is a last ditch attempt after we've tried interrogating mpicc and
# friends, and after we've tried to find generic libraries.  Works on machines like
# Cray XE6, where the modules environment changes what MPI version cc, CC, and ftn use.
function(try_regular_compiler lang success)
  set(scratch_directory ${CMAKE_CURRENT_BINARY_DIR}${CMAKE_FILES_DIRECTORY})
  if (${lang} STREQUAL Fortran)
    set(test_file ${scratch_directory}/cmake_mpi_test.f90)
    file(WRITE ${test_file}
      "program hello\n"
      "include 'mpif.h'\n"
      "integer ierror\n"
      "call MPI_INIT(ierror)\n"
      "call MPI_FINALIZE(ierror)\n"
      "end\n")
  else()
    if (${lang} STREQUAL CXX)
      set(test_file ${scratch_directory}/cmake_mpi_test.cpp)
    else()
      set(test_file ${scratch_directory}/cmake_mpi_test.c)
    endif()
    file(WRITE ${test_file}
      "#include <mpi.h>\n"
      "int main(int argc, char **argv) {\n"
      "  MPI_Init(&argc, &argv);\n"
      "  MPI_Finalize();\n"
      "}\n")
  endif()
  try_compile(compiler_has_mpi ${scratch_directory} ${test_file})
  if (compiler_has_mpi)
    set(MPI_${lang}_NO_INTERROGATE ${CMAKE_${lang}_COMPILER} CACHE STRING "Whether to interrogate MPI ${lang} compiler" FORCE)
    set(MPI_${lang}_COMPILER       ${CMAKE_${lang}_COMPILER} CACHE STRING "MPI ${lang} compiler"                        FORCE)
    set(MPI_${lang}_COMPILE_FLAGS  ""                        CACHE STRING "MPI ${lang} compilation flags"               FORCE)
    set(MPI_${lang}_INCLUDE_PATH   ""                        CACHE STRING "MPI ${lang} include path"                    FORCE)
    set(MPI_${lang}_LINK_FLAGS     ""                        CACHE STRING "MPI ${lang} linking flags"                   FORCE)
    set(MPI_${lang}_LIBRARIES      ""                        CACHE STRING "MPI ${lang} libraries to link against"       FORCE)
  endif()
  set(${success} ${compiler_has_mpi} PARENT_SCOPE)
  unset(compiler_has_mpi CACHE)
endfunction()

# End definitions, commence real work here.

# Most mpi distros have some form of mpiexec which gives us something we can reliably look for.
find_program(MPIEXEC
  NAMES ${_MPI_EXEC_NAMES}
  PATHS ${_MPI_PREFIX_PATH}
  PATH_SUFFIXES bin
  DOC "Executable for running MPI programs.")

# call get_filename_component twice to remove mpiexec and the directory it exists in (typically bin).
# This gives us a fairly reliable base directory to search for /bin /lib and /include from.
get_filename_component(_MPI_BASE_DIR "${MPIEXEC}" PATH)
get_filename_component(_MPI_BASE_DIR "${_MPI_BASE_DIR}" PATH)

set(MPIEXEC_NUMPROC_FLAG "-np" CACHE STRING "Flag used by MPI to specify the number of processes for MPIEXEC; the next option will be the number of processes.")
set(MPIEXEC_PREFLAGS     ""    CACHE STRING "These flags will be directly before the executable that is being run by MPIEXEC.")
set(MPIEXEC_POSTFLAGS    ""    CACHE STRING "These flags will come after all flags given to MPIEXEC.")
set(MPIEXEC_MAX_NUMPROCS "2"   CACHE STRING "Maximum number of processors available to run MPI applications.")
mark_as_advanced(MPIEXEC MPIEXEC_NUMPROC_FLAG MPIEXEC_PREFLAGS MPIEXEC_POSTFLAGS MPIEXEC_MAX_NUMPROCS)


#=============================================================================
# Backward compatibility input hacks.  Propagate the FindMPI hints to C and
# CXX if the respective new versions are not defined.  Translate the old
# MPI_LIBRARY and MPI_EXTRA_LIBRARY to respective MPI_${lang}_LIBRARIES.
#
# Once we find the new variables, we translate them back into their old
# equivalents below.
foreach (lang C CXX)
  # Old input variables.
  set(_MPI_OLD_INPUT_VARS COMPILER COMPILE_FLAGS INCLUDE_PATH LINK_FLAGS)

  # Set new vars based on their old equivalents, if the new versions are not already set.
  foreach (var ${_MPI_OLD_INPUT_VARS})
    if (NOT MPI_${lang}_${var} AND MPI_${var})
      set(MPI_${lang}_${var} "${MPI_${var}}")
    endif()
  endforeach()

  # Special handling for MPI_LIBRARY and MPI_EXTRA_LIBRARY, which we nixed in the
  # new FindMPI.  These need to be merged into MPI_<lang>_LIBRARIES
  if (NOT MPI_${lang}_LIBRARIES AND (MPI_LIBRARY OR MPI_EXTRA_LIBRARY))
    set(MPI_${lang}_LIBRARIES ${MPI_LIBRARY} ${MPI_EXTRA_LIBRARY})
  endif()
endforeach()
#=============================================================================


# This loop finds the compilers and sends them off for interrogation.
foreach (lang C CXX Fortran)
  if (CMAKE_${lang}_COMPILER_WORKS)
    # If the user supplies a compiler *name* instead of an absolute path, assume that we need to find THAT compiler.
    if (MPI_${lang}_COMPILER)
      is_file_executable(MPI_${lang}_COMPILER MPI_COMPILER_IS_EXECUTABLE)
      if (NOT MPI_COMPILER_IS_EXECUTABLE)
        # Get rid of our default list of names and just search for the name the user wants.
        set(_MPI_${lang}_COMPILER_NAMES ${MPI_${lang}_COMPILER})
        set(MPI_${lang}_COMPILER "MPI_${lang}_COMPILER-NOTFOUND" CACHE FILEPATH "Cleared" FORCE)
        # If the user specifies a compiler, we don't want to try to search libraries either.
        set(try_libs FALSE)
      endif()
    else()
      set(try_libs TRUE)
    endif()

    find_program(MPI_${lang}_COMPILER
      NAMES  ${_MPI_${lang}_COMPILER_NAMES}
      PATHS  "${MPI_HOME}/bin" "$ENV{MPI_HOME}/bin" ${_MPI_PREFIX_PATH})
    interrogate_mpi_compiler(${lang} ${try_libs})
    mark_as_advanced(MPI_${lang}_COMPILER)

    # last ditch try -- if nothing works so far, just try running the regular compiler and
    # see if we can create an MPI executable.
    set(regular_compiler_worked 0)
    if (NOT MPI_${lang}_LIBRARIES OR NOT MPI_${lang}_INCLUDE_PATH)
      try_regular_compiler(${lang} regular_compiler_worked)
    endif()

    set(MPI_${lang}_FIND_QUIETLY ${MPI_FIND_QUIETLY})
    set(MPI_${lang}_FIND_REQUIRED ${MPI_FIND_REQUIRED})
    set(MPI_${lang}_FIND_VERSION ${MPI_FIND_VERSION})
    set(MPI_${lang}_FIND_VERSION_EXACT ${MPI_FIND_VERSION_EXACT})

    if (regular_compiler_worked)
      find_package_handle_standard_args(MPI_${lang} DEFAULT_MSG MPI_${lang}_COMPILER)
    else()
      find_package_handle_standard_args(MPI_${lang} DEFAULT_MSG MPI_${lang}_LIBRARIES MPI_${lang}_INCLUDE_PATH)
    endif()
  endif()
endforeach()


#=============================================================================
# More backward compatibility stuff
#
# Bare MPI sans ${lang} vars are set to CXX then C, depending on what was found.
# This mimics the behavior of the old language-oblivious FindMPI.
set(_MPI_OLD_VARS FOUND COMPILER INCLUDE_PATH COMPILE_FLAGS LINK_FLAGS LIBRARIES)
if (MPI_CXX_FOUND)
  foreach (var ${_MPI_OLD_VARS})
    set(MPI_${var} ${MPI_CXX_${var}})
  endforeach()
elseif (MPI_C_FOUND)
  foreach (var ${_MPI_OLD_VARS})
    set(MPI_${var} ${MPI_C_${var}})
  endforeach()
else()
  # Note that we might still have found Fortran, but you'll need to use MPI_Fortran_FOUND
  set(MPI_FOUND FALSE)
endif()

# Chop MPI_LIBRARIES into the old-style MPI_LIBRARY and MPI_EXTRA_LIBRARY, and set them in cache.
if (MPI_LIBRARIES)
  list(GET MPI_LIBRARIES 0 MPI_LIBRARY_WORK)
  set(MPI_LIBRARY ${MPI_LIBRARY_WORK} CACHE FILEPATH "MPI library to link against" FORCE)
else()
  set(MPI_LIBRARY "MPI_LIBRARY-NOTFOUND" CACHE FILEPATH "MPI library to link against" FORCE)
endif()

list(LENGTH MPI_LIBRARIES MPI_NUMLIBS)
if (MPI_NUMLIBS GREATER 1)
  set(MPI_EXTRA_LIBRARY_WORK ${MPI_LIBRARIES})
  list(REMOVE_AT MPI_EXTRA_LIBRARY_WORK 0)
  set(MPI_EXTRA_LIBRARY ${MPI_EXTRA_LIBRARY_WORK} CACHE STRING "Extra MPI libraries to link against" FORCE)
else()
  set(MPI_EXTRA_LIBRARY "MPI_EXTRA_LIBRARY-NOTFOUND" CACHE STRING "Extra MPI libraries to link against" FORCE)
endif()
#=============================================================================

# unset these vars to cleanup namespace
unset(_MPI_OLD_VARS)
unset(_MPI_PREFIX_PATH)
unset(_MPI_BASE_DIR)
foreach (lang C CXX Fortran)
  unset(_MPI_${lang}_COMPILER_NAMES)
endforeach()
__EOF__
======================== FILE ./cmake/FindNetCDF4_C.cmake
FILE: ./cmake/FindNetCDF4_C.cmake
# Input Variables
#    NETCDF4_C_ROOT
# Produces:
#    NETCDF4_C_LIBRARY
#    NETCDF4_C_INCLUDE_DIR


FIND_PATH(NETCDF4_C_INCLUDE_DIR netcdf.h
	HINTS ${NETCDF4_C_ROOT}/include)

FIND_LIBRARY(NETCDF4_C_LIBRARY NAMES netcdf
	HINTS ${NETCDF4_C_ROOT}/lib)

IF (NETCDF4_C_INCLUDE_DIR AND NETCDF4_C_LIBRARY)
   SET(NETCDF4_C_FOUND TRUE)
ENDIF (NETCDF4_C_INCLUDE_DIR AND NETCDF4_C_LIBRARY)

IF (NETCDF4_C_FOUND)
   IF (NOT NETCDF4_C_FIND_QUIETLY)
      MESSAGE(STATUS "Found NETCDF4_C_LIBRARY: ${NETCDF4_C_LIBRARY}")
   ENDIF (NOT NETCDF4_C_FIND_QUIETLY)
ELSE (NETCDF4_C_FOUND)
   IF (NETCDF4_C_FIND_REQUIRED)
      MESSAGE(FATAL_ERROR "Could not find NETCDF4_C")
   ENDIF (NETCDF4_C_FIND_REQUIRED)
ENDIF (NETCDF4_C_FOUND)
__EOF__
======================== FILE ./cmake/FindNetCDF4_CXX.cmake
FILE: ./cmake/FindNetCDF4_CXX.cmake
# Input Variables
#    NETCDF4_CXX_ROOT
# Produces:
#    NETCDF4_CXX_LIBRARY
#    NETCDF4_CXX_INCLUDE_DIR


FIND_PATH(NETCDF4_CXX_INCLUDE_DIR netcdf
	HINTS ${NETCDF4_CXX_ROOT}/include)

FIND_LIBRARY(NETCDF4_CXX_LIBRARY NAMES netcdf-cxx4
	HINTS ${NETCDF4_CXX_ROOT}/lib ${NETCDF4_CXX_ROOT}/lib64)


IF (NETCDF4_CXX_INCLUDE_DIR AND NETCDF4_CXX_LIBRARY)
   SET(NETCDF4_CXX_FOUND TRUE)
ENDIF (NETCDF4_CXX_INCLUDE_DIR AND NETCDF4_CXX_LIBRARY)

IF (NETCDF4_CXX_FOUND)
   IF (NOT NETCDF4_CXX_FIND_QUIETLY)
      MESSAGE(STATUS "Found NETCDF4_CXX_LIBRARY: ${NETCDF4_CXX_LIBRARY}")
   ENDIF (NOT NETCDF4_CXX_FIND_QUIETLY)
ELSE (NETCDF4_CXX_FOUND)
   IF (NETCDF4_CXX_FIND_REQUIRED)
      MESSAGE(FATAL_ERROR "Could not find NETCDF4_CXX")
   ENDIF (NETCDF4_CXX_FIND_REQUIRED)
ENDIF (NETCDF4_CXX_FOUND)
__EOF__
======================== FILE ./cmake/FindNetCDF4_Fortran.cmake
FILE: ./cmake/FindNetCDF4_Fortran.cmake
# Input Variables
#    NETCDF4_FORTRAN_ROOT
# Produces:
#    NETCDF4_FORTRAN_LIBRARY
#    NETCDF4_FORTRAN_INCLUDE_DIR


FIND_PATH(NETCDF4_FORTRAN_INCLUDE_DIR netcdf.mod
	HINTS ${NETCDF4_FORTRAN_ROOT}/include)

FIND_LIBRARY(NETCDF4_FORTRAN_LIBRARY NAMES netcdff
	HINTS ${NETCDF4_FORTRAN_ROOT}/lib)

IF (NETCDF4_FORTRAN_INCLUDE_DIR AND NETCDF4_FORTRAN_LIBRARY)
   SET(NETCDF4_FORTRAN_FOUND TRUE)
ENDIF (NETCDF4_FORTRAN_INCLUDE_DIR AND NETCDF4_FORTRAN_LIBRARY)

IF (NETCDF4_FORTRAN_FOUND)
   IF (NOT NETCDF4_FORTRAN_FIND_QUIETLY)
      MESSAGE(STATUS "Found NETCDF4_FORTRAN_LIBRARY: ${NETCDF4_FORTRAN_LIBRARY}")
   ENDIF (NOT NETCDF4_FORTRAN_FIND_QUIETLY)
ELSE (NETCDF4_FORTRAN_FOUND)
   IF (NETCDF4_FORTRAN_FIND_REQUIRED)
      MESSAGE(FATAL_ERROR "Could not find NETCDF4_FORTRAN")
   ENDIF (NETCDF4_FORTRAN_FIND_REQUIRED)
ENDIF (NETCDF4_FORTRAN_FOUND)
__EOF__
======================== FILE ./cmake/FindNetCDF_CXX.cmake
FILE: ./cmake/FindNetCDF_CXX.cmake
# Finds the OBSOLETE C++ interface to NetCDF
#
# Input Variables
#    NETCDF_CXX_ROOT
# Produces:
#    NETCDF_CXX_LIBRARY
#    NETCDF_CXX_INCLUDE_DIR


FIND_PATH(NETCDF_CXX_INCLUDE_DIR netcdfcpp.h
	HINTS ${NETCDF_CXX_ROOT}/include)

FIND_LIBRARY(NETCDF_CXX_LIBRARY NAMES netcdf_c++
	HINTS ${NETCDF_CXX_ROOT}/lib ${NETCDF_CXX_ROOT}/lib64)


IF (NETCDF_CXX_INCLUDE_DIR AND NETCDF_CXX_LIBRARY)
   SET(NETCDF_CXX_FOUND TRUE)
ENDIF (NETCDF_CXX_INCLUDE_DIR AND NETCDF_CXX_LIBRARY)

IF (NETCDF_CXX_FOUND)
   IF (NOT NETCDF_CXX_FIND_QUIETLY)
      MESSAGE(STATUS "Found NETCDF_CXX_LIBRARY: ${NETCDF_CXX_LIBRARY}")
   ENDIF (NOT NETCDF_CXX_FIND_QUIETLY)
ELSE (NETCDF_CXX_FOUND)
   IF (NETCDF_CXX_FIND_REQUIRED)
      MESSAGE(FATAL_ERROR "Could not find NETCDF_CXX")
   ENDIF (NETCDF_CXX_FIND_REQUIRED)
ENDIF (NETCDF_CXX_FOUND)
__EOF__
======================== FILE ./cmake/FindPETSc.cmake
FILE: ./cmake/FindPETSc.cmake
# - Try to find PETSc
# Once done this will define
#
#  PETSC_FOUND        - system has PETSc
#  PETSC_INCLUDES     - the PETSc include directories
#  PETSC_LIBRARIES    - Link these to use PETSc
#  PETSC_COMPILER     - Compiler used by PETSc, helpful to find a compatible MPI
#  PETSC_DEFINITIONS  - Compiler switches for using PETSc
#  PETSC_MPIEXEC      - Executable for running MPI programs
#  PETSC_VERSION      - Version string (MAJOR.MINOR.SUBMINOR)
#
#  Hack: PETSC_VERSION currently decides on the version based on the
#  layout.  Otherwise we need to run C code to determine the version.
#
# Setting these changes the behavior of the search
#  PETSC_DIR - directory in which PETSc resides
#  PETSC_ARCH - build architecture
#
# Redistribution and use is allowed according to the terms of the BSD license.
# For details see the accompanying COPYING-CMAKE-SCRIPTS file.
#

message("---------------------------" ${PETSC_DIR})

set(PETSC_VALID_COMPONENTS
  C
  CXX)

if(NOT PETSc_FIND_COMPONENTS)
  set(PETSC_LANGUAGE_BINDINGS "C")
else()
  # Right now, this is designed for compatability with the --with-clanguage option, so
  # only allow one item in the components list.
  list(LENGTH ${PETSc_FIND_COMPONENTS} components_length)
  if(${components_length} GREATER 1)
    message(FATAL_ERROR "Only one component for PETSc is allowed to be specified")
  endif()
  # This is a stub for allowing multiple components should that time ever come. Perhaps
  # to also test Fortran bindings?
  foreach(component ${PETSc_FIND_COMPONENTS})
    list(FIND PETSC_VALID_COMPONENTS ${component} component_location)
    if(${component_location} EQUAL -1)
      message(FATAL_ERROR "\"${component}\" is not a valid PETSc component.")
    else()
      list(APPEND PETSC_LANGUAGE_BINDINGS ${component})
    endif()
  endforeach()
endif()

function (petsc_get_version)
  if (EXISTS "${PETSC_DIR}/include/petscversion.h")
    file (STRINGS "${PETSC_DIR}/include/petscversion.h" vstrings REGEX "#define PETSC_VERSION_(RELEASE|MAJOR|MINOR|SUBMINOR|PATCH) ")
    foreach (line ${vstrings})
      string (REGEX REPLACE " +" ";" fields ${line}) # break line into three fields (the first is always "#define")
      list (GET fields 1 var)
      list (GET fields 2 val)
      set (${var} ${val} PARENT_SCOPE)
      set (${var} ${val})         # Also in local scope so we have access below
    endforeach ()
    if (PETSC_VERSION_RELEASE)
      set (PETSC_VERSION "${PETSC_VERSION_MAJOR}.${PETSC_VERSION_MINOR}.${PETSC_VERSION_SUBMINOR}p${PETSC_VERSION_PATCH}" PARENT_SCOPE)
    else ()
      # make dev version compare higher than any patch level of a released version
      set (PETSC_VERSION "${PETSC_VERSION_MAJOR}.${PETSC_VERSION_MINOR}.${PETSC_VERSION_SUBMINOR}.99" PARENT_SCOPE)
    endif ()
  else ()
    message (SEND_ERROR "PETSC_DIR can not be used, ${PETSC_DIR}/include/petscversion.h does not exist")
  endif ()
endfunction ()

find_path (PETSC_DIR include/petsc.h
  HINTS ENV PETSC_DIR
  PATHS
  /usr/lib/petscdir/3.1 /usr/lib/petscdir/3.0.0 /usr/lib/petscdir/2.3.3 /usr/lib/petscdir/2.3.2 # Debian
  $ENV{HOME}/petsc
  DOC "PETSc Directory")

find_program (MAKE_EXECUTABLE NAMES make gmake)

if (PETSC_DIR AND NOT PETSC_ARCH)
  set (_petsc_arches
    $ENV{PETSC_ARCH}                   # If set, use environment variable first
    linux-gnu-c-debug linux-gnu-c-opt  # Debian defaults
    x86_64-unknown-linux-gnu i386-unknown-linux-gnu)
  set (petscconf "NOTFOUND" CACHE FILEPATH "Cleared" FORCE)
  foreach (arch ${_petsc_arches})
    if (NOT PETSC_ARCH)
      find_path (petscconf petscconf.h
	HINTS ${PETSC_DIR}
	PATH_SUFFIXES ${arch}/include bmake/${arch}
	NO_DEFAULT_PATH)
      if (petscconf)
	set (PETSC_ARCH "${arch}" CACHE STRING "PETSc build architecture")
      endif (petscconf)
    endif (NOT PETSC_ARCH)
  endforeach (arch)
  set (petscconf "NOTFOUND" CACHE INTERNAL "Scratch variable" FORCE)
endif (PETSC_DIR AND NOT PETSC_ARCH)

set (petsc_slaves LIBRARIES_SYS LIBRARIES_VEC LIBRARIES_MAT LIBRARIES_DM LIBRARIES_KSP LIBRARIES_SNES LIBRARIES_TS
  INCLUDE_DIR INCLUDE_CONF)
include (FindPackageMultipass)
find_package_multipass (PETSc petsc_config_current
  STATES DIR ARCH
  DEPENDENTS INCLUDES LIBRARIES COMPILER MPIEXEC ${petsc_slaves})

# Determine whether the PETSc layout is old-style (through 2.3.3) or
# new-style (>= 3.0.0)
if (EXISTS "${PETSC_DIR}/${PETSC_ARCH}/include/petscconf.h")   # > 2.3.3
  set (petsc_conf_rules "${PETSC_DIR}/conf/rules")
  set (petsc_conf_variables "${PETSC_DIR}/conf/variables")
elseif (EXISTS "${PETSC_DIR}/bmake/${PETSC_ARCH}/petscconf.h") # <= 2.3.3
  set (petsc_conf_rules "${PETSC_DIR}/bmake/common/rules")
  set (petsc_conf_variables "${PETSC_DIR}/bmake/common/variables")
elseif (PETSC_DIR)
  message (SEND_ERROR "The pair PETSC_DIR=${PETSC_DIR} PETSC_ARCH=${PETSC_ARCH} do not specify a valid PETSc installation")
endif ()

if (petsc_conf_rules AND petsc_conf_variables AND NOT petsc_config_current)
  petsc_get_version()

  # Put variables into environment since they are needed to get
  # configuration (petscvariables) in the PETSc makefile
  set (ENV{PETSC_DIR} "${PETSC_DIR}")
  set (ENV{PETSC_ARCH} "${PETSC_ARCH}")

  # A temporary makefile to probe the PETSc configuration
  set (petsc_config_makefile "${PROJECT_BINARY_DIR}/Makefile.petsc")
  file (WRITE "${petsc_config_makefile}"
"## This file was autogenerated by FindPETSc.cmake
# PETSC_DIR  = ${PETSC_DIR}
# PETSC_ARCH = ${PETSC_ARCH}
include ${petsc_conf_rules}
include ${petsc_conf_variables}
show :
	-@echo -n \${\${VARIABLE}}
")

  macro (PETSC_GET_VARIABLE name var)
    set (${var} "NOTFOUND" CACHE INTERNAL "Cleared" FORCE)
    execute_process (COMMAND ${MAKE_EXECUTABLE} --no-print-directory -f ${petsc_config_makefile} show VARIABLE=${name}
      OUTPUT_VARIABLE ${var}
      RESULT_VARIABLE petsc_return)
  endmacro (PETSC_GET_VARIABLE)
  petsc_get_variable (PETSC_LIB_DIR            petsc_lib_dir)
  petsc_get_variable (PETSC_EXTERNAL_LIB_BASIC petsc_libs_external)
  petsc_get_variable (PETSC_CCPPFLAGS          petsc_cpp_line)
  petsc_get_variable (PETSC_INCLUDE            petsc_include)
  petsc_get_variable (PCC                      petsc_cc)
  petsc_get_variable (MPIEXEC                  petsc_mpiexec)
  # We are done with the temporary Makefile, calling PETSC_GET_VARIABLE after this point is invalid!
  file (REMOVE ${petsc_config_makefile})

  include (ResolveCompilerPaths)
  # Extract include paths and libraries from compile command line
  resolve_includes (petsc_includes_all "${petsc_cpp_line}")

  message (STATUS "petsc_lib_dir ${petsc_lib_dir}")

  macro (PETSC_FIND_LIBRARY suffix name)
    set (PETSC_LIBRARY_${suffix} "NOTFOUND" CACHE INTERNAL "Cleared" FORCE) # Clear any stale value, if we got here, we need to find it again
    find_library (PETSC_LIBRARY_${suffix} NAMES ${name} HINTS ${petsc_lib_dir} NO_DEFAULT_PATH)
    set (PETSC_LIBRARIES_${suffix} "${PETSC_LIBRARY_${suffix}}")
    mark_as_advanced (PETSC_LIBRARY_${suffix})
  endmacro (PETSC_FIND_LIBRARY suffix name)

  # Look for petscvec first, if it doesn't exist, we must be using single-library
  petsc_find_library (VEC petscvec)
  if (PETSC_LIBRARY_VEC)
    petsc_find_library (SYS  "petscsys;petsc") # libpetscsys is called libpetsc prior to 3.1 (when single-library was introduced)
    petsc_find_library (MAT  petscmat)
    petsc_find_library (DM   petscdm)
    petsc_find_library (KSP  petscksp)
    petsc_find_library (SNES petscsnes)
    petsc_find_library (TS   petscts)
    macro (PETSC_JOIN libs deps)
      list (APPEND PETSC_LIBRARIES_${libs} ${PETSC_LIBRARIES_${deps}})
    endmacro (PETSC_JOIN libs deps)
    petsc_join (VEC  SYS)
    petsc_join (MAT  VEC)
    petsc_join (DM   MAT)
    petsc_join (KSP  DM)
    petsc_join (SNES KSP)
    petsc_join (TS   SNES)
    petsc_join (ALL  TS)
  else ()
    set (PETSC_LIBRARY_VEC "NOTFOUND" CACHE INTERNAL "Cleared" FORCE) # There is no libpetscvec
    petsc_find_library (SINGLE petsc)
    foreach (pkg SYS VEC MAT DM KSP SNES TS ALL)
      set (PETSC_LIBRARIES_${pkg} "${PETSC_LIBRARY_SINGLE}")
    endforeach ()
  endif ()
  if (PETSC_LIBRARY_TS)
    message (STATUS "Recognized PETSc install with separate libraries for each package")
  else ()
    message (STATUS "Recognized PETSc install with single library for all packages")
  endif ()

  # Check to see if we are doing a C source test
  if(${PETSC_LANGUAGE_BINDINGS} STREQUAL "C")
    include (CheckCSourceRuns)
    macro (PETSC_TEST_RUNS includes libraries runs)
      if (PETSC_VERSION VERSION_GREATER 3.1)
	set (_PETSC_TSDestroy "TSDestroy(&ts)")
      else ()
	set (_PETSC_TSDestroy "TSDestroy(ts)")
      endif ()
      multipass_c_source_runs ("${includes}" "${libraries}" "
static const char help[] = \"PETSc test program.\";
#include <petscts.h>
int main(int argc,char *argv[]) {
  PetscErrorCode ierr;
  TS ts;

  ierr = PetscInitialize(&argc,&argv,0,help);CHKERRQ(ierr);
  ierr = TSCreate(PETSC_COMM_WORLD,&ts);CHKERRQ(ierr);
  ierr = TSSetFromOptions(ts);CHKERRQ(ierr);
  ierr = ${_PETSC_TSDestroy};CHKERRQ(ierr);
  ierr = PetscFinalize();CHKERRQ(ierr);
  return 0;
}
" ${runs})
      if (${${runs}})
	set (PETSC_EXECUTABLE_RUNS "YES" CACHE BOOL
	  "Can the system successfully run a PETSc executable?  This variable can be manually set to \"YES\" to force CMake to accept a given PETSc configuration, but this will almost always result in a broken build.  If you change PETSC_DIR, PETSC_ARCH, or PETSC_CURRENT you would have to reset this variable." FORCE)
      endif (${${runs}})
    endmacro (PETSC_TEST_RUNS)
  endif()

  if(${PETSC_LANGUAGE_BINDINGS} STREQUAL "CXX")
    include (CheckCXXSourceRuns)
    macro (PETSC_TEST_RUNS includes libraries runs)
      if (PETSC_VERSION VERSION_GREATER 3.1)
	set (_PETSC_TSDestroy "TSDestroy(&ts)")
      else ()
	set (_PETSC_TSDestroy "TSDestroy(ts)")
      endif ()
      multipass_cxx_source_runs ("${includes}" "${libraries}" "
static const char help[] = \"PETSc test program.\";
#include <petscts.h>
int main(int argc,char *argv[]) {
  PetscErrorCode ierr;
  TS ts;

  ierr = PetscInitialize(&argc,&argv,0,help);CHKERRXX(ierr);
  ierr = TSCreate(PETSC_COMM_WORLD,&ts);CHKERRXX(ierr);
  ierr = TSSetFromOptions(ts);CHKERRXX(ierr);
  ierr = ${_PETSC_TSDestroy};CHKERRXX(ierr);
  ierr = PetscFinalize();CHKERRXX(ierr);
  return 0;
}
" ${runs})
      if (${${runs}})
	set (PETSC_EXECUTABLE_RUNS "ON" CACHE BOOL
	  "Can the system successfully run a PETSc executable?  This variable can be manually set to \"ON\" to force CMake to accept a given PETSc configuration, but this will almost always result in a broken build.  If you change PETSC_DIR, PETSC_ARCH, or PETSC_CURRENT you would have to reset this variable." FORCE)
      endif (${${runs}})
    endmacro (PETSC_TEST_RUNS)
  endif()

  find_path (PETSC_INCLUDE_DIR petscts.h HINTS "${PETSC_DIR}" PATH_SUFFIXES include NO_DEFAULT_PATH)
  find_path (PETSC_INCLUDE_CONF petscconf.h HINTS "${PETSC_DIR}" PATH_SUFFIXES "${PETSC_ARCH}/include" "bmake/${PETSC_ARCH}" NO_DEFAULT_PATH)
  mark_as_advanced (PETSC_INCLUDE_DIR PETSC_INCLUDE_CONF)
  set (petsc_includes_minimal ${PETSC_INCLUDE_CONF} ${PETSC_INCLUDE_DIR})

  petsc_test_runs ("${petsc_includes_minimal}" "${PETSC_LIBRARIES_TS}" petsc_works_minimal)
  if (petsc_works_minimal)
    message (STATUS "Minimal PETSc includes and libraries work.  This probably means we are building with shared libs.")
    set (petsc_includes_needed "${petsc_includes_minimal}")
  else (petsc_works_minimal)	# Minimal includes fail, see if just adding full includes fixes it
    petsc_test_runs ("${petsc_includes_all}" "${PETSC_LIBRARIES_TS}" petsc_works_allincludes)
    if (petsc_works_allincludes) # It does, we just need all the includes (
      message (STATUS "PETSc requires extra include paths, but links correctly with only interface libraries.  This is an unexpected configuration (but it seems to work fine).")
      set (petsc_includes_needed ${petsc_includes_all})
    else (petsc_works_allincludes) # We are going to need to link the external libs explicitly
      resolve_libraries (petsc_libraries_external "${petsc_libs_external}")
      foreach (pkg SYS VEC MAT DM KSP SNES TS ALL)
	list (APPEND PETSC_LIBRARIES_${pkg}  ${petsc_libraries_external})
      endforeach (pkg)
      petsc_test_runs ("${petsc_includes_minimal}" "${PETSC_LIBRARIES_TS}" petsc_works_alllibraries)
      if (petsc_works_alllibraries)
	 message (STATUS "PETSc only need minimal includes, but requires explicit linking to all dependencies.  This is expected when PETSc is built with static libraries.")
	set (petsc_includes_needed ${petsc_includes_minimal})
      else (petsc_works_alllibraries)
	# It looks like we really need everything, should have listened to Matt
	set (petsc_includes_needed ${petsc_includes_all})
	petsc_test_runs ("${petsc_includes_all}" "${PETSC_LIBRARIES_TS}" petsc_works_all)
	if (petsc_works_all) # We fail anyways
	  message (STATUS "PETSc requires extra include paths and explicit linking to all dependencies.  This probably means you have static libraries and something unexpected in PETSc headers.")
	else (petsc_works_all) # We fail anyways
	  message (STATUS "PETSc could not be used, maybe the install is broken.")
	endif (petsc_works_all)
      endif (petsc_works_alllibraries)
    endif (petsc_works_allincludes)
  endif (petsc_works_minimal)

  # We do an out-of-source build so __FILE__ will be an absolute path, hence __INSDIR__ is superfluous
  if (${PETSC_VERSION} VERSION_LESS 3.1)
    set (PETSC_DEFINITIONS "-D__SDIR__=\"\"" CACHE STRING "PETSc definitions" FORCE)
  else ()
    set (PETSC_DEFINITIONS "-D__INSDIR__=" CACHE STRING "PETSc definitions" FORCE)
  endif ()
  # Sometimes this can be used to assist FindMPI.cmake
  set (PETSC_MPIEXEC ${petsc_mpiexec} CACHE FILEPATH "Executable for running PETSc MPI programs" FORCE)
  set (PETSC_INCLUDES ${petsc_includes_needed} CACHE STRING "PETSc include path" FORCE)
  set (PETSC_LIBRARIES ${PETSC_LIBRARIES_ALL} CACHE STRING "PETSc libraries" FORCE)
  set (PETSC_COMPILER ${petsc_cc} CACHE FILEPATH "PETSc compiler" FORCE)
  # Note that we have forced values for all these choices.  If you
  # change these, you are telling the system to trust you that they
  # work.  It is likely that you will end up with a broken build.
  mark_as_advanced (PETSC_INCLUDES PETSC_LIBRARIES PETSC_COMPILER PETSC_DEFINITIONS PETSC_MPIEXEC PETSC_EXECUTABLE_RUNS)
endif ()

include (FindPackageHandleStandardArgs)
find_package_handle_standard_args (PETSc
  "PETSc could not be found.  Be sure to set PETSC_DIR and PETSC_ARCH."
  PETSC_INCLUDES PETSC_LIBRARIES PETSC_EXECUTABLE_RUNS)
__EOF__
======================== FILE ./cmake/FindPISM.cmake
FILE: ./cmake/FindPISM.cmake
# - Try to find Pism
# Input Variables
#    PISM_SRC
#    PISM_LIB
# Once done this will define
#  PISM_FOUND - System has Pism
#  PISM_INCLUDE_DIRS - The Pism include directories
#  PISM_LIBRARIES - The libraries needed to use Pism
##  PISM_DEFINITIONS - Compiler switches required for using Pism

#pism_find_prerequisites()


find_path(PISM_SRC base/iceModel.hh
          HINTS ${PISM_SRC})

set(PISM_INCLUDE_DIRS
  ${PISM_SRC}/base
  ${PISM_SRC}/base/stressbalance
  ${PISM_SRC}/base/util
  ${PISM_SRC}/base/util/io
  ${PISM_SRC}/base/energy
  ${PISM_SRC}/base/rheology
  ${PISM_SRC}/base/basalstrength
  ${PISM_SRC}/earth
  ${PISM_SRC}/coupler
  ${PISM_SRC}/coupler/atmosphere
  ${PISM_SRC}/coupler/surface
  ${PISM_SRC}/coupler/ocean
  ${PISM_SRC}/coupler/util)


#     -DUSE_PISM @PETSC_CFLAGS@)

set(PISM_COMPONENTS base earth boundary stressbalance flowlaws util)
foreach(COMPONENT ${PISM_COMPONENTS})
    string(TOUPPER ${COMPONENT} UPPERCOMPONENT)
	find_library(PISM_${UPPERCOMPONENT}_LIBRARY pism${COMPONENT}
		PATH_SUFFIXES pism
		HINTS ${PISM_LIB})
	set(PISM_LIBRARIES ${PISM_LIBRARIES} ${PISM_${UPPERCOMPONENT}_LIBRARY})
endforeach()

include(FindPackageHandleStandardArgs)
# handle the QUIETLY and REQUIRED arguments and set PISM_FOUND to TRUE
# if all listed variables are TRUE
find_package_handle_standard_args(Pism  DEFAULT_MSG
                                  PISM_LIBRARIES PISM_INCLUDE_DIRS)

mark_as_advanced(PISM_INCLUDE_DIRS PISM_LIBRARIES )
__EOF__
======================== FILE ./cmake/FindPNetCDF.cmake
FILE: ./cmake/FindPNetCDF.cmake
# Finds the OBSOLETE C++ interface to Pnetcdf
#
# Input Variables
#    PNETCDF_ROOT
# Produces:
#    PNETCDF_LIBRARY
#    PNETCDF_INCLUDE_DIR


FIND_PATH(PNETCDF_INCLUDE_DIR pnetcdf.h
	HINTS ${PNETCDF_ROOT}/include)

FIND_LIBRARY(PNETCDF_LIBRARY NAMES pnetcdf
	HINTS ${PNETCDF_ROOT}/lib ${PNETCDF_ROOT}/lib64)


IF (PNETCDF_INCLUDE_DIR AND PNETCDF_LIBRARY)
   SET(PNETCDF_FOUND TRUE)
ENDIF (PNETCDF_INCLUDE_DIR AND PNETCDF_LIBRARY)

IF (PNETCDF_FOUND)
   IF (NOT PNETCDF_FIND_QUIETLY)
      MESSAGE(STATUS "Found PNETCDF_LIBRARY: ${PNETCDF_LIBRARY}")
   ENDIF (NOT PNETCDF_FIND_QUIETLY)
ELSE (PNETCDF_FOUND)
   IF (PNETCDF_FIND_REQUIRED)
      MESSAGE(FATAL_ERROR "Could not find PNETCDF")
   ENDIF (PNETCDF_FIND_REQUIRED)
ENDIF (PNETCDF_FOUND)
__EOF__
======================== FILE ./cmake/FindPROJ4.cmake
FILE: ./cmake/FindPROJ4.cmake
# - Find proj.4
# Find the native proj.4 includes and library
#
#  PROJ4_INCLUDES    - where to find proj_api.h
#  PROJ4_LIBRARIES   - List of libraries when using proj.4.
#  PROJ4_FOUND       - True if proj.4 found.

if (PROJ4_INCLUDES)
  # Already in cache, be silent
  set (PROJ4_FIND_QUIETLY TRUE)
endif (PROJ4_INCLUDES)

find_path (PROJ4_INCLUDES proj_api.h
  HINTS "${PROJ_ROOT}/include" "$ENV{PROJ_ROOT}/include")

message(PROJ ${PROJ_ROOT})
message(PROJ ${PROJ4_INCLUDES})


string(REGEX REPLACE "/include/?$" "/lib"
  PROJ4_LIB_HINT ${PROJ4_INCLUDES})

find_library (PROJ4_LIBRARIES
  NAMES proj
  HINTS ${PROJ4_LIB_HINT})

if ((NOT PROJ4_LIBRARIES) OR (NOT PROJ4_INCLUDES))
  message(STATUS "Trying to find proj.4 using LD_LIBRARY_PATH (we're desperate)...")

  file(TO_CMAKE_PATH "$ENV{LD_LIBRARY_PATH}" LD_LIBRARY_PATH)

  find_library(PROJ4_LIBRARIES
    NAMES proj
    HINTS ${LD_LIBRARY_PATH})

  if (PROJ4_LIBRARIES)
    get_filename_component(PROJ4_LIB_DIR ${PROJ4_LIBRARIES} PATH)
    string(REGEX REPLACE "/lib/?$" "/include"
      PROJ4_H_HINT ${PROJ4_LIB_DIR})

    find_path (PROJ4_INCLUDES proj_api.h
      HINTS ${PROJ4_H_HINT}
      DOC "Path to proj_api.h")
  endif()
endif()

# handle the QUIETLY and REQUIRED arguments and set PROJ4_FOUND to TRUE if
# all listed variables are TRUE
include (FindPackageHandleStandardArgs)
find_package_handle_standard_args (PROJ4 DEFAULT_MSG PROJ4_LIBRARIES PROJ4_INCLUDES)

mark_as_advanced (PROJ4_LIBRARIES PROJ4_INCLUDES)
__EOF__
======================== FILE ./cmake/FindPackageHandleStandardArgs.cmake
FILE: ./cmake/FindPackageHandleStandardArgs.cmake
# FIND_PACKAGE_HANDLE_STANDARD_ARGS(NAME (DEFAULT_MSG|"Custom failure message") VAR1 ... )
#    This macro is intended to be used in FindXXX.cmake modules files.
#    It handles the REQUIRED and QUIET argument to FIND_PACKAGE() and
#    it also sets the <UPPERCASED_NAME>_FOUND variable.
#    The package is found if all variables listed are TRUE.
#    Example:
#
#    FIND_PACKAGE_HANDLE_STANDARD_ARGS(LibXml2 DEFAULT_MSG LIBXML2_LIBRARIES LIBXML2_INCLUDE_DIR)
#
#    LibXml2 is considered to be found, if both LIBXML2_LIBRARIES and 
#    LIBXML2_INCLUDE_DIR are valid. Then also LIBXML2_FOUND is set to TRUE.
#    If it is not found and REQUIRED was used, it fails with FATAL_ERROR, 
#    independent whether QUIET was used or not.
#    If it is found, the location is reported using the VAR1 argument, so 
#    here a message "Found LibXml2: /usr/lib/libxml2.so" will be printed out.
#    If the second argument is DEFAULT_MSG, the message in the failure case will 
#    be "Could NOT find LibXml2", if you don't like this message you can specify
#    your own custom failure message there.

MACRO(FIND_PACKAGE_HANDLE_STANDARD_ARGS _NAME _FAIL_MSG _VAR1 )

  IF("${_FAIL_MSG}" STREQUAL "DEFAULT_MSG")
    IF (${_NAME}_FIND_REQUIRED)
      SET(_FAIL_MESSAGE "Could not find REQUIRED package ${_NAME}")
    ELSE (${_NAME}_FIND_REQUIRED)
      SET(_FAIL_MESSAGE "Could not find OPTIONAL package ${_NAME}")
    ENDIF (${_NAME}_FIND_REQUIRED)
  ELSE("${_FAIL_MSG}" STREQUAL "DEFAULT_MSG")
    SET(_FAIL_MESSAGE "${_FAIL_MSG}")
  ENDIF("${_FAIL_MSG}" STREQUAL "DEFAULT_MSG")

  STRING(TOUPPER ${_NAME} _NAME_UPPER)

  SET(${_NAME_UPPER}_FOUND TRUE)
  IF(NOT ${_VAR1})
    SET(${_NAME_UPPER}_FOUND FALSE)
  ENDIF(NOT ${_VAR1})

  FOREACH(_CURRENT_VAR ${ARGN})
    IF(NOT ${_CURRENT_VAR})
      SET(${_NAME_UPPER}_FOUND FALSE)
    ENDIF(NOT ${_CURRENT_VAR})
  ENDFOREACH(_CURRENT_VAR)

  IF (${_NAME_UPPER}_FOUND)
    IF (NOT ${_NAME}_FIND_QUIETLY)
        MESSAGE(STATUS "Found ${_NAME}: ${${_VAR1}}")
    ENDIF (NOT ${_NAME}_FIND_QUIETLY)
  ELSE (${_NAME_UPPER}_FOUND)
    IF (${_NAME}_FIND_REQUIRED)
        MESSAGE(FATAL_ERROR "${_FAIL_MESSAGE}")
    ELSE (${_NAME}_FIND_REQUIRED)
      IF (NOT ${_NAME}_FIND_QUIETLY)
        MESSAGE(STATUS "${_FAIL_MESSAGE}")
      ENDIF (NOT ${_NAME}_FIND_QUIETLY)
    ENDIF (${_NAME}_FIND_REQUIRED)
  ENDIF (${_NAME_UPPER}_FOUND)
ENDMACRO(FIND_PACKAGE_HANDLE_STANDARD_ARGS)

__EOF__
======================== FILE ./cmake/FindPackageMultipass.cmake
FILE: ./cmake/FindPackageMultipass.cmake
# PackageMultipass - this module defines two macros
#
# FIND_PACKAGE_MULTIPASS (Name CURRENT
#  STATES VAR0 VAR1 ...
#  DEPENDENTS DEP0 DEP1 ...)
#
#  This function creates a cache entry <UPPERCASED-Name>_CURRENT which
#  the user can set to "NO" to trigger a reconfiguration of the package.
#  The first time this function is called, the values of
#  <UPPERCASED-Name>_VAR0, ... are saved.  If <UPPERCASED-Name>_CURRENT
#  is false or if any STATE has changed since the last time
#  FIND_PACKAGE_MULTIPASS() was called, then CURRENT will be set to "NO",
#  otherwise CURRENT will be "YES".  IF not CURRENT, then
#  <UPPERCASED-Name>_DEP0, ... will be FORCED to NOTFOUND.
#  Example:
#    find_path (FOO_DIR include/foo.h)
#    FIND_PACKAGE_MULTIPASS (Foo foo_current
#      STATES DIR
#      DEPENDENTS INCLUDES LIBRARIES)
#    if (NOT foo_current)
#      # Make temporary files, run programs, etc, to determine FOO_INCLUDES and FOO_LIBRARIES
#    endif (NOT foo_current)
#
# MULTIPASS_SOURCE_RUNS (Name INCLUDES LIBRARIES SOURCE RUNS LANGUAGE)
#  Always runs the given test, use this when you need to re-run tests
#  because parent variables have made old cache entries stale. The LANGUAGE
#  variable is either C or CXX indicating which compiler the test should
#  use. 
# MULTIPASS_C_SOURCE_RUNS (Name INCLUDES LIBRARIES SOURCE RUNS)
#  DEPRECATED! This is only included for backwards compatability. Use
#  the more general MULTIPASS_SOURCE_RUNS instead.
#  Always runs the given test, use this when you need to re-run tests
#  because parent variables have made old cache entries stale.

macro (FIND_PACKAGE_MULTIPASS _name _current)
  string (TOUPPER ${_name} _NAME)
  set (_args ${ARGV})
  list (REMOVE_AT _args 0 1)

  set (_states_current "YES")
  list (GET _args 0 _cmd)
  if (_cmd STREQUAL "STATES")
    list (REMOVE_AT _args 0)
    list (GET _args 0 _state)
    while (_state AND NOT _state STREQUAL "DEPENDENTS")
      # The name of the stored value for the given state
      set (_stored_var PACKAGE_MULTIPASS_${_NAME}_${_state})
      if (NOT "${${_stored_var}}" STREQUAL "${${_NAME}_${_state}}")
	set (_states_current "NO")
      endif (NOT "${${_stored_var}}" STREQUAL "${${_NAME}_${_state}}")
      set (${_stored_var} "${${_NAME}_${_state}}" CACHE INTERNAL "Stored state for ${_name}." FORCE)
      list (REMOVE_AT _args 0)
      list (GET _args 0 _state)
    endwhile (_state AND NOT _state STREQUAL "DEPENDENTS")
  endif (_cmd STREQUAL "STATES")

  set (_stored ${_NAME}_CURRENT)
  if (NOT ${_stored})
    set (${_stored} "YES" CACHE BOOL "Is the configuration for ${_name} current?  Set to \"NO\" to reconfigure." FORCE)
    set (_states_current "NO")
  endif (NOT ${_stored})

  set (${_current} ${_states_current})
  if (NOT ${_current} AND PACKAGE_MULTIPASS_${_name}_CALLED)
    message (STATUS "Clearing ${_name} dependent variables")
    # Clear all the dependent variables so that the module can reset them
    list (GET _args 0 _cmd)
    if (_cmd STREQUAL "DEPENDENTS")
      list (REMOVE_AT _args 0)
      foreach (dep ${_args})
	set (${_NAME}_${dep} "NOTFOUND" CACHE INTERNAL "Cleared" FORCE)
      endforeach (dep)
    endif (_cmd STREQUAL "DEPENDENTS")
    set (${_NAME}_FOUND "NOTFOUND" CACHE INTERNAL "Cleared" FORCE)
  endif ()
  set (PACKAGE_MULTIPASS_${name}_CALLED YES CACHE INTERNAL "Private" FORCE)
endmacro (FIND_PACKAGE_MULTIPASS)


macro (MULTIPASS_SOURCE_RUNS includes libraries source runs language)
  include (Check${language}SourceRuns)
  # This is a ridiculous hack.  CHECK_${language}_SOURCE_* thinks that if the
  # *name* of the return variable doesn't change, then the test does
  # not need to be re-run.  We keep an internal count which we
  # increment to guarantee that every test name is unique.  If we've
  # gotten here, then the configuration has changed enough that the
  # test *needs* to be rerun.
  if (NOT MULTIPASS_TEST_COUNT)
    set (MULTIPASS_TEST_COUNT 00)
  endif (NOT MULTIPASS_TEST_COUNT)
  math (EXPR _tmp "${MULTIPASS_TEST_COUNT} + 1") # Why can't I add to a cache variable?
  set (MULTIPASS_TEST_COUNT ${_tmp} CACHE INTERNAL "Unique test ID")
  set (testname MULTIPASS_TEST_${MULTIPASS_TEST_COUNT}_${runs})
  set (CMAKE_REQUIRED_INCLUDES ${includes})
  set (CMAKE_REQUIRED_LIBRARIES ${libraries})
  if(${language} STREQUAL "C")
    check_c_source_runs ("${source}" ${testname})
  elseif(${language} STREQUAL "CXX")
    check_cxx_source_runs ("${source}" ${testname})
  endif()
  set (${runs} "${${testname}}")
endmacro (MULTIPASS_SOURCE_RUNS)

macro (MULTIPASS_C_SOURCE_RUNS includes libraries source runs)
  multipass_source_runs("${includes}" "${libraries}" "${source}" ${runs} "C")
endmacro (MULTIPASS_C_SOURCE_RUNS)
__EOF__
======================== FILE ./cmake/FindUDUNITS2.cmake
FILE: ./cmake/FindUDUNITS2.cmake
# - Find UDUNITS2
# Find the native UDUNITS2 includes and library
#
#  UDUNITS2_INCLUDES    - where to find udunits2.h
#  UDUNITS2_LIBRARIES   - libraries to link with
#  UDUNITS2_FOUND       - True if UDUNITS2 was found.

if (UDUNITS2_INCLUDES)
  # Already in cache, be silent
  set (UDUNITS2_FIND_QUIETLY TRUE)
endif (UDUNITS2_INCLUDES)

find_path (UDUNITS2_INCLUDES udunits2.h
  HINTS "${UDUNITS2_ROOT}/include" "$ENV{UDUNITS2_ROOT}/include"
  PATH_SUFFIXES "udunits2"
  DOC "Path to udunits2.h")

# UDUNITS2 headers might be in .../include or .../include/udunits2.
# We try both.
if (${UDUNITS2_INCLUDES} MATCHES "udunits2/?$")
  string(REGEX REPLACE "/include/udunits2/?$" "/lib"
    UDUNITS2_LIB_HINT ${UDUNITS2_INCLUDES})
else()
  string(REGEX REPLACE "/include/?$" "/lib"
    UDUNITS2_LIB_HINT ${UDUNITS2_INCLUDES})
endif()

find_library (UDUNITS2_LIBRARIES
  NAMES udunits2
  HINTS ${UDUNITS2_LIB_HINT})

set(UDUNITS2_TEST_SRC "
#include <udunits2.h>

int main(int argc, char **argv) {
  ut_system *s = ut_read_xml(NULL);
  ut_free_system(s);
  return 0;
}
")

if ((NOT UDUNITS2_LIBRARIES) OR (NOT UDUNITS2_INCLUDES))
  message(STATUS "Trying to find UDUNITS-2 using LD_LIBRARY_PATH (we're desperate)...")

  file(TO_CMAKE_PATH "$ENV{LD_LIBRARY_PATH}" LD_LIBRARY_PATH)

  find_library(UDUNITS2_LIBRARIES
    NAMES udunits2
    HINTS ${LD_LIBRARY_PATH})

  if (UDUNITS2_LIBRARIES)
    get_filename_component(UDUNITS2_LIB_DIR ${UDUNITS2_LIBRARIES} PATH)
    string(REGEX REPLACE "/lib/?$" "/include"
      UDUNITS2_H_HINT ${UDUNITS2_LIB_DIR})

    find_path (UDUNITS2_INCLUDES udunits2.h
      HINTS ${UDUNITS2_H_HINT}
      PATH_SUFFIXES "udunits2"
      DOC "Path to udunits2.h")
  endif()
endif()

include (CheckCSourceRuns)

set(CMAKE_REQUIRED_INCLUDES ${UDUNITS2_INCLUDES})
set(CMAKE_REQUIRED_LIBRARIES ${UDUNITS2_LIBRARIES})
check_c_source_runs("${UDUNITS2_TEST_SRC}" UDUNITS2_WORKS_WITHOUT_EXPAT)

if(${UDUNITS2_WORKS_WITHOUT_EXPAT})
  message(STATUS "UDUNITS-2 does not require expat")
else()
  find_package(EXPAT REQUIRED)

  set(CMAKE_REQUIRED_INCLUDES ${UDUNITS2_INCLUDES} ${EXPAT_INCLUDE_DIRS})
  set(CMAKE_REQUIRED_LIBRARIES ${UDUNITS2_LIBRARIES} ${EXPAT_LIBRARIES})
  check_c_source_runs("${UDUNITS2_TEST_SRC}" UDUNITS2_WORKS_WITH_EXPAT)

  if(NOT ${UDUNITS2_WORKS_WITH_EXPAT})
    message(FATAL_ERROR "UDUNITS-2 does not seem to work with or without expat")
  endif()

  message(STATUS "UDUNITS-2 requires EXPAT")
  set (UDUNITS2_LIBRARIES "${UDUNITS2_LIBRARIES};${EXPAT_LIBRARIES}" CACHE STRING "" FORCE)
endif()

# handle the QUIETLY and REQUIRED arguments and set UDUNITS2_FOUND to TRUE if
# all listed variables are TRUE
include (FindPackageHandleStandardArgs)
find_package_handle_standard_args (UDUNITS2 DEFAULT_MSG UDUNITS2_LIBRARIES UDUNITS2_INCLUDES)

mark_as_advanced (UDUNITS2_LIBRARIES UDUNITS2_INCLUDES)
__EOF__
======================== FILE ./cmake/GLINT2_CMake_macros.cmake
FILE: ./cmake/GLINT2_CMake_macros.cmake
# This file contains CMake macros used in the root CMakeLists.txt

macro(glint2_find_prerequisites)
  # PETSc
  find_package (PETSc)
  if (NOT PETSC_FOUND)
    get_filename_component(pcc ${PETSC_COMPILER} REALPATH)
    get_filename_component(cc ${CMAKE_C_COMPILER} REALPATH)
    if (NOT ${pcc} STREQUAL ${cc})
      message(WARNING
        "PETSC_COMPILER does not match CMAKE_C_COMPILER\n"
	"  PETSC_COMPILER=${PETSC_COMPILER}\n"
	"  CMAKE_C_COMPILER=${CMAKE_C_COMPILER}\n"
	"Try running \n"
	"  rm CMakeCache.txt && cmake -DCMAKE_C_COMPILER=${PETSC_COMPILER} ${CMAKE_SOURCE_DIR}")
    endif()
    message(FATAL_ERROR  "GLINT2 configuration failed: PETSc was not found.")
  endif()

  if ((DEFINED PETSC_VERSION) AND (PETSC_VERSION VERSION_LESS 3.3))
    # Force GLINT2 to look for PETSc again if the version we just found
    # is too old:
    set(PETSC_CURRENT "OFF" CACHE BOOL "" FORCE)
    # Stop with an error message.
    message(FATAL_ERROR "\nGLINT2 requires PETSc version 3.3 or newer (found ${PETSC_VERSION}).\n\n")
  endif()

  # MPI
  # Use the PETSc compiler as a hint when looking for an MPI compiler
  # FindMPI.cmake changed between 2.8.4 and 2.8.5, so we try to support both...
  if (${CMAKE_VERSION} VERSION_LESS "2.8.5")
    set (MPI_COMPILER ${PETSC_COMPILER} CACHE FILEPATH "MPI compiler. Used only to detect MPI compilation flags.")
    find_package (MPI REQUIRED)

    set (MPI_C_INCLUDE_PATH "${MPI_INCLUDE_PATH}" CACHE STRING "MPI include directories (semicolon-separated list)")
    set (MPI_C_LIBRARIES "${MPI_LIBRARY};${MPI_EXTRA_LIBRARY}" CACHE STRING "MPI libraries (semicolon-separated list)")
    mark_as_advanced(MPI_C_INCLUDE_PATH MPI_C_LIBRARIES)
    message (STATUS
      "Note: Please upgrade CMake to version 2.8.5 or later if the build fails with undefined symbols related to MPI.")
  else ()
    set (MPI_C_COMPILER ${PETSC_COMPILER} CACHE FILEPATH "MPI compiler. Used only to detect MPI compilation flags.")
    find_package (MPI REQUIRED)
  endif()

  # Other required libraries
  find_package (UDUNITS2 REQUIRED)
  find_package (GSL REQUIRED)
  find_package (NetCDF REQUIRED)
  find_package (CGAL REQUIRED)

message("CGAL " ${CGAL_INCLUDE_DIR})
message("CGAL " ${CGAL_LIBRARIES})


  # Optional libraries
#  find_package (PNetCDF)
  find_package (FFTW REQUIRED)
  find_package (PROJ4)
#  find_package (TAO)
#  # Try to find netcdf_par.h. We assume that NetCDF was compiled with
#  # parallel I/O if this header is present.
#  find_file(NETCDF_PAR_H netcdf_par.h HINTS ${NETCDF_INCLUDES} NO_DEFAULT_PATH)

#  # Set default values for build options
#  if (NOT NETCDF_PAR_H)
#    set (Glint2_USE_PARALLEL_NETCDF4 OFF CACHE BOOL "Enables parallel NetCDF-4 I/O." FORCE)
#    message(STATUS "Selected NetCDF library does not support parallel I/O.")
#  endif()
#
#  if (NOT PNETCDF_FOUND)
#    set (Glint2_USE_PNETCDF OFF CACHE BOOL "Enables parallel NetCDF-3 I/O using PnetCDF." FORCE)
#  endif()
#
#  if (NOT PROJ4_FOUND)
#    set (Glint2_USE_PROJ4 OFF CACHE BOOL "Use Proj.4 to compute cell areas, longitude, and latitude." FORCE)
#  endif()
#
#  if (NOT TAO_FOUND)
#    set (Glint2_USE_TAO OFF CACHE BOOL "Use TAO in inverse solvers." FORCE)
#    message(STATUS  "TAO not found. Inverse solvers using the TAO library will not be built.")
#  endif()

  # Use option values to set compiler and linker flags
  set (Glint2_EXTERNAL_LIBS "")

#  # optional
#  if (Glint2_USE_PROJ4)
    include_directories (${PROJ4_INCLUDES})
    list (APPEND Glint2_EXTERNAL_LIBS ${PROJ4_LIBRARIES})
#  endif()

#  if (Glint2_USE_PNETCDF)
#    include_directories (${PNETCDF_INCLUDES})
#    list (APPEND Glint2_EXTERNAL_LIBS ${PNETCDF_LIBRARIES})
#  endif()

#  if (Glint2_USE_TAO)
#    include_directories (${TAO_INCLUDE_DIRS})
#    list (APPEND Glint2_EXTERNAL_LIBS ${TAO_LIBRARIES})
#  endif()

endmacro()

macro(glint2_set_dependencies)

  # Set include and library directories for *required* libraries.
  include_directories (
    ${PETSC_INCLUDES}
    ${FFTW_INCLUDE_DIRS}
    ${FFTW_INCLUDES}
    ${GSL_INCLUDES}
    ${UDUNITS2_INCLUDES}
    ${NETCDF_INCLUDES}
    ${MPI_C_INCLUDE_PATH})

  list (APPEND Glint2_EXTERNAL_LIBS
    ${PETSC_LIBRARIES}
    ${UDUNITS2_LIBRARIES}
    ${FFTW_LIBRARIES}
    ${GSL_LIBRARIES}
    ${NETCDF_LIBRARIES}
    ${MPI_C_LIBRARIES})

  # Hide distracting CMake variables
  mark_as_advanced(file_cmd MPI_LIBRARY MPI_EXTRA_LIBRARY
    CMAKE_OSX_ARCHITECTURES CMAKE_OSX_DEPLOYMENT_TARGET CMAKE_OSX_SYSROOT
    MAKE_EXECUTABLE TAO_DIR TAO_INCLUDE_DIRS NETCDF_PAR_H)

endmacro()

macro(glint2_set_dependencies)

include_directories(
	${PROJECT_SOURCE_DIR}/slib
	${Boost_INCLUDE_DIRS}
    ${NETCDF_INCLUDES} ${NETCDF_INCLUDES_CXX} ${NETCDF_INCLUDES_F77}
    ${BLITZ++_INCLUDE_DIR}
    ${GMP_INCLUDE_DIR}
    ${CGAL_INCLUDE_DIR}
	# These should be optional
	${PISM_INCLUDE_DIRS}
	${GALAHAD_INCLUDE_DIRS})

list (APPEND Glint2_EXTERNAL_LIBS
	${Boost_LIBRARIES}
	${NETCDF_LIBRARIES}
	${BLITZ++_LIBRARY}
	${GMP_LIBRARY}
	${CGAL_LIBRARY}
	# These should be optional
	${PISM_LIBRARIES}
	${GALAHAD_LIBRARIES})

endmacro()
__EOF__
======================== FILE ./cmake/GetPrerequisites.cmake
FILE: ./cmake/GetPrerequisites.cmake
#.rst:
# GetPrerequisites
# ----------------
#
# Functions to analyze and list executable file prerequisites.
#
# This module provides functions to list the .dll, .dylib or .so files
# that an executable or shared library file depends on.  (Its
# prerequisites.)
#
# It uses various tools to obtain the list of required shared library
# files:
#
# ::
#
#    dumpbin (Windows)
#    objdump (MinGW on Windows)
#    ldd (Linux/Unix)
#    otool (Mac OSX)
#
# The following functions are provided by this module:
#
# ::
#
#    get_prerequisites
#    list_prerequisites
#    list_prerequisites_by_glob
#    gp_append_unique
#    is_file_executable
#    gp_item_default_embedded_path
#      (projects can override with gp_item_default_embedded_path_override)
#    gp_resolve_item
#      (projects can override with gp_resolve_item_override)
#    gp_resolved_file_type
#      (projects can override with gp_resolved_file_type_override)
#    gp_file_type
#
# Requires CMake 2.6 or greater because it uses function, break, return
# and PARENT_SCOPE.
#
# ::
#
#   GET_PREREQUISITES(<target> <prerequisites_var> <exclude_system> <recurse>
#                     <exepath> <dirs> [<rpaths>])
#
# Get the list of shared library files required by <target>.  The list
# in the variable named <prerequisites_var> should be empty on first
# entry to this function.  On exit, <prerequisites_var> will contain the
# list of required shared library files.
#
# <target> is the full path to an executable file.  <prerequisites_var>
# is the name of a CMake variable to contain the results.
# <exclude_system> must be 0 or 1 indicating whether to include or
# exclude "system" prerequisites.  If <recurse> is set to 1 all
# prerequisites will be found recursively, if set to 0 only direct
# prerequisites are listed.  <exepath> is the path to the top level
# executable used for @executable_path replacment on the Mac.  <dirs> is
# a list of paths where libraries might be found: these paths are
# searched first when a target without any path info is given.  Then
# standard system locations are also searched: PATH, Framework
# locations, /usr/lib...
#
# ::
#
#   LIST_PREREQUISITES(<target> [<recurse> [<exclude_system> [<verbose>]]])
#
# Print a message listing the prerequisites of <target>.
#
# <target> is the name of a shared library or executable target or the
# full path to a shared library or executable file.  If <recurse> is set
# to 1 all prerequisites will be found recursively, if set to 0 only
# direct prerequisites are listed.  <exclude_system> must be 0 or 1
# indicating whether to include or exclude "system" prerequisites.  With
# <verbose> set to 0 only the full path names of the prerequisites are
# printed, set to 1 extra informatin will be displayed.
#
# ::
#
#   LIST_PREREQUISITES_BY_GLOB(<glob_arg> <glob_exp>)
#
# Print the prerequisites of shared library and executable files
# matching a globbing pattern.  <glob_arg> is GLOB or GLOB_RECURSE and
# <glob_exp> is a globbing expression used with "file(GLOB" or
# "file(GLOB_RECURSE" to retrieve a list of matching files.  If a
# matching file is executable, its prerequisites are listed.
#
# Any additional (optional) arguments provided are passed along as the
# optional arguments to the list_prerequisites calls.
#
# ::
#
#   GP_APPEND_UNIQUE(<list_var> <value>)
#
# Append <value> to the list variable <list_var> only if the value is
# not already in the list.
#
# ::
#
#   IS_FILE_EXECUTABLE(<file> <result_var>)
#
# Return 1 in <result_var> if <file> is a binary executable, 0
# otherwise.
#
# ::
#
#   GP_ITEM_DEFAULT_EMBEDDED_PATH(<item> <default_embedded_path_var>)
#
# Return the path that others should refer to the item by when the item
# is embedded inside a bundle.
#
# Override on a per-project basis by providing a project-specific
# gp_item_default_embedded_path_override function.
#
# ::
#
#   GP_RESOLVE_ITEM(<context> <item> <exepath> <dirs> <resolved_item_var>
#                   [<rpaths>])
#
# Resolve an item into an existing full path file.
#
# Override on a per-project basis by providing a project-specific
# gp_resolve_item_override function.
#
# ::
#
#   GP_RESOLVED_FILE_TYPE(<original_file> <file> <exepath> <dirs> <type_var>
#                         [<rpaths>])
#
# Return the type of <file> with respect to <original_file>.  String
# describing type of prerequisite is returned in variable named
# <type_var>.
#
# Use <exepath> and <dirs> if necessary to resolve non-absolute <file>
# values -- but only for non-embedded items.
#
# Possible types are:
#
# ::
#
#    system
#    local
#    embedded
#    other
#
# Override on a per-project basis by providing a project-specific
# gp_resolved_file_type_override function.
#
# ::
#
#   GP_FILE_TYPE(<original_file> <file> <type_var>)
#
# Return the type of <file> with respect to <original_file>.  String
# describing type of prerequisite is returned in variable named
# <type_var>.
#
# Possible types are:
#
# ::
#
#    system
#    local
#    embedded
#    other

#=============================================================================
# Copyright 2008-2009 Kitware, Inc.
#
# Distributed under the OSI-approved BSD License (the "License");
# see accompanying file Copyright.txt for details.
#
# This software is distributed WITHOUT ANY WARRANTY; without even the
# implied warranty of MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.
# See the License for more information.
#=============================================================================
# (To distribute this file outside of CMake, substitute the full
#  License text for the above reference.)

function(gp_append_unique list_var value)
  set(contains 0)

  foreach(item ${${list_var}})
    if(item STREQUAL "${value}")
      set(contains 1)
      break()
    endif()
  endforeach()

  if(NOT contains)
    set(${list_var} ${${list_var}} "${value}" PARENT_SCOPE)
  endif()
endfunction()


function(is_file_executable file result_var)
  #
  # A file is not executable until proven otherwise:
  #
  set(${result_var} 0 PARENT_SCOPE)

  get_filename_component(file_full "${file}" ABSOLUTE)
  string(TOLOWER "${file_full}" file_full_lower)

  # If file name ends in .exe on Windows, *assume* executable:
  #
  if(WIN32 AND NOT UNIX)
    if("${file_full_lower}" MATCHES "\\.exe$")
      set(${result_var} 1 PARENT_SCOPE)
      return()
    endif()

    # A clause could be added here that uses output or return value of dumpbin
    # to determine ${result_var}. In 99%+? practical cases, the exe name
    # match will be sufficient...
    #
  endif()

  # Use the information returned from the Unix shell command "file" to
  # determine if ${file_full} should be considered an executable file...
  #
  # If the file command's output contains "executable" and does *not* contain
  # "text" then it is likely an executable suitable for prerequisite analysis
  # via the get_prerequisites macro.
  #
  if(UNIX)
    if(NOT file_cmd)
      find_program(file_cmd "file")
      mark_as_advanced(file_cmd)
    endif()

    if(file_cmd)
      execute_process(COMMAND "${file_cmd}" "${file_full}"
        OUTPUT_VARIABLE file_ov
        OUTPUT_STRIP_TRAILING_WHITESPACE
        )

      # Replace the name of the file in the output with a placeholder token
      # (the string " _file_full_ ") so that just in case the path name of
      # the file contains the word "text" or "executable" we are not fooled
      # into thinking "the wrong thing" because the file name matches the
      # other 'file' command output we are looking for...
      #
      string(REPLACE "${file_full}" " _file_full_ " file_ov "${file_ov}")
      string(TOLOWER "${file_ov}" file_ov)

      #message(STATUS "file_ov='${file_ov}'")
      if("${file_ov}" MATCHES "executable")
        #message(STATUS "executable!")
        if("${file_ov}" MATCHES "text")
          #message(STATUS "but text, so *not* a binary executable!")
        else()
          set(${result_var} 1 PARENT_SCOPE)
          return()
        endif()
      endif()

      # Also detect position independent executables on Linux,
      # where "file" gives "shared object ... (uses shared libraries)"
      if("${file_ov}" MATCHES "shared object.*\(uses shared libs\)")
        set(${result_var} 1 PARENT_SCOPE)
        return()
      endif()

      # "file" version 5.22 does not print "(used shared libraries)"
      # but uses "interpreter"
      if("${file_ov}" MATCHES "shared object.*interpreter")
        set(${result_var} 1 PARENT_SCOPE)
        return()
      endif()

    else()
      message(STATUS "warning: No 'file' command, skipping execute_process...")
    endif()
  endif()
endfunction()


function(gp_item_default_embedded_path item default_embedded_path_var)

  # On Windows and Linux, "embed" prerequisites in the same directory
  # as the executable by default:
  #
  set(path "@executable_path")
  set(overridden 0)

  # On the Mac, relative to the executable depending on the type
  # of the thing we are embedding:
  #
  if(APPLE)
    #
    # The assumption here is that all executables in the bundle will be
    # in same-level-directories inside the bundle. The parent directory
    # of an executable inside the bundle should be MacOS or a sibling of
    # MacOS and all embedded paths returned from here will begin with
    # "@executable_path/../" and will work from all executables in all
    # such same-level-directories inside the bundle.
    #

    # By default, embed things right next to the main bundle executable:
    #
    set(path "@executable_path/../../Contents/MacOS")

    # Embed .dylibs right next to the main bundle executable:
    #
    if(item MATCHES "\\.dylib$")
      set(path "@executable_path/../MacOS")
      set(overridden 1)
    endif()

    # Embed frameworks in the embedded "Frameworks" directory (sibling of MacOS):
    #
    if(NOT overridden)
      if(item MATCHES "[^/]+\\.framework/")
        set(path "@executable_path/../Frameworks")
        set(overridden 1)
      endif()
    endif()
  endif()

  # Provide a hook so that projects can override the default embedded location
  # of any given library by whatever logic they choose:
  #
  if(COMMAND gp_item_default_embedded_path_override)
    gp_item_default_embedded_path_override("${item}" path)
  endif()

  set(${default_embedded_path_var} "${path}" PARENT_SCOPE)
endfunction()


function(gp_resolve_item context item exepath dirs resolved_item_var)
  set(resolved 0)
  set(resolved_item "${item}")
  if(ARGC GREATER 5)
    set(rpaths "${ARGV5}")
  else()
    set(rpaths "")
  endif()

  # Is it already resolved?
  #
  if(IS_ABSOLUTE "${resolved_item}" AND EXISTS "${resolved_item}")
    set(resolved 1)
  endif()

  if(NOT resolved)
    if(item MATCHES "^@executable_path")
      #
      # @executable_path references are assumed relative to exepath
      #
      string(REPLACE "@executable_path" "${exepath}" ri "${item}")
      get_filename_component(ri "${ri}" ABSOLUTE)

      if(EXISTS "${ri}")
        #message(STATUS "info: embedded item exists (${ri})")
        set(resolved 1)
        set(resolved_item "${ri}")
      else()
        message(STATUS "warning: embedded item does not exist '${ri}'")
      endif()
    endif()
  endif()

  if(NOT resolved)
    if(item MATCHES "^@loader_path")
      #
      # @loader_path references are assumed relative to the
      # PATH of the given "context" (presumably another library)
      #
      get_filename_component(contextpath "${context}" PATH)
      string(REPLACE "@loader_path" "${contextpath}" ri "${item}")
      get_filename_component(ri "${ri}" ABSOLUTE)

      if(EXISTS "${ri}")
        #message(STATUS "info: embedded item exists (${ri})")
        set(resolved 1)
        set(resolved_item "${ri}")
      else()
        message(STATUS "warning: embedded item does not exist '${ri}'")
      endif()
    endif()
  endif()

  if(NOT resolved)
    if(item MATCHES "^@rpath")
      #
      # @rpath references are relative to the paths built into the binaries with -rpath
      # We handle this case like we do for other Unixes
      #
      string(REPLACE "@rpath/" "" norpath_item "${item}")

      set(ri "ri-NOTFOUND")
      find_file(ri "${norpath_item}" ${exepath} ${dirs} ${rpaths} NO_DEFAULT_PATH)
      if(ri)
        #message(STATUS "info: 'find_file' in exepath/dirs/rpaths (${ri})")
        set(resolved 1)
        set(resolved_item "${ri}")
        set(ri "ri-NOTFOUND")
      endif()

    endif()
  endif()

  if(NOT resolved)
    set(ri "ri-NOTFOUND")
    find_file(ri "${item}" ${exepath} ${dirs} NO_DEFAULT_PATH)
    find_file(ri "${item}" ${exepath} ${dirs} /usr/lib)
    if(ri)
      #message(STATUS "info: 'find_file' in exepath/dirs (${ri})")
      set(resolved 1)
      set(resolved_item "${ri}")
      set(ri "ri-NOTFOUND")
    endif()
  endif()

  if(NOT resolved)
    if(item MATCHES "[^/]+\\.framework/")
      set(fw "fw-NOTFOUND")
      find_file(fw "${item}"
        "~/Library/Frameworks"
        "/Library/Frameworks"
        "/System/Library/Frameworks"
      )
      if(fw)
        #message(STATUS "info: 'find_file' found framework (${fw})")
        set(resolved 1)
        set(resolved_item "${fw}")
        set(fw "fw-NOTFOUND")
      endif()
    endif()
  endif()

  # Using find_program on Windows will find dll files that are in the PATH.
  # (Converting simple file names into full path names if found.)
  #
  if(WIN32 AND NOT UNIX)
  if(NOT resolved)
    set(ri "ri-NOTFOUND")
    find_program(ri "${item}" PATHS "${exepath};${dirs}" NO_DEFAULT_PATH)
    find_program(ri "${item}" PATHS "${exepath};${dirs}")
    if(ri)
      #message(STATUS "info: 'find_program' in exepath/dirs (${ri})")
      set(resolved 1)
      set(resolved_item "${ri}")
      set(ri "ri-NOTFOUND")
    endif()
  endif()
  endif()

  # Provide a hook so that projects can override item resolution
  # by whatever logic they choose:
  #
  if(COMMAND gp_resolve_item_override)
    gp_resolve_item_override("${context}" "${item}" "${exepath}" "${dirs}" resolved_item resolved)
  endif()

  if(NOT resolved)
    message(STATUS "
warning: cannot resolve item '${item}'

  possible problems:
    need more directories?
    need to use InstallRequiredSystemLibraries?
    run in install tree instead of build tree?
")
#    message(STATUS "
#******************************************************************************
#warning: cannot resolve item '${item}'
#
#  possible problems:
#    need more directories?
#    need to use InstallRequiredSystemLibraries?
#    run in install tree instead of build tree?
#
#    context='${context}'
#    item='${item}'
#    exepath='${exepath}'
#    dirs='${dirs}'
#    resolved_item_var='${resolved_item_var}'
#******************************************************************************
#")
  endif()

  set(${resolved_item_var} "${resolved_item}" PARENT_SCOPE)
endfunction()


function(gp_resolved_file_type original_file file exepath dirs type_var)
  if(ARGC GREATER 5)
    set(rpaths "${ARGV5}")
  else()
    set(rpaths "")
  endif()
  #message(STATUS "**")

  if(NOT IS_ABSOLUTE "${original_file}")
    message(STATUS "warning: gp_resolved_file_type expects absolute full path for first arg original_file")
  endif()

  set(is_embedded 0)
  set(is_local 0)
  set(is_system 0)

  set(resolved_file "${file}")

  if("${file}" MATCHES "^@(executable|loader)_path")
    set(is_embedded 1)
  endif()

  if(NOT is_embedded)
    if(NOT IS_ABSOLUTE "${file}")
      gp_resolve_item("${original_file}" "${file}" "${exepath}" "${dirs}" resolved_file "${rpaths}")
    endif()

    string(TOLOWER "${original_file}" original_lower)
    string(TOLOWER "${resolved_file}" lower)

    if(UNIX)
      if(resolved_file MATCHES "^(/lib/|/lib32/|/lib64/|/usr/lib/|/usr/lib32/|/usr/lib64/|/usr/X11R6/|/usr/bin/)")
        set(is_system 1)
      endif()
    endif()

    if(APPLE)
      if(resolved_file MATCHES "^(/System/Library/|/usr/lib/)")
        set(is_system 1)
      endif()
    endif()

    if(WIN32)
      string(TOLOWER "$ENV{SystemRoot}" sysroot)
      file(TO_CMAKE_PATH "${sysroot}" sysroot)

      string(TOLOWER "$ENV{windir}" windir)
      file(TO_CMAKE_PATH "${windir}" windir)

      if(lower MATCHES "^(${sysroot}/sys(tem|wow)|${windir}/sys(tem|wow)|(.*/)*msvc[^/]+dll)")
        set(is_system 1)
      endif()

      if(UNIX)
        # if cygwin, we can get the properly formed windows paths from cygpath
        find_program(CYGPATH_EXECUTABLE cygpath)

        if(CYGPATH_EXECUTABLE)
          execute_process(COMMAND ${CYGPATH_EXECUTABLE} -W
                          OUTPUT_VARIABLE env_windir
                          OUTPUT_STRIP_TRAILING_WHITESPACE)
          execute_process(COMMAND ${CYGPATH_EXECUTABLE} -S
                          OUTPUT_VARIABLE env_sysdir
                          OUTPUT_STRIP_TRAILING_WHITESPACE)
          string(TOLOWER "${env_windir}" windir)
          string(TOLOWER "${env_sysdir}" sysroot)

          if(lower MATCHES "^(${sysroot}/sys(tem|wow)|${windir}/sys(tem|wow)|(.*/)*msvc[^/]+dll)")
            set(is_system 1)
          endif()
        endif()
      endif()
    endif()

    if(NOT is_system)
      get_filename_component(original_path "${original_lower}" PATH)
      get_filename_component(path "${lower}" PATH)
      if(original_path STREQUAL path)
        set(is_local 1)
      else()
        string(LENGTH "${original_path}/" original_length)
        string(LENGTH "${lower}" path_length)
        if(${path_length} GREATER ${original_length})
          string(SUBSTRING "${lower}" 0 ${original_length} path)
          if("${original_path}/" STREQUAL path)
            set(is_embedded 1)
          endif()
        endif()
      endif()
    endif()
  endif()

  # Return type string based on computed booleans:
  #
  set(type "other")

  if(is_system)
    set(type "system")
  elseif(is_embedded)
    set(type "embedded")
  elseif(is_local)
    set(type "local")
  endif()

  #message(STATUS "gp_resolved_file_type: '${file}' '${resolved_file}'")
  #message(STATUS "                type: '${type}'")

  if(NOT is_embedded)
    if(NOT IS_ABSOLUTE "${resolved_file}")
      if(lower MATCHES "^msvc[^/]+dll" AND is_system)
        message(STATUS "info: non-absolute msvc file '${file}' returning type '${type}'")
      else()
        message(STATUS "warning: gp_resolved_file_type non-absolute file '${file}' returning type '${type}' -- possibly incorrect")
      endif()
    endif()
  endif()

  # Provide a hook so that projects can override the decision on whether a
  # library belongs to the system or not by whatever logic they choose:
  #
  if(COMMAND gp_resolved_file_type_override)
    gp_resolved_file_type_override("${resolved_file}" type)
  endif()

  set(${type_var} "${type}" PARENT_SCOPE)

  #message(STATUS "**")
endfunction()


function(gp_file_type original_file file type_var)
  if(NOT IS_ABSOLUTE "${original_file}")
    message(STATUS "warning: gp_file_type expects absolute full path for first arg original_file")
  endif()

  get_filename_component(exepath "${original_file}" PATH)

  set(type "")
  gp_resolved_file_type("${original_file}" "${file}" "${exepath}" "" type)

  set(${type_var} "${type}" PARENT_SCOPE)
endfunction()


function(get_prerequisites target prerequisites_var exclude_system recurse exepath dirs)
  set(verbose 0)
  set(eol_char "E")
  if(ARGC GREATER 6)
    set(rpaths "${ARGV6}")
  else()
    set(rpaths "")
  endif()

  if(NOT IS_ABSOLUTE "${target}")
    message("warning: target '${target}' is not absolute...")
  endif()

  if(NOT EXISTS "${target}")
    message("warning: target '${target}' does not exist...")
  endif()

  set(gp_cmd_paths ${gp_cmd_paths}
    "C:/Program Files/Microsoft Visual Studio 9.0/VC/bin"
    "C:/Program Files (x86)/Microsoft Visual Studio 9.0/VC/bin"
    "C:/Program Files/Microsoft Visual Studio 8/VC/BIN"
    "C:/Program Files (x86)/Microsoft Visual Studio 8/VC/BIN"
    "C:/Program Files/Microsoft Visual Studio .NET 2003/VC7/BIN"
    "C:/Program Files (x86)/Microsoft Visual Studio .NET 2003/VC7/BIN"
    "/usr/local/bin"
    "/usr/bin"
    )

  # <setup-gp_tool-vars>
  #
  # Try to choose the right tool by default. Caller can set gp_tool prior to
  # calling this function to force using a different tool.
  #
  if(NOT gp_tool)
    set(gp_tool "ldd")

    if(APPLE)
      set(gp_tool "otool")
    endif()

    if(WIN32 AND NOT UNIX) # This is how to check for cygwin, har!
      find_program(gp_dumpbin "dumpbin" PATHS ${gp_cmd_paths})
      if(gp_dumpbin)
        set(gp_tool "dumpbin")
      else() # Try harder. Maybe we're on MinGW
        set(gp_tool "objdump")
      endif()
    endif()
  endif()

  find_program(gp_cmd ${gp_tool} PATHS ${gp_cmd_paths})

  if(NOT gp_cmd)
    message(STATUS "warning: could not find '${gp_tool}' - cannot analyze prerequisites...")
    return()
  endif()

  if(gp_tool STREQUAL "ldd")
    set(gp_cmd_args "")
    set(gp_regex "^[\t ]*[^\t ]+ => ([^\t\(]+) .*${eol_char}$")
    set(gp_regex_error "not found${eol_char}$")
    set(gp_regex_fallback "^[\t ]*([^\t ]+) => ([^\t ]+).*${eol_char}$")
    set(gp_regex_cmp_count 1)
  elseif(gp_tool STREQUAL "otool")
    set(gp_cmd_args "-L")
    set(gp_regex "^\t([^\t]+) \\(compatibility version ([0-9]+.[0-9]+.[0-9]+), current version ([0-9]+.[0-9]+.[0-9]+)\\)${eol_char}$")
    set(gp_regex_error "")
    set(gp_regex_fallback "")
    set(gp_regex_cmp_count 3)
  elseif(gp_tool STREQUAL "dumpbin")
    set(gp_cmd_args "/dependents")
    set(gp_regex "^    ([^ ].*[Dd][Ll][Ll])${eol_char}$")
    set(gp_regex_error "")
    set(gp_regex_fallback "")
    set(gp_regex_cmp_count 1)
  elseif(gp_tool STREQUAL "objdump")
    set(gp_cmd_args "-p")
    set(gp_regex "^\t*DLL Name: (.*\\.[Dd][Ll][Ll])${eol_char}$")
    set(gp_regex_error "")
    set(gp_regex_fallback "")
    set(gp_regex_cmp_count 1)
  else()
    message(STATUS "warning: gp_tool='${gp_tool}' is an unknown tool...")
    message(STATUS "CMake function get_prerequisites needs more code to handle '${gp_tool}'")
    message(STATUS "Valid gp_tool values are dumpbin, ldd, objdump and otool.")
    return()
  endif()


  if(gp_tool STREQUAL "dumpbin")
    # When running dumpbin, it also needs the "Common7/IDE" directory in the
    # PATH. It will already be in the PATH if being run from a Visual Studio
    # command prompt. Add it to the PATH here in case we are running from a
    # different command prompt.
    #
    get_filename_component(gp_cmd_dir "${gp_cmd}" PATH)
    get_filename_component(gp_cmd_dlls_dir "${gp_cmd_dir}/../../Common7/IDE" ABSOLUTE)
    # Use cmake paths as a user may have a PATH element ending with a backslash.
    # This will escape the list delimiter and create havoc!
    if(EXISTS "${gp_cmd_dlls_dir}")
      # only add to the path if it is not already in the path
      set(gp_found_cmd_dlls_dir 0)
      file(TO_CMAKE_PATH "$ENV{PATH}" env_path)
      foreach(gp_env_path_element ${env_path})
        if(gp_env_path_element STREQUAL gp_cmd_dlls_dir)
          set(gp_found_cmd_dlls_dir 1)
        endif()
      endforeach()

      if(NOT gp_found_cmd_dlls_dir)
        file(TO_NATIVE_PATH "${gp_cmd_dlls_dir}" gp_cmd_dlls_dir)
        set(ENV{PATH} "$ENV{PATH};${gp_cmd_dlls_dir}")
      endif()
    endif()
  endif()
  #
  # </setup-gp_tool-vars>

  if(gp_tool STREQUAL "ldd")
    set(old_ld_env "$ENV{LD_LIBRARY_PATH}")
    set(new_ld_env "${exepath}")
    foreach(dir ${dirs})
      set(new_ld_env "${new_ld_env}:${dir}")
    endforeach()
    set(ENV{LD_LIBRARY_PATH} "${new_ld_env}:$ENV{LD_LIBRARY_PATH}")
  endif()


  # Track new prerequisites at each new level of recursion. Start with an
  # empty list at each level:
  #
  set(unseen_prereqs)

  # Run gp_cmd on the target:
  #
  execute_process(
    COMMAND ${gp_cmd} ${gp_cmd_args} ${target}
    OUTPUT_VARIABLE gp_cmd_ov
    )

  if(gp_tool STREQUAL "ldd")
    set(ENV{LD_LIBRARY_PATH} "${old_ld_env}")
  endif()

  if(verbose)
    message(STATUS "<RawOutput cmd='${gp_cmd} ${gp_cmd_args} ${target}'>")
    message(STATUS "gp_cmd_ov='${gp_cmd_ov}'")
    message(STATUS "</RawOutput>")
  endif()

  get_filename_component(target_dir "${target}" PATH)

  # Convert to a list of lines:
  #
  string(REPLACE ";" "\\;" candidates "${gp_cmd_ov}")
  string(REPLACE "\n" "${eol_char};" candidates "${candidates}")

  # check for install id and remove it from list, since otool -L can include a
  # reference to itself
  set(gp_install_id)
  if(gp_tool STREQUAL "otool")
    execute_process(
      COMMAND otool -D ${target}
      OUTPUT_VARIABLE gp_install_id_ov
      )
    # second line is install name
    string(REGEX REPLACE ".*:\n" "" gp_install_id "${gp_install_id_ov}")
    if(gp_install_id)
      # trim
      string(REGEX MATCH "[^\n ].*[^\n ]" gp_install_id "${gp_install_id}")
      #message("INSTALL ID is \"${gp_install_id}\"")
    endif()
  endif()

  # Analyze each line for file names that match the regular expression:
  #
  foreach(candidate ${candidates})
  if("${candidate}" MATCHES "${gp_regex}")

    # Extract information from each candidate:
    if(gp_regex_error AND "${candidate}" MATCHES "${gp_regex_error}")
      string(REGEX REPLACE "${gp_regex_fallback}" "\\1" raw_item "${candidate}")
    else()
      string(REGEX REPLACE "${gp_regex}" "\\1" raw_item "${candidate}")
    endif()

    if(gp_regex_cmp_count GREATER 1)
      string(REGEX REPLACE "${gp_regex}" "\\2" raw_compat_version "${candidate}")
      string(REGEX REPLACE "^([0-9]+)\\.([0-9]+)\\.([0-9]+)$" "\\1" compat_major_version "${raw_compat_version}")
      string(REGEX REPLACE "^([0-9]+)\\.([0-9]+)\\.([0-9]+)$" "\\2" compat_minor_version "${raw_compat_version}")
      string(REGEX REPLACE "^([0-9]+)\\.([0-9]+)\\.([0-9]+)$" "\\3" compat_patch_version "${raw_compat_version}")
    endif()

    if(gp_regex_cmp_count GREATER 2)
      string(REGEX REPLACE "${gp_regex}" "\\3" raw_current_version "${candidate}")
      string(REGEX REPLACE "^([0-9]+)\\.([0-9]+)\\.([0-9]+)$" "\\1" current_major_version "${raw_current_version}")
      string(REGEX REPLACE "^([0-9]+)\\.([0-9]+)\\.([0-9]+)$" "\\2" current_minor_version "${raw_current_version}")
      string(REGEX REPLACE "^([0-9]+)\\.([0-9]+)\\.([0-9]+)$" "\\3" current_patch_version "${raw_current_version}")
    endif()

    # Use the raw_item as the list entries returned by this function. Use the
    # gp_resolve_item function to resolve it to an actual full path file if
    # necessary.
    #
    set(item "${raw_item}")

    # Add each item unless it is excluded:
    #
    set(add_item 1)

    if(item STREQUAL gp_install_id)
      set(add_item 0)
    endif()

    if(add_item AND ${exclude_system})
      set(type "")
      gp_resolved_file_type("${target}" "${item}" "${exepath}" "${dirs}" type "${rpaths}")

      if(type STREQUAL "system")
        set(add_item 0)
      endif()
    endif()

    if(add_item)
      list(LENGTH ${prerequisites_var} list_length_before_append)
      gp_append_unique(${prerequisites_var} "${item}")
      list(LENGTH ${prerequisites_var} list_length_after_append)

      if(${recurse})
        # If item was really added, this is the first time we have seen it.
        # Add it to unseen_prereqs so that we can recursively add *its*
        # prerequisites...
        #
        # But first: resolve its name to an absolute full path name such
        # that the analysis tools can simply accept it as input.
        #
        if(NOT list_length_before_append EQUAL list_length_after_append)
          gp_resolve_item("${target}" "${item}" "${exepath}" "${dirs}" resolved_item "${rpaths}")
          set(unseen_prereqs ${unseen_prereqs} "${resolved_item}")
        endif()
      endif()
    endif()
  else()
    if(verbose)
      message(STATUS "ignoring non-matching line: '${candidate}'")
    endif()
  endif()
  endforeach()

  list(LENGTH ${prerequisites_var} prerequisites_var_length)
  if(prerequisites_var_length GREATER 0)
    list(SORT ${prerequisites_var})
  endif()
  if(${recurse})
    set(more_inputs ${unseen_prereqs})
    foreach(input ${more_inputs})
      get_prerequisites("${input}" ${prerequisites_var} ${exclude_system} ${recurse} "${exepath}" "${dirs}" "${rpaths}")
    endforeach()
  endif()

  set(${prerequisites_var} ${${prerequisites_var}} PARENT_SCOPE)
endfunction()


function(list_prerequisites target)
  if(ARGC GREATER 1 AND NOT "${ARGV1}" STREQUAL "")
    set(all "${ARGV1}")
  else()
    set(all 1)
  endif()

  if(ARGC GREATER 2 AND NOT "${ARGV2}" STREQUAL "")
    set(exclude_system "${ARGV2}")
  else()
    set(exclude_system 0)
  endif()

  if(ARGC GREATER 3 AND NOT "${ARGV3}" STREQUAL "")
    set(verbose "${ARGV3}")
  else()
    set(verbose 0)
  endif()

  set(count 0)
  set(count_str "")
  set(print_count "${verbose}")
  set(print_prerequisite_type "${verbose}")
  set(print_target "${verbose}")
  set(type_str "")

  get_filename_component(exepath "${target}" PATH)

  set(prereqs "")
  get_prerequisites("${target}" prereqs ${exclude_system} ${all} "${exepath}" "")

  if(print_target)
    message(STATUS "File '${target}' depends on:")
  endif()

  foreach(d ${prereqs})
    math(EXPR count "${count} + 1")

    if(print_count)
      set(count_str "${count}. ")
    endif()

    if(print_prerequisite_type)
      gp_file_type("${target}" "${d}" type)
      set(type_str " (${type})")
    endif()

    message(STATUS "${count_str}${d}${type_str}")
  endforeach()
endfunction()


function(list_prerequisites_by_glob glob_arg glob_exp)
  message(STATUS "=============================================================================")
  message(STATUS "List prerequisites of executables matching ${glob_arg} '${glob_exp}'")
  message(STATUS "")
  file(${glob_arg} file_list ${glob_exp})
  foreach(f ${file_list})
    is_file_executable("${f}" is_f_executable)
    if(is_f_executable)
      message(STATUS "=============================================================================")
      list_prerequisites("${f}" ${ARGN})
      message(STATUS "")
    endif()
  endforeach()
endfunction()

__EOF__
======================== FILE ./cmake/LibFindMacros.cmake
FILE: ./cmake/LibFindMacros.cmake
# Version 1.0 (2013-04-12)
# Public Domain, originally written by Lasse Krkkinen <tronic@zi.fi>
# Published at http://www.cmake.org/Wiki/CMake:How_To_Find_Libraries

# If you improve the script, please modify the forementioned wiki page because
# I no longer maintain my scripts (hosted as static files at zi.fi). Feel free
# to remove this entire header if you use real version control instead.

# Changelog:
# 2013-04-12  Added version number (1.0) and this header, no other changes
# 2009-10-08  Originally published


# Works the same as find_package, but forwards the "REQUIRED" and "QUIET" arguments
# used for the current package. For this to work, the first parameter must be the
# prefix of the current package, then the prefix of the new package etc, which are
# passed to find_package.
macro (libfind_package PREFIX)
  set (LIBFIND_PACKAGE_ARGS ${ARGN})
  if (${PREFIX}_FIND_QUIETLY)
    set (LIBFIND_PACKAGE_ARGS ${LIBFIND_PACKAGE_ARGS} QUIET)
  endif (${PREFIX}_FIND_QUIETLY)
  if (${PREFIX}_FIND_REQUIRED)
    set (LIBFIND_PACKAGE_ARGS ${LIBFIND_PACKAGE_ARGS} REQUIRED)
  endif (${PREFIX}_FIND_REQUIRED)
  find_package(${LIBFIND_PACKAGE_ARGS})
endmacro (libfind_package)

# CMake developers made the UsePkgConfig system deprecated in the same release (2.6)
# where they added pkg_check_modules. Consequently I need to support both in my scripts
# to avoid those deprecated warnings. Here's a helper that does just that.
# Works identically to pkg_check_modules, except that no checks are needed prior to use.
macro (libfind_pkg_check_modules PREFIX PKGNAME)
  if (${CMAKE_MAJOR_VERSION} EQUAL 2 AND ${CMAKE_MINOR_VERSION} EQUAL 4)
    include(UsePkgConfig)
    pkgconfig(${PKGNAME} ${PREFIX}_INCLUDE_DIRS ${PREFIX}_LIBRARY_DIRS ${PREFIX}_LDFLAGS ${PREFIX}_CFLAGS)
  else (${CMAKE_MAJOR_VERSION} EQUAL 2 AND ${CMAKE_MINOR_VERSION} EQUAL 4)
    find_package(PkgConfig)
    if (PKG_CONFIG_FOUND)
      pkg_check_modules(${PREFIX} ${PKGNAME})
    endif (PKG_CONFIG_FOUND)
  endif (${CMAKE_MAJOR_VERSION} EQUAL 2 AND ${CMAKE_MINOR_VERSION} EQUAL 4)
endmacro (libfind_pkg_check_modules)

# Do the final processing once the paths have been detected.
# If include dirs are needed, ${PREFIX}_PROCESS_INCLUDES should be set to contain
# all the variables, each of which contain one include directory.
# Ditto for ${PREFIX}_PROCESS_LIBS and library files.
# Will set ${PREFIX}_FOUND, ${PREFIX}_INCLUDE_DIRS and ${PREFIX}_LIBRARIES.
# Also handles errors in case library detection was required, etc.
macro (libfind_process PREFIX)
  # Skip processing if already processed during this run
  if (NOT ${PREFIX}_FOUND)
    # Start with the assumption that the library was found
    set (${PREFIX}_FOUND TRUE)

    # Process all includes and set _FOUND to false if any are missing
    foreach (i ${${PREFIX}_PROCESS_INCLUDES})
      if (${i})
        set (${PREFIX}_INCLUDE_DIRS ${${PREFIX}_INCLUDE_DIRS} ${${i}})
        mark_as_advanced(${i})
      else (${i})
        set (${PREFIX}_FOUND FALSE)
      endif (${i})
    endforeach (i)

    # Process all libraries and set _FOUND to false if any are missing
    foreach (i ${${PREFIX}_PROCESS_LIBS})
      if (${i})
        set (${PREFIX}_LIBRARIES ${${PREFIX}_LIBRARIES} ${${i}})
        mark_as_advanced(${i})
      else (${i})
        set (${PREFIX}_FOUND FALSE)
      endif (${i})
    endforeach (i)

    # Print message and/or exit on fatal error
    if (${PREFIX}_FOUND)
      if (NOT ${PREFIX}_FIND_QUIETLY)
        message (STATUS "Found ${PREFIX} ${${PREFIX}_VERSION}")
      endif (NOT ${PREFIX}_FIND_QUIETLY)
    else (${PREFIX}_FOUND)
      if (${PREFIX}_FIND_REQUIRED)
        foreach (i ${${PREFIX}_PROCESS_INCLUDES} ${${PREFIX}_PROCESS_LIBS})
          message("${i}=${${i}}")
        endforeach (i)
        message (FATAL_ERROR "Required library ${PREFIX} NOT FOUND.\nInstall the library (dev version) and try again. If the library is already installed, use ccmake to set the missing variables manually.")
      endif (${PREFIX}_FIND_REQUIRED)
    endif (${PREFIX}_FOUND)
  endif (NOT ${PREFIX}_FOUND)
endmacro (libfind_process)

macro(libfind_library PREFIX basename)
  set(TMP "")
  if(MSVC80)
    set(TMP -vc80)
  endif(MSVC80)
  if(MSVC90)
    set(TMP -vc90)
  endif(MSVC90)
  set(${PREFIX}_LIBNAMES ${basename}${TMP})
  if(${ARGC} GREATER 2)
    set(${PREFIX}_LIBNAMES ${basename}${TMP}-${ARGV2})
    string(REGEX REPLACE "\\." "_" TMP ${${PREFIX}_LIBNAMES})
    set(${PREFIX}_LIBNAMES ${${PREFIX}_LIBNAMES} ${TMP})
  endif(${ARGC} GREATER 2)
  find_library(${PREFIX}_LIBRARY
    NAMES ${${PREFIX}_LIBNAMES}
    PATHS ${${PREFIX}_PKGCONF_LIBRARY_DIRS}
  )
endmacro(libfind_library)

__EOF__
======================== FILE ./cmake/ModelE_CMake_macros.cmake
FILE: ./cmake/ModelE_CMake_macros.cmake
# This file contains CMake macros used in the root CMakeLists.txt

macro(modele_find_prerequisites)
  if (${USE_FEXCEPTION})
    find_package(FException REQUIRED)
  endif()

  if (COMPILE_MODEL)
    find_package (MPI REQUIRED)

    if (${USE_PNETCDF})
        find_package(PNetCDF REQUIRED)
#        find_package(NetCDF_CXX REQUIRED)
    endif()

  endif()
  
  # Other required libraries
  find_package (NetCDF4_Fortran REQUIRED)

  # Use option values to set compiler and linker flags
  set (ModelE_EXTERNAL_LIBS "")

endmacro()

macro(modele_set_dependencies)

  # Set include and library directories for *required* libraries.
  include_directories(${NETCDF4_FORTRAN_INCLUDE_DIR})

  if (COMPILE_MODEL)
    include_directories(${MPI_Fortran_INCLUDE_PATH})
    list (APPEND ModelE_EXTERNAL_LIBS ${MPI_Fortran_LIBRARIES})
  endif()

  list (APPEND ModelE_EXTERNAL_LIBS ${NETCDF4_FORTRAN_LIBRARY})

  if (${USE_FEXCEPTION})
    include_directories(${FEXCEPTION_INCLUDE_DIR})
    list(APPEND ModelE_EXTERNAL_LIBS ${FEXCEPTION_LIBRARY})
  endif()

  # Hide distracting CMake variables
  mark_as_advanced(file_cmd MPI_LIBRARY MPI_EXTRA_LIBRARY
    CMAKE_OSX_ARCHITECTURES CMAKE_OSX_DEPLOYMENT_TARGET CMAKE_OSX_SYSROOT
    MAKE_EXECUTABLE TAO_DIR TAO_INCLUDE_DIRS NETCDF_PAR_H)

  if (USE_PNETCDF MATCHES YES)
    include_directories(${PNETCDF_INCLUDE_DIR})
#    include_directories(${NETCDF_CXX_INCLUDE_DIR})
    list (APPEND ModelE_EXTERNAL_LIBS ${PNETCDF_LIBRARY})# ${NETCDF_CXX_LIBRARY})
  endif()

endmacro()


macro(aux_set_dependencies)

  # Set include and library directories for *required* libraries.
  include_directories(${NETCDF4_FORTRAN_INCLUDE_DIR})

  list (APPEND AUX_EXTERNAL_LIBS ${NETCDF4_FORTRAN_LIBRARY})

endmacro()

macro(mkdiags_set_dependencies)

  # Set include and library directories for *required* libraries.
  include_directories(${NETCDF4_FORTRAN_INCLUDE_DIR})

  list (APPEND MKDIAGS_EXTERNAL_LIBS ${NETCDF4_FORTRAN_LIBRARY})

  # Hide distracting CMake variables
  mark_as_advanced(file_cmd MPI_LIBRARY MPI_EXTRA_LIBRARY
    CMAKE_OSX_ARCHITECTURES CMAKE_OSX_DEPLOYMENT_TARGET CMAKE_OSX_SYSROOT
    MAKE_EXECUTABLE TAO_DIR TAO_INCLUDE_DIRS NETCDF_PAR_H)

endmacro()

# ------------------------------------------
macro(modele_set_flags)
   # Get ARCH information
  execute_process( 
    COMMAND uname -m 
    COMMAND tr -d '\n' 
    OUTPUT_VARIABLE ARCHITECTURE)

  set(CFLAGS "-O2 -m64")
  if (CMAKE_SYSTEM_NAME MATCHES Linux)
    add_definitions(-DMACHINE_Linux)
  else()
    add_definitions(-DMACHINE_MAC)
  endif()
  if (MPI MATCHES "YES")
    add_definitions(-DMPI_LOOKUP_HACK)
  endif()

# ===================================== Intel compiler flags
  if (${CMAKE_Fortran_COMPILER_ID} STREQUAL "Intel")

    set(CPP /usr/local/other/SLES11/gcc/4.9.1/bin/gcc -E)

    add_definitions(-DCOMPILER_Intel8 -DCONVERT_BIGENDIAN)

    set (CMAKE_Fortran_FLAGS_RELEASE "${CPPFLAGS} -fpp -O2 -g -convert big_endian \
        -ftz -assume protect_parens -fp-model strict -warn nousage -assume realloc_lhs")
    set (CMAKE_Fortran_FLAGS_DEBUG   "${CPPFLAGS} -fpp -O0 -g -traceback \
        -ftz -convert big_endian \
        -assume protect_parens -fp-model strict -warn nousage -assume realloc_lhs")

    if (CMAKE_BUILD_TYPE MATCHES Release)
      set(CMAKE_Fortran_FLAGS ${CMAKE_Fortran_FLAGS_RELEASE})
    else()
      set(CMAKE_Fortran_FLAGS ${CMAKE_Fortran_FLAGS_DEBUG})
      set (LFLAGS  "-O2 -ftz")
    endif()

    if ("${COMPILE_WITH_TRAPS}" STREQUAL "YES")
      set(CMAKE_Fortran_FLAGS "${CMAKE_Fortran_FLAGS} -CB -fpe0 \
           -check uninit -ftrapuv -traceback")
      set(LFLAGS "${LFLAGS} -CB -fpe0 -check uninit -ftrapuv")
    endif()

    set(R8 "-r8")
    set(EXTENDED_SOURCE "-extend_source")

# ===================================== GNU compiler flags
  elseif(${CMAKE_Fortran_COMPILER_ID} STREQUAL GNU)

    set (CPP ${CMAKE_C_COMPILER} -E)

    set(CPPFLAGS "${CPPFLAGS} -cpp")
    add_definitions(-DCOMPILER_G95)
    # This breaks if you try to wrap the long line in the obvious way.
    set (CMAKE_Fortran_FLAGS_RELEASE "${CPPFLAGS} -O2 -g -fconvert=big-endian -fno-range-check -ffree-line-length-none")
    set (CMAKE_Fortran_FLAGS_DEBUG "${CPPFLAGS} -O -g -fbacktrace -fconvert=big-endian -fno-range-check -ffree-line-length-none -fcheck=bounds -fcheck=do -fcheck=mem -fcheck=recursion")


    if (CMAKE_BUILD_TYPE MATCHES Release)
      set(CMAKE_Fortran_FLAGS ${CMAKE_Fortran_FLAGS_RELEASE})
    else()
      set(CMAKE_Fortran_FLAGS ${CMAKE_Fortran_FLAGS_DEBUG})
    endif()

    if ("${COMPILE_WITH_TRAPS}" STREQUAL "YES")
      set(CMAKE_Fortran_FLAGS
           "${CMAKE_Fortran_FLAGS} -fbounds-check -fcheck-array-temporaries -ffpe-trap=invalid,zero,overflow")
    endif()

    set(LFLAGS  "")
    set(R8 "-fdefault-real-8 -fdefault-double-8")
    set(EXTENDED_SOURCE "-ffixed-line-length-132")

  endif()

endmacro()
__EOF__
======================== FILE ./cmake/PISM_CMake_macros.cmake
FILE: ./cmake/PISM_CMake_macros.cmake
# This file contains CMake macros used in the root CMakeLists.txt

# Set CMake variables to enable rpath
macro(pism_use_rpath)
  ## Use full RPATH, with this setting Pism libraries cannot be moved after installation
  ## but the correct libraries will always be found regardless of LD_LIBRARY_PATH
  ## in use, i.e. don't skip the full RPATH for the build tree
  set (CMAKE_SKIP_BUILD_RPATH FALSE)
  # when building, don't use the install RPATH already
  # (but later on when installing)
  set (CMAKE_BUILD_WITH_INSTALL_RPATH FALSE) 
  # the RPATH to be used when installing
  set (CMAKE_INSTALL_RPATH "${CMAKE_INSTALL_PREFIX}/${Pism_LIB_DIR}")
  # add the automatically determined parts of the RPATH
  # which point to directories outside the build tree to the install RPATH
  set (CMAKE_INSTALL_RPATH_USE_LINK_PATH TRUE)

  # Mac OS X install_name fix:
  set (CMAKE_INSTALL_NAME_DIR "${CMAKE_INSTALL_PREFIX}/${Pism_LIB_DIR}")
endmacro(pism_use_rpath)

# Set CMake variables to disable rpath
macro(pism_dont_use_rpath)
  set (CMAKE_SKIP_BUILD_RPATH TRUE)
  set (CMAKE_BUILD_WITH_INSTALL_RPATH TRUE) 
  set (CMAKE_INSTALL_RPATH "${CMAKE_INSTALL_PREFIX}/${Pism_LIB_DIR}")
  set (CMAKE_INSTALL_RPATH_USE_LINK_PATH FALSE)
endmacro(pism_dont_use_rpath)

# Set CMake variables to ensure that everything is static
macro(pism_strictly_static)
  set (CMAKE_SKIP_RPATH ON CACHE BOOL "Disable RPATH completely")
  set (CMAKE_FIND_LIBRARY_SUFFIXES .a)

  set (BUILD_SHARED_LIBS OFF CACHE BOOL "Build shared Pism libraries" FORCE)

  SET(CMAKE_SHARED_LIBRARY_LINK_C_FLAGS "") # get rid of -rdynamic
  SET(CMAKE_SHARED_LIBRARY_LINK_CXX_FLAGS "") # ditto

  set_property(GLOBAL PROPERTY LINK_SEARCH_END_STATIC 1)
  set(CMAKE_EXE_LINK_DYNAMIC_C_FLAGS)       # remove -Wl,-Bdynamic
  set(CMAKE_EXE_LINK_DYNAMIC_CXX_FLAGS)

  pism_dont_use_rpath()
endmacro(pism_strictly_static)

# Set the revision tag if PISM was checked out using Git.
macro(pism_set_revision_tag_git)
  if (NOT Pism_VERSION)
    if (EXISTS ${Pism_SOURCE_DIR}/.git)
      find_program (GIT_EXECUTABLE git DOC "Git executable")
      mark_as_advanced(GIT_EXECUTABLE)
      execute_process (COMMAND ${GIT_EXECUTABLE} describe --always --match v?.?
        WORKING_DIRECTORY ${Pism_SOURCE_DIR}
        OUTPUT_VARIABLE Pism_VERSION
        OUTPUT_STRIP_TRAILING_WHITESPACE)
    endif (EXISTS ${Pism_SOURCE_DIR}/.git)
  endif(NOT Pism_VERSION)
endmacro(pism_set_revision_tag_git)

# Set the revision tag if PISM was checked out using Subversion.
macro(pism_set_revision_tag_svn)
  if (NOT Pism_VERSION)
    if (EXISTS ${Pism_SOURCE_DIR}/.svn)
      find_package(Subversion)
      if (SUBVERSION_FOUND)
        Subversion_WC_INFO(${Pism_SOURCE_DIR}/src "Pism")
        set(Pism_VERSION "${Pism_WC_LAST_CHANGED_DATE}")
      endif(SUBVERSION_FOUND)
    endif(EXISTS ${Pism_SOURCE_DIR}/.svn)
  endif(NOT Pism_VERSION)
endmacro(pism_set_revision_tag_svn)

# Set the PISM revision tag
macro(pism_set_revision_tag)
  # Git
  pism_set_revision_tag_git()

  # Subversion
  pism_set_revision_tag_svn()

  # Otherwise...
  if (NOT Pism_VERSION)
    set (Pism_VERSION "no-version-control")
  endif (NOT Pism_VERSION)

  set (Pism_REVISION_TAG "${Pism_BRANCH} ${Pism_VERSION}")

  message(STATUS "Configuring PISM version '${Pism_REVISION_TAG}'")
endmacro(pism_set_revision_tag)

macro(pism_set_install_prefix)
  # Allow setting a custom install prefix using the PISM_PREFIX environment variable.
  string (LENGTH "$ENV{PISM_INSTALL_PREFIX}" INSTALL_PREFIX_LENGTH)
  if (INSTALL_PREFIX_LENGTH)
    set (CMAKE_INSTALL_PREFIX $ENV{PISM_INSTALL_PREFIX} CACHE PATH "PISM install prefix" FORCE)
    message (STATUS "Setting PISM install prefix to ${CMAKE_INSTALL_PREFIX}.")
  endif()

  # Define the directory structure.
  set (Pism_BIN_DIR "bin")
  set (Pism_LIB_DIR "lib/pism")
  set (Pism_DOC_DIR "share/doc/pism")
endmacro()

# Set pedantic compiler flags
macro(pism_set_pedantic_flags)
  set (DEFAULT_PEDANTIC_FLAGS "-pedantic -Wall -Wextra -Wno-cast-qual -Wundef -Wshadow -Wpointer-arith -Wno-cast-align -Wwrite-strings -Wno-conversion -Wsign-compare -Wno-redundant-decls -Winline -Wno-long-long -Wmissing-format-attribute -Wmissing-noreturn -Wpacked -Wdisabled-optimization -Wmultichar -Wformat-nonliteral -Wformat-security -Wformat-y2k -Wendif-labels -Winvalid-pch -Wmissing-field-initializers -Wvariadic-macros -Wstrict-aliasing -funit-at-a-time")
  set (DEFAULT_PEDANTIC_CFLAGS "${DEFAULT_PEDANTIC_FLAGS} -std=c99")
  set (DEFAULT_PEDANTIC_CXXFLAGS "${DEFAULT_PEDANTIC_FLAGS} -Woverloaded-virtual")
  set (PEDANTIC_CFLAGS ${DEFAULT_PEDANTIC_CFLAGS} CACHE STRING "Compiler flags to enable pedantic warnings")
  set (PEDANTIC_CXXFLAGS ${DEFAULT_PEDANTIC_CXXFLAGS} CACHE STRING "Compiler flags to enable pedantic warnings for C++")
  mark_as_advanced (PEDANTIC_CFLAGS PEDANTIC_CXXFLAGS)
  set (CMAKE_C_FLAGS_DEBUG "-g ${PEDANTIC_CFLAGS}")
  set (CMAKE_CXX_FLAGS_DEBUG "-g ${PEDANTIC_CXXFLAGS}")
endmacro(pism_set_pedantic_flags)

# Make sure that we don't create .petscrc in $HOME, because this would affect
# all PISM runs by the current user.
macro(pism_check_build_dir_location)
  file (TO_CMAKE_PATH $ENV{HOME} home_dir)
  file (TO_CMAKE_PATH ${PROJECT_BINARY_DIR} build_dir)

  if (${home_dir} STREQUAL ${build_dir})
    message (FATAL_ERROR
      "\n"
      "The build directory is the same as your $HOME!\n"
      "Buiding PISM here would result in a big mess. "
      "Please create a special build directory and run cmake from there.\n")
  endif()
endmacro()

macro(pism_find_prerequisites)
  # PETSc
  find_package (PETSc)
  if (NOT PETSC_FOUND)
    get_filename_component(pcc ${PETSC_COMPILER} REALPATH)
    get_filename_component(cc ${CMAKE_C_COMPILER} REALPATH)
    if (NOT ${pcc} STREQUAL ${cc})
      message(WARNING
        "PETSC_COMPILER does not match CMAKE_C_COMPILER\n"
	"  PETSC_COMPILER=${PETSC_COMPILER}\n"
	"  CMAKE_C_COMPILER=${CMAKE_C_COMPILER}\n"
	"Try running \n"
	"  rm CMakeCache.txt && cmake -DCMAKE_C_COMPILER=${PETSC_COMPILER} ${CMAKE_SOURCE_DIR}")
    endif()
    message(FATAL_ERROR  "PISM configuration failed: PETSc was not found.")
  endif()

  if ((DEFINED PETSC_VERSION) AND (PETSC_VERSION VERSION_LESS 3.3))
    # Force PISM to look for PETSc again if the version we just found
    # is too old:
    set(PETSC_CURRENT "OFF" CACHE BOOL "" FORCE)
    # Stop with an error message.
    message(FATAL_ERROR "\nPISM requires PETSc version 3.3 or newer (found ${PETSC_VERSION}).\n\n")
  endif()

  # MPI
  # Use the PETSc compiler as a hint when looking for an MPI compiler
  # FindMPI.cmake changed between 2.8.4 and 2.8.5, so we try to support both...
  if (${CMAKE_VERSION} VERSION_LESS "2.8.5")
    set (MPI_COMPILER ${PETSC_COMPILER} CACHE FILEPATH "MPI compiler. Used only to detect MPI compilation flags.")
    find_package (MPI REQUIRED)

    set (MPI_C_INCLUDE_PATH "${MPI_INCLUDE_PATH}" CACHE STRING "MPI include directories (semicolon-separated list)")
    set (MPI_C_LIBRARIES "${MPI_LIBRARY};${MPI_EXTRA_LIBRARY}" CACHE STRING "MPI libraries (semicolon-separated list)")
    mark_as_advanced(MPI_C_INCLUDE_PATH MPI_C_LIBRARIES)
    message (STATUS
      "Note: Please upgrade CMake to version 2.8.5 or later if the build fails with undefined symbols related to MPI.")
  else ()
    set (MPI_C_COMPILER ${PETSC_COMPILER} CACHE FILEPATH "MPI compiler. Used only to detect MPI compilation flags.")
    find_package (MPI REQUIRED)
  endif()

  # Other required libraries
  find_package (UDUNITS2 REQUIRED)
  find_package (GSL REQUIRED)
  find_package (NetCDF REQUIRED)

  # Optional libraries
  find_package (PNetCDF)
  find_package (FFTW REQUIRED)
  find_package (PROJ4)
  find_package (TAO)
  # Try to find netcdf_par.h. We assume that NetCDF was compiled with
  # parallel I/O if this header is present.
  find_file(NETCDF_PAR_H netcdf_par.h HINTS ${NETCDF_INCLUDES} NO_DEFAULT_PATH)

  # Set default values for build options
  if (NOT NETCDF_PAR_H)
    set (Pism_USE_PARALLEL_NETCDF4 OFF CACHE BOOL "Enables parallel NetCDF-4 I/O." FORCE)
    message(STATUS "Selected NetCDF library does not support parallel I/O.")
  endif()

  if (NOT PNETCDF_FOUND)
    set (Pism_USE_PNETCDF OFF CACHE BOOL "Enables parallel NetCDF-3 I/O using PnetCDF." FORCE)
  endif()

  if (NOT PROJ4_FOUND)
    set (Pism_USE_PROJ4 OFF CACHE BOOL "Use Proj.4 to compute cell areas, longitude, and latitude." FORCE)
  endif()

  if (NOT TAO_FOUND)
    set (Pism_USE_TAO OFF CACHE BOOL "Use TAO in inverse solvers." FORCE)
    message(STATUS  "TAO not found. Inverse solvers using the TAO library will not be built.")
  endif()

  # Use option values to set compiler and linker flags
  set (Pism_EXTERNAL_LIBS "")

  # optional
  if (Pism_USE_PROJ4)
    include_directories (${PROJ4_INCLUDES})
    list (APPEND Pism_EXTERNAL_LIBS ${PROJ4_LIBRARIES})
  endif()

  if (Pism_USE_PNETCDF)
    include_directories (${PNETCDF_INCLUDES})
    list (APPEND Pism_EXTERNAL_LIBS ${PNETCDF_LIBRARIES})
  endif()

  if (Pism_USE_TAO)
    include_directories (${TAO_INCLUDE_DIRS})
    list (APPEND Pism_EXTERNAL_LIBS ${TAO_LIBRARIES})
  endif()

endmacro()

macro(pism_set_dependencies)

  # Set include and library directories for *required* libraries.
  include_directories (
    ${PETSC_INCLUDES}
    ${FFTW_INCLUDE_DIRS}
    ${FFTW_INCLUDES}
    ${GSL_INCLUDES}
    ${UDUNITS2_INCLUDES}
    ${NETCDF_INCLUDES}
    ${MPI_C_INCLUDE_PATH})

  list (APPEND Pism_EXTERNAL_LIBS
    ${PETSC_LIBRARIES}
    ${UDUNITS2_LIBRARIES}
    ${FFTW_LIBRARIES}
    ${GSL_LIBRARIES}
    ${NETCDF_LIBRARIES}
    ${MPI_C_LIBRARIES})

  # Hide distracting CMake variables
  mark_as_advanced(file_cmd MPI_LIBRARY MPI_EXTRA_LIBRARY
    CMAKE_OSX_ARCHITECTURES CMAKE_OSX_DEPLOYMENT_TARGET CMAKE_OSX_SYSROOT
    MAKE_EXECUTABLE TAO_DIR TAO_INCLUDE_DIRS NETCDF_PAR_H)

endmacro()
__EOF__
======================== FILE ./cmake/PreventInSourceBuild.cmake
FILE: ./cmake/PreventInSourceBuild.cmake
# Print error message on an attempt to build inside the source directory tree:
if ("${CMAKE_CURRENT_SOURCE_DIR}" STREQUAL "${CMAKE_CURRENT_BINARY_DIR}")
   message(FATAL_ERROR "ERROR! "
   "CMAKE_CURRENT_SOURCE_DIR=${CMAKE_CURRENT_SOURCE_DIR}"
   " == CMAKE_CURRENT_BINARY_DIR=${CMAKE_CURRENT_BINARY_DIR}"
   "\nmodelE does not support in-source builds:\n"
   "You must now delete the CMakeCache.txt file and the CMakeFiles/ directory under"
   "the top ${PROJECT_NAME} directory  or you will not be able to configure correctly!"
   "\nYou must now run something like:\n"
   "  $ rm -r CMakeCache.txt CMakeFiles/"
   "\n"
   "Please create a different directory and configure ${PROJECT_NAME} under that different directory such as:\n"
   "  $ mkdir MY_BUILD\n"
   "  $ cd MY_BUILD\n"
   "  $ cmake [OPTIONS] .."
   )
endif()
__EOF__
======================== FILE ./cmake/ProcessCommandLineOptions.cmake
FILE: ./cmake/ProcessCommandLineOptions.cmake
# USE_FEXCEPTION
if (NOT DEFINED USE_FEXCEPTION)
   # Use the fexception package in stop_model, rather than simply terminating
   # the process. Allows for better debugging from Python.
   set(USE_FEXCEPTION NO)
endif()

if(${USE_FEXCEPTION})
    # This will require the fexception library
    add_definitions(-DUSE_FEXCEPTION)
endif()

# BUILD_TYPE
if (NOT DEFINED CMAKE_BUILD_TYPE)
   # Use the fexception package in stop_model, rather than simply terminating
   # the process. Allows for better debugging from Python.
   message(STATUS "Setting build type to 'Debug' as none was specified.")
   set(CMAKE_BUILD_TYPE Debug)
    # Set the possible values of build type for cmake-gui
    set_property(CACHE CMAKE_BUILD_TYPE PROPERTY STRINGS "Debug" "Release"
    "Traps")
endif()


# USE_MPI
if (NOT DEFINED MPI)
   set(MPI YES)
endif()
if(${MPI})
    add_definitions(-DUSE_MPI)
endif()

if (NOT DEFINED USE_PNETCDF)
    set(USE_PNETCDF YES)
endif()

if (NOT DEFINED COMPILE_MODEL)
    set(COMPILE_MODEL YES)
endif()

if (NOT DEFINED COMPILE_AUX)
    set(COMPILE_AUX NO)
endif()

if (NOT DEFINED COMPILE_DIAGS)
    set(COMPILE_DIAGS NO)
endif()

if (NOT DEFINED COMPILE_IC)
    set(COMPILE_IC NO)
endif()

__EOF__
======================== FILE ./cmake/ResolveCompilerPaths.cmake
FILE: ./cmake/ResolveCompilerPaths.cmake
# ResolveCompilerPaths - this module defines two macros
#
# RESOLVE_LIBRARIES (XXX_LIBRARIES LINK_LINE)
#  This macro is intended to be used by FindXXX.cmake modules.
#  It parses a compiler link line and resolves all libraries
#  (-lfoo) using the library path contexts (-L/path) in scope.
#  The result in XXX_LIBRARIES is the list of fully resolved libs.
#  Example:
#
#    RESOLVE_LIBRARIES (FOO_LIBRARIES "-L/A -la -L/B -lb -lc -ld")
#
#  will be resolved to
#
#    FOO_LIBRARIES:STRING="/A/liba.so;/B/libb.so;/A/libc.so;/usr/lib/libd.so"
#
#  if the filesystem looks like
#
#    /A:       liba.so         libc.so
#    /B:       liba.so libb.so
#    /usr/lib: liba.so libb.so libc.so libd.so
#
#  and /usr/lib is a system directory.
#
#  Note: If RESOLVE_LIBRARIES() resolves a link line differently from
#  the native linker, there is a bug in this macro (please report it).
#
# RESOLVE_INCLUDES (XXX_INCLUDES INCLUDE_LINE)
#  This macro is intended to be used by FindXXX.cmake modules.
#  It parses a compile line and resolves all includes
#  (-I/path/to/include) to a list of directories.  Other flags are ignored.
#  Example:
#
#    RESOLVE_INCLUDES (FOO_INCLUDES "-I/A -DBAR='\"irrelevant -I/string here\"' -I/B")
#
#  will be resolved to
#
#    FOO_INCLUDES:STRING="/A;/B"
#
#  assuming both directories exist.
#  Note: as currently implemented, the -I/string will be picked up mistakenly (cry, cry)

macro (RESOLVE_LIBRARIES LIBS LINK_LINE)
  string (REGEX MATCHALL "((-L|-l|-Wl)([^\" ]+|\"[^\"]+\")|/[^\" ]+(a|so|dll))" _all_tokens "${LINK_LINE}")
  set (_libs_found)
  set (_directory_list)
  foreach (token ${_all_tokens})
    if (token MATCHES "-L([^\" ]+|\"[^\"]+\")")
      # If it's a library path, add it to the list
      string (REGEX REPLACE "^-L" "" token ${token})
      string (REGEX REPLACE "//" "/" token ${token})
      list (APPEND _directory_list ${token})
    elseif (token MATCHES "^(-l([^\" ]+|\"[^\"]+\")|/[^\" ]+(a|so|dll))")
      # It's a library, resolve the path by looking in the list and then (by default) in system directories
      string (REGEX REPLACE "^-l" "" token ${token})
      set (_root)
      if (token MATCHES "^/")	# We have an absolute path, add root to the search path
	set (_root "/")
      endif (token MATCHES "^/")
      set (_lib "NOTFOUND" CACHE FILEPATH "Cleared" FORCE)
      find_library (_lib ${token} HINTS ${_directory_list} ${_root})
      if (_lib)
	string (REPLACE "//" "/" _lib ${_lib})
        list (APPEND _libs_found ${_lib})
      else (_lib)
        message (STATUS "Unable to find library ${token}")
      endif (_lib)
    endif (token MATCHES "-L([^\" ]+|\"[^\"]+\")")
  endforeach (token)
  set (_lib "NOTFOUND" CACHE INTERNAL "Scratch variable" FORCE)
  # only the LAST occurence of each library is required since there should be no circular dependencies
  if (_libs_found)
    list (REVERSE _libs_found)
    list (REMOVE_DUPLICATES _libs_found)
    list (REVERSE _libs_found)
  endif (_libs_found)
  set (${LIBS} "${_libs_found}")
endmacro (RESOLVE_LIBRARIES)

macro (RESOLVE_INCLUDES INCS COMPILE_LINE)
  string (REGEX MATCHALL "-I([^\" ]+|\"[^\"]+\")" _all_tokens "${COMPILE_LINE}")
  set (_incs_found)
  foreach (token ${_all_tokens})
    string (REGEX REPLACE "^-I" "" token ${token})
    string (REGEX REPLACE "//" "/" token ${token})
    if (EXISTS ${token})
      list (APPEND _incs_found ${token})
    else (EXISTS ${token})
      message (STATUS "Include directory ${token} does not exist")
    endif (EXISTS ${token})
  endforeach (token)
  list (REMOVE_DUPLICATES _incs_found)
  set (${INCS} "${_incs_found}")
endmacro (RESOLVE_INCLUDES)
__EOF__
======================== FILE ./cmake/listContains.cmake
FILE: ./cmake/listContains.cmake
MACRO(listContains var value)
  SET(${var})
  FOREACH (value2 ${ARGN})
    IF (${value} STREQUAL ${value2})
      SET(${var} TRUE)
    ENDIF (${value} STREQUAL ${value2})
  ENDFOREACH (value2)
ENDMACRO(listContains)
__EOF__
======================== FILE ./cmake/scripts/rundeck_to_cmake.py
FILE: ./cmake/scripts/rundeck_to_cmake.py
import os
srcdir = os.path.dirname(os.path.abspath(__file__))
import sys
libdir = os.path.join(srcdir, '..', '..', 'python', 'lib')
libdir = os.path.normpath(libdir)
sys.path = [libdir] + sys.path   # Somehwow append does not work
import modele.rundir
import modele.rundeck
import re
import tempfile
import filecmp
import shutil

# ------------------------------------------------------
class WriteIfDifferent(object):
    """Allows user to write to a temporary file, then move it
    to the destination only if it is different from the destination."""
    def __init__(self, ofname, **kwargs):
        """ofname: Name we ultimately want to write to."""
        self.ofname = ofname
        self.file = tempfile.NamedTemporaryFile(delete=False, **kwargs)
        self.tfname = self.file.name

    def close(self):
        self.file.close()
        try:
            if filecmp.cmp(self.tfname, self.ofname):
                # Files are equal, we are done!
                os.remove(self.tfname)
                return
        except: pass # Error means the files were NOT equal.

        # Files are not equal, so copy the temporary file over.
        shutil.copyfile(self.tfname, self.ofname)
        os.remove(self.tfname)

# ------------------------------------------------------
print('==================== BEGIN rundeck_to_cmake.py')
print('sys.argv', sys.argv)

# Get command line arguments
source_root = sys.argv[1]       # ${PROJECT_SOURCE_ROOT}
build_root = sys.argv[2]        # ${PROJECT_BUILD_ROOT}
rundeck_fname = sys.argv[3]
defines = sys.argv[4:]          # Add these to rundeck_opts.h

rundeck = modele.rundeck.load_rundeck(rundeck_fname, auto_download=False)
build = rundeck.build    # We only care about the build part of the rundeck
build.components['profiler'] = None     # Include profiler in all builds
#build.components['landice'] = None     # Include landice in all builds


src_files = []

# Find the source files (Object Modules)
for obj_module in build.sources:
    src_file = None
    for ext in ('.f', '.F', '.f90', '.F90'):
        fname = os.path.join(source_root, 'model', obj_module + ext)
        if os.path.exists(fname):
            src_file = obj_module+ext
            break

    if src_file is None:
        raise ValueError('Cannot find source file for object module {0}'.format(obj_module))
    src_files.append(src_file)

# Write out our source files for top-level ModelE build
with open(os.path.join(build_root, 'model', 'modele_SOURCES.cmake'), 'w') as out:
    out.write('# Machine-generated, DO NOT EDIT.\n')

    # Write out component options
    out.write('\n# Component Options\n')
    for component,options in build.components.items():
        if options is None:
            continue
        for name,value in options.items():
            out.write('set({0} {1})\n'.format(name,value))

    # Now include component lists of files
    # (which could depend on component options)
    out.write('\n# Get lists of files in components we will use\n')
    for component in build.components.keys():
        out.write('include(${CMAKE_CURRENT_SOURCE_DIR}/' + '{0}/{0}_SOURCES.cmake)\n'.format(component))

    out.write('\n#Set main list of files for the ModelE library\n')
    out.write('set(modele_SOURCES')

    for component in build.components.keys():
        out.write('\n\t${%s_SOURCES}' % component)

    for src_file in src_files:
        out.write('\n\t${CMAKE_CURRENT_SOURCE_DIR}/'+src_file)

    out.write(')\n')

# Write preprocessor #define's into the rundeck_opts.h file
rundeck_opts = WriteIfDifferent(os.path.join(build_root, 'model', 'rundeck_opts.h'), mode='w')
out = rundeck_opts.file

for symbol,definition in build.defines.items():
    if definition is None:
        out.write('#define {0}\n'.format(symbol))
    else:
        out.write('#define {0} {1}\n'.format(symbol, definition))

# From command line
for deff in defines:
    out.write('#define {0}\n'.format(deff))
rundeck_opts.close()

print('==================== END rundeck_to_cmake.py')
__EOF__
======================== FILE ./cmake/scripts/write_export_constants.py
FILE: ./cmake/scripts/write_export_constants.py
# Reads comments from the Fortran source file Constants_mod.F90
# Produces the Fortran source file ExportConstants.F90, which
# exports those constants from ModelE through a Fortran callback.
#
# by Elizabeth Fischer        April 26, 2014
from __future__ import print_function
import re
import netCDF4
import os.path
import sys
import string
try:
    import cf_units
    has_cf_units = True
except ImportError:
    has_cf_units = False


source_root = sys.argv[1]   # ${PROJECT_SOURCE_DIR}
build_root = sys.argv[2]        # ${PROJECT_BUILD_DIR}

#model_dir = os.path.realpath(os.path.join(os.path.dirname(__file__), '../../model'))

source_files = [ \
    ('shared/Constants_mod.F90', 'constant'), \
    ('SEAICE.f', 'seaice')]
#   ('LANDICE.f', 'landice')]

odir = os.path.join(build_root, 'model', 'landice')
export_constants_f90 = os.path.join(odir, 'ExportConstants.F90')

try: os.makedirs(odir)
except: pass


print('Writing %s' % export_constants_f90)

def split_comments(fin) :
    """Generator yields (line,comment) for each line"""
    for line in fin :
        pt = line.find('!')
        if pt < 0 : yield (line,None)
        yield (line[:pt], line[pt:])

paramRE = re.compile(r'!@param\s+(.*?)\s(.*?)\[\s*(.*?)\s*\]', re.IGNORECASE)

out = open(export_constants_f90, 'w')

# Get name of this script, strip off stuff above the ModelE source tree.
this_script = os.path.realpath(__file__)
exec_i = this_script.find('exec')
if exec_i >= 0 :
    this_script = this_script[exec_i:]

# ============================================================
out.write("""! This file is machine-generated.  DO NOT EDIT BY HAND!
! Generated by %s\n""" % this_script)

out.write("""module ExportConstants

abstract interface
    ! Callback used to communicate a constant out of ModelE
    subroutine set_constant_cb( &
        api, &
        name_f, name_len, &
        val, &
        units_f, units_len, &
        description_f, description_len) bind(c)
    use iso_c_binding
        type(c_ptr), value :: api
        character(c_char) :: name_f(*)
        integer(c_int), value :: name_len
        real(c_double), value :: val
        character(c_char) :: units_f(*)
        integer(c_int), value :: units_len
        character(c_char) :: description_f(*)
        integer(c_int), value :: description_len
    end subroutine
end interface

contains

! Communicate all ModelE constants to an external source
! @param set_constant Call this function on each ModelE constant.
subroutine set_all_constants(api, set_constant)
""")

for (leaf, module) in source_files :
    out.write("    use %s\n" % module)

out.write("""use iso_c_binding
implicit none
    type(c_ptr), value :: api
    procedure(set_constant_cb), pointer :: set_constant

""")
# ============================================================


defvars = []
for (leaf, module) in source_files :
    fname = os.path.join(source_root, 'model', leaf)
    print('Reading %s' % fname)
    for line,comment in split_comments(open(fname, 'r')) :
        # Parse the comment
        if comment is None : continue

        match = paramRE.match(comment)
        if match is not None :
            param_names = match.group(1)
            description = match.group(2).strip()
            units = match.group(3)

            # Error-check (validate) the unit
            if has_cf_units:
                try:
                    compiled_unit = cf_units.Unit(units)
                except ValueError:
                    print('Invalid unit on {0}: [{1}]'.format(param_names, units))

            fdescription = "'%s'" % description.replace("'", "''")

            for name in param_names.split(',') :
                name = name.lower()
                full_name = '%s::%s' % (module, name.lower())
                out.write(("    call set_constant(api, '%s', %d, %s, '%s', %d, &\n" + \
                    "        %s, %d)\n") \
                    % (full_name, len(full_name), name, units, len(units), fdescription, len(description)))

out.write("""end subroutine
end module
""")


out.close()
__EOF__
======================== FILE ./cmake/scripts/write_export_constants.py.bak
FILE: ./cmake/scripts/write_export_constants.py.bak
# Reads comments from the Fortran source file Constants_mod.F90
# Produces the Fortran source file ExportConstants.F90, which
# exports those constants from ModelE through a Fortran callback.
#
# by Robert Fischer        April 26, 2014

import re
import netCDF4
import os.path
import sys
import string
try:
    import cf_units
    has_cf_units = True
except ImportError:
    has_cf_units = False


source_root = sys.argv[1]   # ${PROJECT_SOURCE_DIR}
build_root = sys.argv[2]        # ${PROJECT_BUILD_DIR}

#model_dir = os.path.realpath(os.path.join(os.path.dirname(__file__), '../../model'))

source_files = [ \
    ('shared/Constants_mod.F90', 'constant'), \
    ('SEAICE.f', 'seaice')]
#   ('LANDICE.f', 'landice')]

odir = os.path.join(build_root, 'model', 'landice')
export_constants_f90 = os.path.join(odir, 'ExportConstants.F90')

try: os.makedirs(odir)
except: pass


print('Writing %s' % export_constants_f90)

def split_comments(fin) :
<<<<<<< HEAD
	"""Generator yields (line,comment) for each line"""
	for line in fin :
		pt = line.find('!')
		if pt < 0 : yield (line,None)
		yield (line[:pt], line[pt:])
=======
    """Generator yields (line,comment) for each line"""
    for line in fin :
        pt = line.find('!')
        if pt < 0 : yield (line,None)
        yield (line[:pt], line[pt:])
>>>>>>> cmake

paramRE = re.compile(r'!@param\s+(.*?)\s(.*?)\[\s*(.*?)\s*\]', re.IGNORECASE)

out = open(export_constants_f90, 'w')

# Get name of this script, strip off stuff above the ModelE source tree.
this_script = os.path.realpath(__file__)
exec_i = this_script.find('exec')
if exec_i >= 0 :
<<<<<<< HEAD
	this_script = this_script[exec_i:]
=======
    this_script = this_script[exec_i:]
>>>>>>> cmake

# ============================================================
out.write("""! This file is machine-generated.  DO NOT EDIT BY HAND!
! Generated by %s\n""" % this_script)

out.write("""module ExportConstants

abstract interface
<<<<<<< HEAD
	! Callback used to communicate a constant out of ModelE
	subroutine set_constant_cb( &
		api, &
		name_f, name_len, &
		val, &
		units_f, units_len, &
		description_f, description_len) bind(c)
	use iso_c_binding
		type(c_ptr), value :: api
		character(c_char) :: name_f(*)
		integer(c_int), value :: name_len
		real(c_double), value :: val
		character(c_char) :: units_f(*)
		integer(c_int), value :: units_len
		character(c_char) :: description_f(*)
		integer(c_int), value :: description_len
	end subroutine
=======
    ! Callback used to communicate a constant out of ModelE
    subroutine set_constant_cb( &
        api, &
        name_f, name_len, &
        val, &
        units_f, units_len, &
        description_f, description_len) bind(c)
    use iso_c_binding
        type(c_ptr), value :: api
        character(c_char) :: name_f(*)
        integer(c_int), value :: name_len
        real(c_double), value :: val
        character(c_char) :: units_f(*)
        integer(c_int), value :: units_len
        character(c_char) :: description_f(*)
        integer(c_int), value :: description_len
    end subroutine
>>>>>>> cmake
end interface

contains

! Communicate all ModelE constants to an external source
! @param set_constant Call this function on each ModelE constant.
subroutine set_all_constants(api, set_constant)
""")

for (leaf, module) in source_files :
<<<<<<< HEAD
	out.write("    use %s\n" % module)
=======
    out.write("    use %s\n" % module)
>>>>>>> cmake

out.write("""use iso_c_binding
implicit none
    type(c_ptr), value :: api
<<<<<<< HEAD
	procedure(set_constant_cb), pointer :: set_constant
=======
    procedure(set_constant_cb), pointer :: set_constant
>>>>>>> cmake

""")
# ============================================================


defvars = []
for (leaf, module) in source_files :
<<<<<<< HEAD
	fname = os.path.join(source_root, 'model', leaf)
	print('Reading %s' % fname)
	for line,comment in split_comments(open(fname, 'r')) :
		# Parse the comment
		if comment is None : continue

		match = paramRE.match(comment)
		if match is not None :
			param_names = match.group(1)
			description = match.group(2).strip()
			units = match.group(3)

			# Error-check (validate) the unit
			if has_cf_units:
				try:
					compiled_unit = cf_units.Unit(units)
				except ValueError:
					print('Invalid unit on {}: [{}]'.format(param_names, units))

			fdescription = "'%s'" % description.replace("'", "''")

			for name in param_names.split(',') :
				name = name.lower()
				full_name = '%s::%s' % (module, name.lower())
				out.write(("    call set_constant(api, '%s', %d, %s, '%s', %d, &\n" + \
					"        %s, %d)\n") \
					% (full_name, len(full_name), name, units, len(units), fdescription, len(description)))
=======
    fname = os.path.join(source_root, 'model', leaf)
    print('Reading %s' % fname)
    for line,comment in split_comments(open(fname, 'r')) :
        # Parse the comment
        if comment is None : continue

        match = paramRE.match(comment)
        if match is not None :
            param_names = match.group(1)
            description = match.group(2).strip()
            units = match.group(3)

            # Error-check (validate) the unit
            if has_cf_units:
                try:
                    compiled_unit = cf_units.Unit(units)
                except ValueError:
                    print('Invalid unit on {}: [{}]'.format(param_names, units))

            fdescription = "'%s'" % description.replace("'", "''")

            for name in param_names.split(',') :
                name = name.lower()
                full_name = '%s::%s' % (module, name.lower())
                out.write(("    call set_constant(api, '%s', %d, %s, '%s', %d, &\n" + \
                    "        %s, %d)\n") \
                    % (full_name, len(full_name), name, units, len(units), fdescription, len(description)))
>>>>>>> cmake

out.write("""end subroutine
end module
""")


out.close()
__EOF__
======================== FILE ./cmake/setup_rpath.cmake
FILE: ./cmake/setup_rpath.cmake
# enable @rpath in the install name for any shared library being built
# note: it is planned that a future version of CMake will enable this by default
set(CMAKE_MACOSX_RPATH 1)

# --------------------------------------------------------
# Always use full RPATH
# http://www.cmake.org/Wiki/CMake_RPATH_handling
# http://www.kitware.com/blog/home/post/510

# use, i.e. don't skip the full RPATH for the build tree
SET(CMAKE_SKIP_BUILD_RPATH  FALSE)

# when building, don't use the install RPATH already
# (but later on when installing)
SET(CMAKE_BUILD_WITH_INSTALL_RPATH FALSE) 

# add the automatically determined parts of the RPATH
# which point to directories outside the build tree to the install RPATH
SET(CMAKE_INSTALL_RPATH_USE_LINK_PATH TRUE)

# the RPATH to be used when installing, but only if it's not a system directory
LIST(FIND CMAKE_PLATFORM_IMPLICIT_LINK_DIRECTORIES "${CMAKE_INSTALL_PREFIX}/lib" isSystemDir)
IF("${isSystemDir}" STREQUAL "-1")
   SET(CMAKE_INSTALL_RPATH "${CMAKE_INSTALL_PREFIX}/lib")
ENDIF("${isSystemDir}" STREQUAL "-1")

message("-- CMAKE_INSTALL_RPATH " ${CMAKE_INSTALL_RPATH})
# --------------------------------------------------------
__EOF__
======================== FILE ./exec/cmake/modele
FILE: ./exec/cmake/modele
#!/usr/bin/env python2
#
# Main command to control ModelE
from __future__ import print_function

import os
srcdir = os.path.dirname(os.path.abspath(__file__))
import sys
sys.path.append(os.path.join(srcdir, '..', '..', 'python', 'lib'))

from modele import rundeck,rundir, pathutil

import string
import tempfile
import filecmp
import shutil

cmd_name = sys.argv[1]
argv = sys.argv[2:]

if cmd_name == 'setup':
    rundeck_fname = argv[0]
    run_dir = argv[1]

    rd=rundeck.load_rundeck(rundeck_fname)
    rundir.make_rundir(rd, run_dir)

elif cmd_name == 'run':
    run_dir = argv[1]

    modele_root = pathutil.modele_root()
    modelexe = os.path.join(modele_root, 'build', 'model', 'modelexe')
    print '(cd {}; mpirun -np 8 {} -cold-restart -i I)'.format(run_dir, modelexe)

else:
    sys.stderr.write('Unknown modele command: {}'.format(sys.argv))
__EOF__
======================== FILE ./init_cond/CMakeLists.txt
FILE: ./init_cond/CMakeLists.txt
# init_cond

include_directories(${PROJECT_BINARY_DIR}/model)

# Targets

# This requires a Rundeck to build...
#add_executable(mkAIC.bin AIC.D771201.f HNTRPS.f)
#target_link_libraries(mkAIC.bin modele)

# Does not build; something wrong with FOCEAN/ZOCEAN common block
#add_executable(OIC.WOA98.exe OIC.WOA98.f)
add_executable(OPF.exe OPF.f)

install(TARGETS OPF.exe DESTINATION bin)
# mkAIC.bin

__EOF__
======================== FILE ./model/CMakeLists.txt
FILE: ./model/CMakeLists.txt
# main model CMakeLists.txt

get_filename_component(DIRNAME "${CMAKE_CURRENT_SOURCE_DIR}" NAME)
set(LIB ${DIRNAME})

# In modelE, the final model executable is built upon specifications in
# a so-called 'rundeck' file. The rundeck contains information about all
# the components, model parameters and data files needed to compile and
# run the model.
# As a result one has to somehow parse the template file to extract the names
# of the components and the corresponding files, the compile and run options
# and the runtime parameters and data files. 

modele_set_dependencies()
# -----------------------------------------------------------
# Get lists of source files for all ModelE components.
# They may or may not be used in the final ModelE library.
set(BUILD_CPP_OPTIONS )		# Accumulate options here

include(${CMAKE_CURRENT_SOURCE_DIR}/shared/shared_SOURCES.cmake)
include(${CMAKE_CURRENT_SOURCE_DIR}/MPI_Support/MPI_Support_SOURCES.cmake)
include(${CMAKE_CURRENT_SOURCE_DIR}/solvers/solvers_SOURCES.cmake)
include(${CMAKE_CURRENT_SOURCE_DIR}/giss_LSM/giss_LSM_SOURCES.cmake)
include(${CMAKE_CURRENT_SOURCE_DIR}/dd2d/dd2d_SOURCES.cmake)
include(${CMAKE_CURRENT_SOURCE_DIR}/Ent/Ent_SOURCES.cmake)
include(${CMAKE_CURRENT_SOURCE_DIR}/profiler/profiler_SOURCES.cmake)
#include(${CMAKE_CURRENT_SOURCE_DIR}/landice/landice_SOURCES.cmake)

# -----------------------------------------------------------
# This is a file included by model files.
set(RUNDECK_OPTS ${CMAKE_CURRENT_BINARY_DIR}/include/rundeck_opts.h)

# Export rundeck file settings into CMake
execute_process(
   COMMAND
   python2 ${PROJECT_SOURCE_DIR}/cmake/scripts/rundeck_to_cmake.py
   ${PROJECT_SOURCE_DIR} ${PROJECT_BINARY_DIR} ${RUN} ${BUILD_CPP_OPTIONS}
)

# include containers
include_directories(${PROJECT_SOURCE_DIR}/model/shared)

# include generated rundeck_opts
#include_directories(${CMAKE_CURRENT_BINARY_DIR}/include)
include(${CMAKE_CURRENT_BINARY_DIR}/modele_SOURCES.cmake)

# Specify TARGETS. 
add_library(modele SHARED ${modele_SOURCES})
target_link_libraries(modele   ${ModelE_EXTERNAL_LIBS}  )

# Set RPATH in the installed library
# (although we are unlikely to ever install here)
# http://www.cmake.org/Wiki/CMake_RPATH_handling
# http://www.kitware.com/blog/home/post/510

set_target_properties(modele PROPERTIES INSTALL_RPATH_USE_LINK_PATH TRUE)

install(TARGETS modele DESTINATION lib)

# modelE executable
add_executable(modelexe main.F90)

# Set additional link library dependencies
target_link_libraries(modelexe modele ${ModelE_EXTERNAL_LIBS})

set_target_properties(modelexe PROPERTIES INSTALL_RPATH_USE_LINK_PATH TRUE)
install(TARGETS modelexe DESTINATION bin)

__EOF__
======================== FILE ./model/Ent/Ent_SOURCES.cmake
FILE: ./model/Ent/Ent_SOURCES.cmake

# Pre-process m4F90 files
file(GLOB m4files "Ent/*.m4f")
foreach(file ${m4files})
   get_filename_component (name_without_extension ${file} NAME_WE)

   add_custom_command (
      COMMAND ${CMAKE_COMMAND} -E make_directory ${CMAKE_CURRENT_BINARY_DIR}/Ent

      OUTPUT ${CMAKE_CURRENT_BINARY_DIR}/Ent/${name_without_extension}.f
      COMMAND m4
      ARGS -s -I${CMAKE_CURRENT_SOURCE_DIR}/Ent ${file} > ${CMAKE_CURRENT_BINARY_DIR}/Ent/${name_without_extension}.f
      DEPENDS ${file}
   )
endforeach()


# Set Sources
set(Ent_SOURCES
   ${CMAKE_CURRENT_SOURCE_DIR}/Ent/ent_prescribed_drv.f
   ${CMAKE_CURRENT_SOURCE_DIR}/Ent/ent_prescribed_drv_geo.f
   ${CMAKE_CURRENT_BINARY_DIR}/Ent/ent_mod.f
   ${CMAKE_CURRENT_SOURCE_DIR}/Ent/ent.f
   ${CMAKE_CURRENT_SOURCE_DIR}/Ent/cohorts.f
   ${CMAKE_CURRENT_SOURCE_DIR}/Ent/patches.f
   ${CMAKE_CURRENT_SOURCE_DIR}/Ent/entcells.f
   ${CMAKE_CURRENT_SOURCE_DIR}/Ent/physutil.f
   ${CMAKE_CURRENT_SOURCE_DIR}/Ent/allometryfn.f
   ${CMAKE_CURRENT_SOURCE_DIR}/Ent/reproduction.f
   ${CMAKE_CURRENT_SOURCE_DIR}/Ent/phenology.f
   ${CMAKE_CURRENT_SOURCE_DIR}/Ent/respauto_physio.f
   ${CMAKE_CURRENT_SOURCE_DIR}/Ent/disturbance.f
   ${CMAKE_CURRENT_SOURCE_DIR}/Ent/soilbgc.f
   ${CMAKE_CURRENT_SOURCE_DIR}/Ent/ent_const.f
   ${CMAKE_CURRENT_SOURCE_DIR}/Ent/ent_types.f 
   ${CMAKE_CURRENT_SOURCE_DIR}/Ent/ent_prescr_veg.f
   ${CMAKE_CURRENT_SOURCE_DIR}/Ent/ent_prescribed_updates.f
   ${CMAKE_CURRENT_SOURCE_DIR}/Ent/ent_debug.f)


# Set sources based on rundeck options
if (PFT_MODEL MATCHES "ENT")
   if (FLUXNET MATCHES "YES")
      list(APPEND Ent_SOURCES ${CMAKE_CURRENT_SOURCE_DIR}/Ent/ent_pfts_ENT_FLUXNET.f)
   else()
      list(APPEND Ent_SOURCES ${CMAKE_CURRENT_SOURCE_DIR}/Ent/ent_pfts_ENT.f)
   endif()
else()
   if (FLUXNET MATCHES "YES")
      list(APPEND Ent_SOURCES ${CMAKE_CURRENT_SOURCE_DIR}/Ent/ent_pfts_FLUXNET.f)
   else()
      list(APPEND Ent_SOURCES ${CMAKE_CURRENT_SOURCE_DIR}/Ent/ent_pfts.f)
   endif()
endif()

# Set Ent_SOURCES based on rundeck options
if (PS_MODEL MATCHES "FBB")
   list(APPEND Ent_SOURCES ${CMAKE_CURRENT_SOURCE_DIR}/Ent/FBBphotosynthesis.f)
   if (RAD_MODEL MATCHES "GORT")
      list(APPEND Ent_SOURCES ${CMAKE_CURRENT_SOURCE_DIR}/Ent/canopyradiation.f ${CMAKE_CURRENT_SOURCE_DIR}/Ent/canopygort.f)
   else()
      list(APPEND Ent_SOURCES ${CMAKE_CURRENT_SOURCE_DIR}/Ent/canopyspitters.f)
   endif()
   if (PFT_MODEL MATCHES "ENT")
      if (FLUXNET MATCHES "YES")
         list(APPEND Ent_SOURCES ${CMAKE_CURRENT_SOURCE_DIR}/Ent/FBBpfts_ENT_FLUXNET.f)
      else()
         list(APPEND Ent_SOURCES ${CMAKE_CURRENT_SOURCE_DIR}/Ent/FBBpfts_ENT.f)
      endif()
   else()
      if (FLUXNET MATCHES "YES")
         list(APPEND Ent_SOURCES ${CMAKE_CURRENT_SOURCE_DIR}/Ent/FBBpfts_FLUXNET.f)
      else()
         list(APPEND Ent_SOURCES ${CMAKE_CURRENT_SOURCE_DIR}/Ent/FBBpfts.f)
      endif()
   endif()
else()
   list(APPEND Ent_SOURCES ${CMAKE_CURRENT_SOURCE_DIR}/Ent/biophysics.f)
endif()

if (MIXED_CANOPY_OPT MATCHES "ENT")
   list(APPEND Ent_SOURCES ${CMAKE_CURRENT_SOURCE_DIR}/Ent/ent_make_struct.f)
endif()

# TODO: This needs to get fixed up...
# Would like to write all preprocessor flags into a .h file
# for easy inspection.  Also, preprocessor flag should match
# the Ent option name.

# Set CPPFLAGS based on rundeck options
if (MIXED_CANOPY_OPT MATCHES "YES")
   set(CPPFLAGS "${CPPFLAGS} -DMIXED_CANOPY")
endif()

if (ENT_STANDALONE_DIAG MATCHES "YES")
   set(CPPFLAGS "${CPPFLAGS} -DENT_STANDALONE_DIAG")
endif()

if (SITE MATCHES "YES")
   set(CPPFLAGS "${CPPFLAGS} -DSOILCARB_SITE")
endif()

if (PFT_MODEL MATCHES "ENT")
    add_definitions(-DPFT_MODEL_ENT)
endif()

if (FLUXNET MATCHES "YES")
    add_definitions(-DSOILCARB_SITE)
endif()

if (PFT_MODEL MATCHES "YES")
    add_definitions(-DENT_STANDALONE_DIAG)
endif()
__EOF__
======================== FILE ./model/MPI_Support/MPI_Support_SOURCES.cmake
FILE: ./model/MPI_Support/MPI_Support_SOURCES.cmake
# Set sources
set(MPI_Support_SOURCES
   ${CMAKE_CURRENT_SOURCE_DIR}/MPI_Support/dd2d_utils.f
   ${CMAKE_CURRENT_SOURCE_DIR}/MPI_Support/DomainDecompLatLon.f
   ${CMAKE_CURRENT_SOURCE_DIR}/MPI_Support/pario_fbsa.f
   ${CMAKE_CURRENT_SOURCE_DIR}/MPI_Support/assert.F90
   ${CMAKE_CURRENT_SOURCE_DIR}/MPI_Support/dist_grid_mod.F90
   ${CMAKE_CURRENT_SOURCE_DIR}/MPI_Support/DomainDecomposition_mod.F90
   ${CMAKE_CURRENT_SOURCE_DIR}/MPI_Support/Domain_mod.F90
   ${CMAKE_CURRENT_SOURCE_DIR}/MPI_Support/GatherScatter_mod.F90
   ${CMAKE_CURRENT_SOURCE_DIR}/MPI_Support/GlobalSum_mod.F90
   ${CMAKE_CURRENT_SOURCE_DIR}/MPI_Support/Halo_mod.F90
   ${CMAKE_CURRENT_SOURCE_DIR}/MPI_Support/Hidden_mod.F90
   ${CMAKE_CURRENT_SOURCE_DIR}/MPI_Support/MpiSupport_mod.F90
   ${CMAKE_CURRENT_SOURCE_DIR}/MPI_Support/ProcessTopology_mod.F90
   ${CMAKE_CURRENT_SOURCE_DIR}/MPI_Support/SpecialIO_mod.F90
)
__EOF__
======================== FILE ./model/dd2d/dd2d_SOURCES.cmake
FILE: ./model/dd2d/dd2d_SOURCES.cmake
set(dd2d_SOURCES
   ${CMAKE_CURRENT_SOURCE_DIR}/dd2d/cdl_mod.f
   ${CMAKE_CURRENT_SOURCE_DIR}/dd2d/timestream_mod.f
   ${CMAKE_CURRENT_SOURCE_DIR}/dd2d/ParallelIo.F90
)

if (USE_PNETCDF)
   if(MPI)
      list(APPEND dd2d_SOURCES ${CMAKE_CURRENT_SOURCE_DIR}/dd2d/pario_pnc.f)
   else()
      list(APPEND dd2d_SOURCES ${CMAKE_CURRENT_SOURCE_DIR}/dd2d/pario_nc.f)
   endif()
else()
   list(APPEND dd2d_SOURCES ${CMAKE_CURRENT_SOURCE_DIR}/dd2d/pario_nc.f)
endif()
__EOF__
======================== FILE ./model/giss_LSM/giss_LSM_SOURCES.cmake
FILE: ./model/giss_LSM/giss_LSM_SOURCES.cmake
set(giss_LSM_SOURCES
   ${CMAKE_CURRENT_SOURCE_DIR}/giss_LSM/GHY.f
   ${CMAKE_CURRENT_SOURCE_DIR}/giss_LSM/GHY_H.f
   ${CMAKE_CURRENT_SOURCE_DIR}/giss_LSM/SNOW_DRV.f
   ${CMAKE_CURRENT_SOURCE_DIR}/giss_LSM/SNOW.f
)


# Set sources and CPPFLAGS based on rundeck options
if (USE_ENT MATCHES "YES")
   set(giss_LSM_SOURCES ${giss_LSM_SOURCES} ${CMAKE_CURRENT_SOURCE_DIR}/giss_LSM/VEGETATION.f)
   #set(CPPFLAGS "${CPPFLAGS} -DUSE_ENT")  
endif()

if (OFFLINE_RUN MATCHES "YES")
   set(giss_LSM_SOURCES ${giss_LSM_SOURCES} ${CMAKE_CURRENT_SOURCE_DIR}/giss_LSM/VEGETATION.f)
   #set(CPPFLAGS "${CPPFLAGS} -DOFFLINE_RUN")  
endif()
__EOF__
======================== FILE ./model/mk_diags/CMakeLists.txt
FILE: ./model/mk_diags/CMakeLists.txt
# mk_diags

modele_set_dependencies()
mkdiags_set_dependencies()

# Sources
set(srcs_f
   agcstat.f
   csregrid.f
   diffreport.f
   miscnc.f
   prtadiurn.f
   prtaj.f
   prtajl.f
   prtareg.f
   prtconsrv.f
   prtisccp.f
   prtolnst.f
   prtostat.f
   prtotj.f
   prtrvr.f
   prtspeca.f
   scaleaccdrv.f
   scaleacc.f
   sumfiles.f
   write_2d_as_giss4d.f
   write_giss2d.f
)

#
# Loop over diagnostics categories and compile each Fortran print
# routine with a driver program which opens/closes the input file
# and passes any extra command-line arguments to the print routine
#
set(diags
   aj areg ajl adiurn consrv rvr isccp olnst otj
)
foreach(diag ${diags})
   set(PRTDIAG "prt${diag}")
   configure_file (
     "${CMAKE_CURRENT_SOURCE_DIR}/prtdrv.f.in"
     "${CMAKE_CURRENT_BINARY_DIR}/${PRTDIAG}drv.f"
   )
   add_executable(${PRTDIAG} 
      ${CMAKE_CURRENT_BINARY_DIR}/${PRTDIAG}drv.f 
      ${PRTDIAG}.f
      miscnc.f)
   #message(STATUS " ---> Add executable ${PRTDIAG}")
   target_link_libraries(${PRTDIAG}  ${MKDIAGS_EXTERNAL_LIBS})
   install(TARGETS ${PRTDIAG} DESTINATION bin)
endforeach()

#
# Compile the generic scaling routine with an appropriate driver
#
add_executable(scaleacc scaleaccdrv.f scaleacc.f csregrid.f miscnc.f)
target_link_libraries(scaleacc ${MKDIAGS_EXTERNAL_LIBS})
install(TARGETS scaleacc DESTINATION bin)

#
# Compile miscellaneous routines
#
set(apps
  agcstat sumfiles write_giss2d write_2d_as_giss4d diffreport prtostat prtspeca
)
foreach(app ${apps})
   add_executable(${app} ${app}.f miscnc.f)
   #message(STATUS " ---> Add executable ${app}")
   target_link_libraries(${app} ${ModelE_EXTERNAL_LIBS})
   install(TARGETS ${app} DESTINATION bin)
endforeach()

__EOF__
======================== FILE ./model/mk_diags/prtdrv.f.in
FILE: ./model/mk_diags/prtdrv.f.in
      program driver
      implicit none
      include 'netcdf.inc'
      integer :: status,ifid
      character(len=80) :: ifile,argstr
      character(len=160) :: progargs
      integer :: iarg,nargs
      !integer, external :: iargc
      nargs = iargc()
      call getarg(1,ifile)
      progargs=''
      if(nargs.gt.1) then
         do iarg=2,nargs
           call getarg(iarg,argstr)
           if(trim(argstr).eq.'gissfmt') then
             argstr='gissfmt='//ifile(1:len_trim(ifile)-3) ! no .nc suffix
           endif
           if(iarg.eq.2) then
             progargs=argstr
           else
             progargs=trim(progargs)//' '//trim(argstr)
           endif
         enddo
      endif
      status = nf_open(trim(ifile),nf_nowrite,ifid)
      if(status.ne.nf_noerr) then
        write(6,*) 'nonexistent/non-netcdf input file ',trim(ifile)
        stop
      endif
      call @PRTDIAG@(ifid,progargs)
      status = nf_close(ifid)
      end program driver
__EOF__
======================== FILE ./model/mk_diags/scaleacc_driver.f
FILE: ./model/mk_diags/scaleacc_driver.f
      program driver
      implicit none
      include 'netcdf.inc'
      integer :: status,ifids(2)
      character(len=200) :: ifile,remap_file
      character(len=80) :: accname
      integer :: i1,i2,nargs
      !integer, external :: iargc
      nargs = iargc()
      if(nargs.ne.2 .and. nargs.ne.3) then
         write(6,*)
     &   'usage: scaleacc acc-file acc_array_name[,name2] [remap_file]'
         stop
      endif
      call getarg(1,ifile)
      call getarg(2,accname)
      i1 = index(ifile,'.acc')
      if(i1.eq.0) i1 = index(ifile,'.subdd')
      i2 = index(ifile,'.nc')
      if(i1.eq.0 .or. i1.gt.i2) then
        stop 'expecting filename of the form *.acc*.nc or *.subdd*.nc'
      endif
      status = nf_open(trim(ifile),nf_nowrite,ifids(1))
      if(status.ne.nf_noerr) then
        write(6,*) 'nonexistent/non-netcdf input file ',trim(ifile)
        stop
      endif
      ifids(2) = -99
      if(nargs.eq.3) then
        call getarg(3,remap_file)
        status = nf_open(trim(remap_file),nf_nowrite,ifids(2))
        if(status.ne.nf_noerr) then
          write(6,*) 'nonexistent/non-netcdf remap file ',
     &          trim(remap_file)
          stop
        endif
      endif
      call scaleacc(ifids,accname,ifile)
      status = nf_close(ifids(1))
      if(ifids(2).ne.-99) status = nf_close(ifids(2))
      end program driver
__EOF__
======================== FILE ./model/mk_diags/scaleaccdrv.f
FILE: ./model/mk_diags/scaleaccdrv.f
      program driver
      implicit none
      include 'netcdf.inc'
      integer :: status,ifids(2)
      character(len=200) :: ifile,remap_file
      character(len=80) :: accname
      integer :: i1,i2,nargs
      !integer, external :: iargc
      nargs = iargc()
      if(nargs.ne.2 .and. nargs.ne.3) then
         write(6,*)
     &   'usage: scaleacc acc-file acc_array_name[,name2] [remap_file]'
         stop
      endif
      call getarg(1,ifile)
      call getarg(2,accname)
      i1 = index(ifile,'.acc')
      if(i1.eq.0) i1 = index(ifile,'.subdd')
      i2 = index(ifile,'.nc')
      if(i1.eq.0 .or. i1.gt.i2) then
        stop 'expecting filename of the form *.acc*.nc or *.subdd*.nc'
      endif
      status = nf_open(trim(ifile),nf_nowrite,ifids(1))
      if(status.ne.nf_noerr) then
        write(6,*) 'nonexistent/non-netcdf input file ',trim(ifile)
        stop
      endif
      ifids(2) = -99
      if(nargs.eq.3) then
        call getarg(3,remap_file)
        status = nf_open(trim(remap_file),nf_nowrite,ifids(2))
        if(status.ne.nf_noerr) then
          write(6,*) 'nonexistent/non-netcdf remap file ',
     &          trim(remap_file)
          stop
        endif
      endif
      call scaleacc(ifids,accname,ifile)
      status = nf_close(ifids(1))
      if(ifids(2).ne.-99) status = nf_close(ifids(2))
      end program driver
__EOF__
======================== FILE ./model/profiler/profiler_SOURCES.cmake
FILE: ./model/profiler/profiler_SOURCES.cmake
set(profiler_SOURCES
   ${CMAKE_CURRENT_SOURCE_DIR}/profiler/ProfileReport_mod.F90
   ${CMAKE_CURRENT_SOURCE_DIR}/profiler/ReportColumn_mod.F90
   ${CMAKE_CURRENT_SOURCE_DIR}/profiler/TimeFormatUtilities_mod.F90
   ${CMAKE_CURRENT_SOURCE_DIR}/profiler/TimerList_mod.F90
   ${CMAKE_CURRENT_SOURCE_DIR}/profiler/Timer_mod.F90
   ${CMAKE_CURRENT_SOURCE_DIR}/profiler/TimerPackage_mod.F90
)
__EOF__
======================== FILE ./model/shared/shared_SOURCES.cmake
FILE: ./model/shared/shared_SOURCES.cmake
# Remember that some .F90 files were preprocessed from .m4F90 files.
# TODO: We need to add in this code generation at some point.


# Pre-process m4F90 files
file(GLOB m4files "shared/*.m4F90")
foreach(file ${m4files})
   get_filename_component (name_without_extension ${file} NAME_WE)

   add_custom_command (
      COMMAND ${CMAKE_COMMAND} -E make_directory ${CMAKE_CURRENT_BINARY_DIR}/shared

      OUTPUT ${CMAKE_CURRENT_BINARY_DIR}/shared/${name_without_extension}.F90
      COMMAND m4
      ARGS -s -I${CMAKE_CURRENT_SOURCE_DIR}/shared ${file} > ${CMAKE_CURRENT_BINARY_DIR}/shared/${name_without_extension}.F90
      DEPENDS ${file}
   )
endforeach()


# Create a post-processed AttributeHashMap.F90
add_custom_command(
   COMMAND ${CMAKE_COMMAND} -E make_directory ${CMAKE_CURRENT_BINARY_DIR}/shared


   OUTPUT ${CMAKE_CURRENT_BINARY_DIR}/shared/AttributeHashMap.F90
   COMMAND ${CPP}
   ARGS -P -I${CMAKE_SOURCE_DIR}/model/include -I${CMAKE_SOURCE_DIR}/model/shared
   ${CMAKE_CURRENT_SOURCE_DIR}/shared/AttributeHashMap.F90 -o
   ${CMAKE_CURRENT_BINARY_DIR}/shared/AttributeHashMap.F90
   DEPENDS ${CMAKE_CURRENT_SOURCE_DIR}/shared/AttributeHashMap.F90


   OUTPUT ${CMAKE_CURRENT_BINARY_DIR}/shared/AbstractTimeStamp.F90
   COMMAND ${CPP}
   ARGS -P -I${CMAKE_SOURCE_DIR}/model/include -I${CMAKE_SOURCE_DIR}/model/shared
   ${CMAKE_CURRENT_SOURCE_DIR}/shared/AbstractTimeStamp.F90 -o
   ${CMAKE_CURRENT_BINARY_DIR}/shared/AbstractTimeStamp.F90
   DEPENDS ${CMAKE_CURRENT_SOURCE_DIR}/shared/AbstractTimeStamp.F90


   OUTPUT ${CMAKE_CURRENT_BINARY_DIR}/shared/CalendarDate.F90
   COMMAND ${CPP}
   ARGS -P -I${CMAKE_SOURCE_DIR}/model/include -I${CMAKE_SOURCE_DIR}/model/shared
   ${CMAKE_CURRENT_SOURCE_DIR}/shared/CalendarDate.F90 -o
   ${CMAKE_CURRENT_BINARY_DIR}/shared/CalendarDate.F90
   DEPENDS ${CMAKE_CURRENT_SOURCE_DIR}/shared/CalendarDate.F90
)



set(shared_SOURCES
   ${CMAKE_CURRENT_SOURCE_DIR}/shared/system_tools.c
   ${CMAKE_CURRENT_SOURCE_DIR}/shared/orbpar.f
   ${CMAKE_CURRENT_SOURCE_DIR}/shared/AbstractAttribute.F90
   ${CMAKE_CURRENT_SOURCE_DIR}/shared/ArrayBundle_mod.F90
   ${CMAKE_CURRENT_BINARY_DIR}/shared/AttributeDictionary.F90
   ${CMAKE_CURRENT_BINARY_DIR}/shared/AttributeHashMap.F90
   ${CMAKE_CURRENT_SOURCE_DIR}/shared/AttributeReference.F90
   ${CMAKE_CURRENT_BINARY_DIR}/shared/Attributes.F90
   ${CMAKE_CURRENT_SOURCE_DIR}/shared/Constants_mod.F90
   ${CMAKE_CURRENT_SOURCE_DIR}/shared/CubicEquation_mod.F90
   ${CMAKE_CURRENT_SOURCE_DIR}/shared/Dictionary_mod.F90
   ${CMAKE_CURRENT_SOURCE_DIR}/shared/FileManager_mod.F90
   ${CMAKE_CURRENT_SOURCE_DIR}/shared/GaussianQuadrature.F90
   ${CMAKE_CURRENT_SOURCE_DIR}/shared/GenericType_mod.F90
   ${CMAKE_CURRENT_SOURCE_DIR}/shared/Geometry_mod.F90
   ${CMAKE_CURRENT_SOURCE_DIR}/shared/GetTime_mod.F90
   ${CMAKE_CURRENT_SOURCE_DIR}/shared/KeyValuePair_mod.F90
   ${CMAKE_CURRENT_SOURCE_DIR}/shared/Parser_mod.F90
   ${CMAKE_CURRENT_SOURCE_DIR}/shared/MathematicalConstants.F90
   ${CMAKE_CURRENT_SOURCE_DIR}/shared/PlanetaryParams.F90
   ${CMAKE_CURRENT_SOURCE_DIR}/shared/PlanetParams_mod.F90
   ${CMAKE_CURRENT_SOURCE_DIR}/shared/PolynomialInterpolator.F90
   ${CMAKE_CURRENT_SOURCE_DIR}/shared/Precision_mod.F90
   ${CMAKE_CURRENT_SOURCE_DIR}/shared/Random_mod.F90
   ${CMAKE_CURRENT_SOURCE_DIR}/shared/RootFinding_mod.F90
   ${CMAKE_CURRENT_BINARY_DIR}/shared/RunTimeControls_mod.F90
   ${CMAKE_CURRENT_SOURCE_DIR}/shared/SpecialFunctions.F90
   ${CMAKE_CURRENT_SOURCE_DIR}/shared/stop_model.F90
   ${CMAKE_CURRENT_SOURCE_DIR}/shared/modele_python.F90
   ${CMAKE_CURRENT_SOURCE_DIR}/shared/StringUtilities_mod.F90
   ${CMAKE_CURRENT_SOURCE_DIR}/shared/System.F90
   ${CMAKE_CURRENT_SOURCE_DIR}/shared/dast.F90
   ${CMAKE_CURRENT_SOURCE_DIR}/shared/SystemTimers_mod.F90
   ${CMAKE_CURRENT_SOURCE_DIR}/shared/TimeConstants.F90
   ${CMAKE_CURRENT_SOURCE_DIR}/shared/Time.F90
   ${CMAKE_CURRENT_SOURCE_DIR}/shared/Utilities.F90
   ${CMAKE_CURRENT_SOURCE_DIR}/shared/SystemTools.F90
   ${CMAKE_CURRENT_SOURCE_DIR}/shared/KindParameters.F90
   ${CMAKE_CURRENT_SOURCE_DIR}/shared/Rational.F90
   ${CMAKE_CURRENT_SOURCE_DIR}/shared/BaseTime.F90
   ${CMAKE_CURRENT_SOURCE_DIR}/shared/TimeInterval.F90
   ${CMAKE_CURRENT_BINARY_DIR}/shared/AbstractTimeStamp.F90
   ${CMAKE_CURRENT_SOURCE_DIR}/shared/AnniversaryDate.F90
   ${CMAKE_CURRENT_BINARY_DIR}/shared/CalendarDate.F90
   ${CMAKE_CURRENT_SOURCE_DIR}/shared/CalendarMonth.F90
   ${CMAKE_CURRENT_SOURCE_DIR}/shared/AbstractCalendar.F90
   ${CMAKE_CURRENT_SOURCE_DIR}/shared/FixedCalendar.F90
   ${CMAKE_CURRENT_SOURCE_DIR}/shared/JulianCalendar.F90
   ${CMAKE_CURRENT_SOURCE_DIR}/shared/PlanetaryCalendar.F90
   ${CMAKE_CURRENT_SOURCE_DIR}/shared/Time.F90
   ${CMAKE_CURRENT_SOURCE_DIR}/shared/OrbitUtilities.F90
   ${CMAKE_CURRENT_SOURCE_DIR}/shared/AbstractOrbit.F90
   ${CMAKE_CURRENT_SOURCE_DIR}/shared/FixedOrbit.F90
   ${CMAKE_CURRENT_SOURCE_DIR}/shared/Earth365DayOrbit.F90
   ${CMAKE_CURRENT_SOURCE_DIR}/shared/ParameterizedEarthOrbit.F90
   ${CMAKE_CURRENT_SOURCE_DIR}/shared/PlanetaryOrbit.F90
   ${CMAKE_CURRENT_SOURCE_DIR}/shared/ModelClock.F90
)
__EOF__
======================== FILE ./model/solvers/dgtsv.f
FILE: ./model/solvers/dgtsv.f
! From LAPACK
! TODO: Replace this with "real" LAPACK
! Relationship between DGTSV and Numerical recipe's TRIDIAG:
! D(1..n) = b(1..n)
! DL(1..n-1) = a(2..n)
! DU(1..n-1) = c(1..n-1)

      SUBROUTINE DGTSV( N, NRHS, DL, D, DU, B, LDB, INFO )
*
*  -- LAPACK routine (version 3.3.1) --
*  -- LAPACK is a software package provided by Univ. of Tennessee,    --
*  -- Univ. of California Berkeley, Univ. of Colorado Denver and NAG Ltd..--
*  -- April 2011                                                      --
*
*     .. Scalar Arguments ..
      INTEGER            INFO, LDB, N, NRHS
*     ..
*     .. Array Arguments ..
      DOUBLE PRECISION   B( LDB, * ), D( * ), DL( * ), DU( * )
*     ..
*
*  Purpose
*  =======
*
*  DGTSV  solves the equation
*
*     A*X = B,
*
*  where A is an n by n tridiagonal matrix, by Gaussian elimination with
*  partial pivoting.
*
*  Note that the equation  A**T*X = B  may be solved by interchanging the
*  order of the arguments DU and DL.
*
*  Arguments
*  =========
*
*  N       (input) INTEGER
*          The order of the matrix A.  N >= 0.
*
*  NRHS    (input) INTEGER
*          The number of right hand sides, i.e., the number of columns
*          of the matrix B.  NRHS >= 0.
*
*  DL      (input/output) DOUBLE PRECISION array, dimension (N-1)
*          On entry, DL must contain the (n-1) sub-diagonal elements of
*          A.
*
*          On exit, DL is overwritten by the (n-2) elements of the
*          second super-diagonal of the upper triangular matrix U from
*          the LU factorization of A, in DL(1), ..., DL(n-2).
*
*  D       (input/output) DOUBLE PRECISION array, dimension (N)
*          On entry, D must contain the diagonal elements of A.
*
*          On exit, D is overwritten by the n diagonal elements of U.
*
*  DU      (input/output) DOUBLE PRECISION array, dimension (N-1)
*          On entry, DU must contain the (n-1) super-diagonal elements
*          of A.
*
*          On exit, DU is overwritten by the (n-1) elements of the first
*          super-diagonal of U.
*
*  B       (input/output) DOUBLE PRECISION array, dimension (LDB,NRHS)
*          On entry, the N by NRHS matrix of right hand side matrix B.
*          On exit, if INFO = 0, the N by NRHS solution matrix X.
*
*  LDB     (input) INTEGER
*          The leading dimension of the array B.  LDB >= max(1,N).
*
*  INFO    (output) INTEGER
*          = 0: successful exit
*          < 0: if INFO = -i, the i-th argument had an illegal value
*          > 0: if INFO = i, U(i,i) is exactly zero, and the solution
*               has not been computed.  The factorization has not been
*               completed unless i = N.
*
*  =====================================================================
*
*     .. Parameters ..
      DOUBLE PRECISION   ZERO
      PARAMETER          ( ZERO = 0.0D+0 )
*     ..
*     .. Local Scalars ..
      INTEGER            I, J
      DOUBLE PRECISION   FACT, TEMP
*     ..
*     .. Intrinsic Functions ..
      INTRINSIC          ABS, MAX
*     ..
*     .. External Subroutines ..
!      EXTERNAL           XERBLA
*     ..
*     .. Executable Statements ..
*
      INFO = 0
      IF( N.LT.0 ) THEN
         INFO = -1
      ELSE IF( NRHS.LT.0 ) THEN
         INFO = -2
      ELSE IF( LDB.LT.MAX( 1, N ) ) THEN
         INFO = -7
      END IF
      IF( INFO.NE.0 ) THEN
         CALL stop_model( 'DGTSV ', -INFO )
         RETURN
      END IF
*
      IF( N.EQ.0 )
     $   RETURN
*
      IF( NRHS.EQ.1 ) THEN
         DO 10 I = 1, N - 2
            IF( ABS( D( I ) ).GE.ABS( DL( I ) ) ) THEN
*
*              No row interchange required
*
               IF( D( I ).NE.ZERO ) THEN
                  FACT = DL( I ) / D( I )
                  D( I+1 ) = D( I+1 ) - FACT*DU( I )
                  B( I+1, 1 ) = B( I+1, 1 ) - FACT*B( I, 1 )
               ELSE
                  INFO = I
                  RETURN
               END IF
               DL( I ) = ZERO
            ELSE
*
*              Interchange rows I and I+1
*
               FACT = D( I ) / DL( I )
               D( I ) = DL( I )
               TEMP = D( I+1 )
               D( I+1 ) = DU( I ) - FACT*TEMP
               DL( I ) = DU( I+1 )
               DU( I+1 ) = -FACT*DL( I )
               DU( I ) = TEMP
               TEMP = B( I, 1 )
               B( I, 1 ) = B( I+1, 1 )
               B( I+1, 1 ) = TEMP - FACT*B( I+1, 1 )
            END IF
   10    CONTINUE
         IF( N.GT.1 ) THEN
            I = N - 1
            IF( ABS( D( I ) ).GE.ABS( DL( I ) ) ) THEN
               IF( D( I ).NE.ZERO ) THEN
                  FACT = DL( I ) / D( I )
                  D( I+1 ) = D( I+1 ) - FACT*DU( I )
                  B( I+1, 1 ) = B( I+1, 1 ) - FACT*B( I, 1 )
               ELSE
                  INFO = I
                  RETURN
               END IF
            ELSE
               FACT = D( I ) / DL( I )
               D( I ) = DL( I )
               TEMP = D( I+1 )
               D( I+1 ) = DU( I ) - FACT*TEMP
               DU( I ) = TEMP
               TEMP = B( I, 1 )
               B( I, 1 ) = B( I+1, 1 )
               B( I+1, 1 ) = TEMP - FACT*B( I+1, 1 )
            END IF
         END IF
         IF( D( N ).EQ.ZERO ) THEN
            INFO = N
            RETURN
         END IF
      ELSE
         DO 40 I = 1, N - 2
            IF( ABS( D( I ) ).GE.ABS( DL( I ) ) ) THEN
*
*              No row interchange required
*
               IF( D( I ).NE.ZERO ) THEN
                  FACT = DL( I ) / D( I )
                  D( I+1 ) = D( I+1 ) - FACT*DU( I )
                  DO 20 J = 1, NRHS
                     B( I+1, J ) = B( I+1, J ) - FACT*B( I, J )
   20             CONTINUE
               ELSE
                  INFO = I
                  RETURN
               END IF
               DL( I ) = ZERO
            ELSE
*
*              Interchange rows I and I+1
*
               FACT = D( I ) / DL( I )
               D( I ) = DL( I )
               TEMP = D( I+1 )
               D( I+1 ) = DU( I ) - FACT*TEMP
               DL( I ) = DU( I+1 )
               DU( I+1 ) = -FACT*DL( I )
               DU( I ) = TEMP
               DO 30 J = 1, NRHS
                  TEMP = B( I, J )
                  B( I, J ) = B( I+1, J )
                  B( I+1, J ) = TEMP - FACT*B( I+1, J )
   30          CONTINUE
            END IF
   40    CONTINUE
         IF( N.GT.1 ) THEN
            I = N - 1
            IF( ABS( D( I ) ).GE.ABS( DL( I ) ) ) THEN
               IF( D( I ).NE.ZERO ) THEN
                  FACT = DL( I ) / D( I )
                  D( I+1 ) = D( I+1 ) - FACT*DU( I )
                  DO 50 J = 1, NRHS
                     B( I+1, J ) = B( I+1, J ) - FACT*B( I, J )
   50             CONTINUE
               ELSE
                  INFO = I
                  RETURN
               END IF
            ELSE
               FACT = D( I ) / DL( I )
               D( I ) = DL( I )
               TEMP = D( I+1 )
               D( I+1 ) = DU( I ) - FACT*TEMP
               DU( I ) = TEMP
               DO 60 J = 1, NRHS
                  TEMP = B( I, J )
                  B( I, J ) = B( I+1, J )
                  B( I+1, J ) = TEMP - FACT*B( I+1, J )
   60          CONTINUE
            END IF
         END IF
         IF( D( N ).EQ.ZERO ) THEN
            INFO = N
            RETURN
         END IF
      END IF
*
*     Back solve with the matrix U from the factorization.
*
      IF( NRHS.LE.2 ) THEN
         J = 1
   70    CONTINUE
         B( N, J ) = B( N, J ) / D( N )
         IF( N.GT.1 )
     $      B( N-1, J ) = ( B( N-1, J )-DU( N-1 )*B( N, J ) ) / D( N-1 )
         DO 80 I = N - 2, 1, -1
            B( I, J ) = ( B( I, J )-DU( I )*B( I+1, J )-DL( I )*
     $                  B( I+2, J ) ) / D( I )
   80    CONTINUE
         IF( J.LT.NRHS ) THEN
            J = J + 1
            GO TO 70
         END IF
      ELSE
         DO 100 J = 1, NRHS
            B( N, J ) = B( N, J ) / D( N )
            IF( N.GT.1 )
     $         B( N-1, J ) = ( B( N-1, J )-DU( N-1 )*B( N, J ) ) /
     $                       D( N-1 )
            DO 90 I = N - 2, 1, -1
               B( I, J ) = ( B( I, J )-DU( I )*B( I+1, J )-DL( I )*
     $                     B( I+2, J ) ) / D( I )
   90       CONTINUE
  100    CONTINUE
      END IF
*
      RETURN
*
*     End of DGTSV
*
      END
__EOF__
======================== FILE ./model/solvers/solvers_SOURCES.cmake
FILE: ./model/solvers/solvers_SOURCES.cmake
set(solvers_SOURCES
   ${CMAKE_CURRENT_SOURCE_DIR}/solvers/TRIDIAG.f
   ${CMAKE_CURRENT_SOURCE_DIR}/solvers/dgtsv.f
)
__EOF__
======================== FILE ./python/lib/modele/__init__.py
FILE: ./python/lib/modele/__init__.py

__EOF__
======================== FILE ./python/lib/modele/pathutil.py
FILE: ./python/lib/modele/pathutil.py
import os

# http://code.activestate.com/recipes/52224-find-a-file-given-a-search-path/
def search_file(filename, search_path):
    """Given a search path, find file
    """
    if os.path.exists(filename):
        return os.path.abspath(filename)

    for path in search_path:
        fname = os.path.abspath(os.path.join(path, filename))
        if os.path.exists(fname):
            return fname
    raise IOError('File not found in search path: {0}'.format(filename))


# Returns the root of this ModelE installation
def modele_root():
    dir = os.path.dirname(os.path.realpath(__file__))
    return os.path.realpath(os.path.join(dir, '..', '..', '..'))
__EOF__
======================== FILE ./python/lib/modele/rundeck/__init__.py
FILE: ./python/lib/modele/rundeck/__init__.py
from modele.rundeck import legacy
import datetime
import os
import sys
from modele import pathutil
import copy
import urllib2
from modele import xhash

# parameter types
GENERAL = 'GENERAL'
FILE = 'FILE'
DATETIME = 'DATETIME'

class Param(object):
    def __init__(self, pname, type, value, sval=None):
        self.pname = pname
        self.type = type
        self.value = value
        self.sval = sval    # Raw unparsed value, if appropriate

        if id(self.type) == id(DATETIME):
            dt = self.value
            if not isinstance(dt, datetime.datetime):
                raise ValueError('Values of type DATETYPE must have Python type datetime.datetime')
            if (dt.minute!=0) or (dt.second !=0) or (dt.microsecond!=0):
                raise ValueError('Values of type DATETYPE must be on the hour.  Error in: {0}'.format(dt))
            if (dt.tzinfo is not None):
                raise ValueError('Values of type DATETYPE cannot have a timezone.  Error in: {0}'.format(dt))

    def __lt__(self, other):
        return self.pname < other.pname

    def __repr__(self):
        return repr((self.pname, self.type, self.value))

    def sname(self):
        return '.'.join(pname)

def replace_date(dd, suffix, result):
    try:
        yeari = int(dd['YEAR'+suffix])
        monthi = int(dd['MONTH'+suffix])
        datei = int(dd['DATE'+suffix])
        houri = int(dd['HOUR'+suffix])
        dd[result] = datetime.datetime(yeari, monthi, datei, houri, 0, 0)
        del dd['YEAR'+suffix]
        del dd['MONTH'+suffix]
        del dd['DATE'+suffix]
        del dd['HOUR'+suffix]
    except KeyError:
        pass



class Params(dict):
    def __init__(self, file_path, auto_download=False):
        """auto_download:
            Download files we can't find locally?"""
        self.file_path = file_path
        self.auto_download = auto_download

    def add(self,param):
        self[param.pname] = param

    def __repr__(self):
        return '\n'.join([repr(x) for x in sorted(list(self.values()))])
        

    def download_file(self, sval):
        # Only try to download if it's a raw leafname
        if len(os.path.split(sval)[0]) > 0:
            return None

        # Try to download the file
        # http://stackoverflow.com/questions/22676/how-do-i-download-a-file-over-http-using-python
        file_name = os.path.join(self.file_path[0], sval)
        url = 'http://portal.nccs.nasa.gov/GISS_modelE/modelE_input_data/' + sval

        with open(file_name, 'wb') as fout:
            u = urllib2.urlopen(url)
            meta = u.info()
            file_size = int(meta.getheaders("Content-Length")[0])
            print "Downloading: %s Bytes: %s" % (file_name, file_size)

            file_size_dl = 0
            block_sz = 8192
            while True:
                buffer = u.read(block_sz)
                if not buffer:
                    break

                file_size_dl += len(buffer)
                fout.write(buffer)
                status = r"%10d  [%3.2f%%]" % (file_size_dl, file_size_dl * 100. / file_size)
                status = status + chr(8)*(len(status)+1)
                print status,
        return file_name


    def set_file(self, symbol, fname):
        ret = True
        try:
            fname_full = pathutil.search_file(fname, self.file_path)
        except IOError as e:
#            try:
#                fname_full = self.download_file(fname)
#            except Exception as e2:
#                print(e2)
                sys.stderr.write('{0}: {1}\n'.format(symbol, e))
                ret = False    # Error condition
                fname_full = None

        self.add(Param((symbol,), FILE, fname_full, sval=fname))
        return ret


    def add_legacy(self, legacy):
        """Extract rundeck parametesr from a legacy rundeck."""
        ret = True
        for symbol,fname in legacy['Data input files']:
                ret = ret and self.set_file(symbol, fname)


        for symbol,value in legacy['Parameters']:
            param = Param((symbol,), GENERAL, value)
            self.add(param)

        # ------- Deal with the namelists

        # Split into a series of namelists, splitting on 'ISTART=...'
        inputz = legacy['InputZ']
        inputzs = list()
        inputz_cur = list()
        for item in inputz:
            if item[0].upper() == 'ISTART':
                if len(inputz_cur) > 0:
                    inputzs.append(dict(inputz_cur))
                inputz_cur = list()
            inputz_cur.append((item[0].upper(), item[1]))
        inputzs.append(dict(inputz_cur))
    
        for inputz in inputzs:
            replace_date(inputz, 'I', 'START_TIME')
            replace_date(inputz, 'E', 'END_TIME')

        if len(inputzs) > 2:
            raise ValueError('At most one ISTART line is allowed')

        prefixes = ('INPUTZ', 'INPUTZ_cold')
        for prefix,inputz in zip(prefixes,inputzs):
            for symbol,value in inputz.items():
                type = DATETIME if isinstance(value, datetime.datetime) else GENERAL
                self.add(Param((prefix,symbol), type, value))

        return ret
# ------------------------------------------
class Build(object):
    def __init__(self):
        self.sources = set()    # Object Modules
        self.components = dict()    # Directories of sources --> options

        self.defines = dict()    # Preprocessor Options

    def update_hash(self, hash):
        xhash.update(self.sources, hash)
        xhash.update(self.components, hash)
        xhash.update(self.defines, hash)

    def add_legacy(self, legacy):
        for src in legacy['Object Modules']:
            self.sources.add(src)
        for symbol,value in legacy['Preprocessor Options']:
            self.defines[symbol] = value
        for component in legacy['Components']:
            self.components[component] = None

        for component,options in legacy['Component Options']:
            if component not in self.components:
                raise ValueError('Options found for non-existant component %s' % component)
            self.components[component] = dict(options)



# ------------------------------------------
class ChangeSysPath(object):
    def __init__(self, new_path):
        self.new_path = new_path
    def __enter__(self):
        self.old_path = sys.path
        sys.path = self.new_path
    def __exit__(self, type, value, traceback):
        sys.path = self.old_path

def load_rundeck(fname, template_path=None, file_path=None, auto_download=True):
    if template_path is None:
        template_path = copy.copy(default_template_path)

    # Resolve the rundeck filename
    fname = pathutil.search_file(fname, default_template_path)

    # Add the directory of the rundeck to the path
    dirname,leafname = os.path.split(fname)
    template_path = [dirname] + template_path

    # Create a blank rundeck
    rd = Rundeck(template_path=template_path, auto_download=auto_download)

    root,ext = os.path.splitext(leafname)
    if ext == '.py':
        # Load Python-format rundeck
        with ChangeSysPath(rd.template_path + sys.path):
            globals = dict()
            rd_code = __import__(root, globals)
            rd_code.setup(rd)
    else:
        # Load legacy-format rundeck
        rd.load_legacy(fname)

    return rd


# ------------------------------------------
try:
    MODELE_TEMPLATE_PATH = os.environ['MODELE_TEMPLATE_PATH'].split(os.pathsep)
except:
    MODELE_TEMPLATE_PATH = []

default_template_path = MODELE_TEMPLATE_PATH + [os.path.join(pathutil.modele_root(), 'templates')]

# Search for input files
try:
    default_file_path = os.environ['MODELE_FILE_PATH'].split(os.pathsep)
except Exception as e:
    default_file_path = ['.']
# ------------------------------------------

class Rundeck(object):
    def __init__(self, template_path=None, file_path=None, auto_download=False):
        if template_path is None:
            self.template_path = default_template_path
        else:
            self.template_path = template_path
        if file_path is None:
            self.file_path = default_file_path
        else:
            self.file_path = file_path

        self.preamble = None
        self.params = Params(self.file_path, auto_download=auto_download)
        self.build = Build()

    def update_hash(self, hash):
        xhash.update(self.build, hash)

    def set(self, name, type, value):
        if id(type) == id(FILE):
            self.params.set_file(name, value)
        else:
            return self.params.add(Param((name,), type, value))

    def add_legacy(self, legacy):
        self.preamble = legacy['preamble']
        self.params.add_legacy(legacy)
        self.build.add_legacy(legacy)

    def load_legacy(self, fname, template_path=None, file_path=None):
        if template_path is None:
            template_path = default_template_path
        if file_path is None:
            file_path = default_file_path

        fname_full = pathutil.search_file(fname, template_path)

        fin = legacy.preprocessor(fname_full, template_path)
        legacy_rundeck = legacy.read_rundeck(fin)       # Auto-closes
        self.add_legacy(legacy_rundeck)

    def __repr__(self):
        return '\n'.join(('============= Rundeck',
            '--------- Preamble', \
            repr(self.preamble),
            '--------- Params', \
            repr(self.params),
            '-------- Sources', \
            repr(self.build.sources),
            '-------- Components', \
            repr(self.build.components),
            '-------- Defines', \
            repr(self.build.defines)))
__EOF__
======================== FILE ./python/lib/modele/rundeck/legacy.py
FILE: ./python/lib/modele/rundeck/legacy.py
from __future__ import print_function
import io
import re
import os
import sys

def find_in_path(fname, search_path):
    for path in search_path:
        candidate = os.path.join(path, fname)
        if os.path.exists(candidate):
            return candidate
    raise ValueError('File not found in path: %s' % fname)

includeRE = re.compile(b'\s*#include\s*"(.*?)"\s*(!\s*)?')

def preprocessor(fname, search_path):
    """Load a fully preprocessed rundeck from the templates directory.
    Works as a generator, producing one line at a time."""
    try:
        with open(fname, 'rb') as fin:
            while True:
                line = next(fin)
                match = includeRE.match(line)
                if match is None:
                    yield line
                else:
                    leaf1 = match.group(1).decode()
                    fname1 = find_in_path(leaf1, search_path)
                    yield ('! ---------- BEGIN #include %s\n' % fname1).encode()
                    for line1 in preprocessor(fname1, search_path):
                        yield line1
                    yield ('! ---------- END #include %s\n' % fname1).encode()
    except EOFError:
        pass

# -------------------------------------------------------------------------
def iterable_to_stream(iterable, buffer_size=io.DEFAULT_BUFFER_SIZE):
    """
    Lets you use an iterable (e.g. a generator) that yields bytestrings as a read-only
    input stream.

    The stream implements Python 3's newer I/O API (available in Python 2's io module).
    For efficiency, the stream is buffered.

    See: http://stackoverflow.com/questions/6657820/python-convert-an-iterable-to-a-stream
    """
    class IterStream(io.RawIOBase):
        def __init__(self):
            self.leftover = None
        def readable(self):
            return True
        def readinto(self, b):
            try:
                l = len(b)  # We're supposed to return at most this much
                chunk = self.leftover or next(iterable)
                output, self.leftover = chunk[:l], chunk[l:]
                b[:len(output)] = output
                return len(output)
            except StopIteration:
                return 0    # indicate EOF
    return io.BufferedReader(IterStream(), buffer_size=buffer_size)

# =====================================================================
# ----------------------------------------------------------

# Finds the division between preprocessor sections
sectionRE = re.compile(r'\s*((Preamble:?)|(Preprocessor\s+Options:?)|(Run\s+Options:?)|(Object\s+modules:?)|(Components:?)|(Component\s+Options:?)|(Data\s+input\s+files:?)|(&&PARAMETERS)|(&INPUTZ))\s*')
num_sections = 9

def parse_section(fin, parse_line):
    """Rundecks are grouped in sections.  This parses the current section, and
    reports the section type of the next section."""
    while True:
        line = next(fin)    # Pass along EOFException
        match = sectionRE.match(line)
        if match is None:
            parse_line(line)
        else:
            groups = match.groups()[1:]     # Skip the top-level group
            for i in range(0,len(groups)):
                if groups[i] is not None:
                    return i        # Next section
            raise ValueError('Could not find next section for ' + line)
# ----------------------------------------------------------
def remove_comments(line):
    # Remove Fortran-style comments
    exp = line.find('!')
    if (exp >= 0): line = line[:exp]

    # Remove C-style comments too
    # http://stackoverflow.com/questions/2319019/using-regex-to-remove-comments-from-source-files
    line = re.sub(re.compile("/\*.*?\*/",re.DOTALL ) ,"" ,line)

    line = line.strip()
    return line

# ----------------------------------------------------------
# Parsers for the different sections
class Parser(object):
    def __init__(self):
        self.section = list()

class CopyLines(Parser):
    def __call__(self, line):
        self.section.append(line)

class CopyLinesNoComments(Parser):
    def __call__(self, line):
        line = remove_comments(line)
        if len(line) > 0:
            self.section.append(line)



preprocessorRE = re.compile(r'\s*#define\s+([^\s]*)(\s+(.*))?')
class PreprocessorOptions(Parser):
    def __call__(self, line):
        line = remove_comments(line)

        match = preprocessorRE.match(line)
        if match is not None:
            self.section.append((match.group(1), match.group(3)))

key_eq_valueRE = re.compile(r'\s*([^=\s]*)\s*=\s*([^!]*).*')
class KeyEqValue(Parser):
    def __call__(self, line):
        line = remove_comments(line)

        match = key_eq_valueRE.match(line)
        if match is not None:
            self.section.append((match.group(1), match.group(2).strip()))

class ComponentOptions(Parser):
    def __call__(self, line):
        line = remove_comments(line)

        match = key_eq_valueRE.match(line)
        if match is not None:
            scomp = match.group(1)
            options = match.group(2).strip()
            parsed_options = []

            if scomp.startswith('OPTS_'):
                component = scomp[5:]
            else:
                component = scomp

            for opt in options.split(' '):
                if len(opt) == 0: continue
                words = opt.split('=')
                if len(words) != 2:
                    raise ValueError('Bad component option {0}'.format(opt))
                parsed_options.append((words[0].strip(), words[1].strip()))
            self.section.append((component, tuple(parsed_options)))

class NameList(Parser):
    def __call__(self, line):
        line = remove_comments(line)

        eqs = line.split('=')
        eqs2 = []
        for x in eqs:
            comma = x.rfind(',')
            if (comma < 0):
                eqs2.append((x,))
            else:
                eqs2.append((x[:comma], x[comma+1:]))

        eqs3 = list()
        for i in range(0,len(eqs)-1):
            self.section.append((eqs2[i][-1].strip(), eqs2[i+1][0].strip()))

class InputZ(Parser):
    def __call__(self, line):
        line = remove_comments(line)

        for ll in line.split(','):
            match = key_eq_valueRE.match(ll)
            if match is not None:
                self.section.append((match.group(1), match.group(2).strip()))

class WordList(Parser):
    def __call__(self, line):
        line = remove_comments(line)

        words = line.split(' ')
        for word in words:
            word = word.strip()
            if len(word) > 0: self.section.append(word)
# ----------------------------------------------------------
class Legacy(dict):
    def __repr__(self):
        out = list()

        for title,values in self.items():
            out.append(('---------------- %s' % title))
            out.append(repr(values))

        return '\n'.join(out)


def read_rundeck(fin):
    """fin:
        Line generator producing the legacy rundeck."""
    buf = []
    section = 0

    section_parsers = [
        ('preamble', CopyLines()),
        ('Preprocessor Options', PreprocessorOptions()),
        ('Run Options', KeyEqValue()),
        ('Object Modules', WordList()),
        ('Components', WordList()),
        ('Component Options', ComponentOptions()),
        ('Data input files', KeyEqValue()),
        ('Parameters', KeyEqValue()),
        ('InputZ', NameList())
    ]

    while True:
        try:
            section = parse_section(fin, section_parsers[section][1])
        except StopIteration:
            break

    ret = Legacy()
    for parser in section_parsers:
        ret[parser[0]] = parser[1].section
    return ret


__EOF__
======================== FILE ./python/lib/modele/rundir.py
FILE: ./python/lib/modele/rundir.py
from modele import rundeck

import sys
import os
import string
import tempfile
import filecmp
import shutil
from modele import pathutil

# TODO: Be careful not to leave around zero-length files when downloading

# --------------------------------------

def namelist_time(suffix, dt):
    return 'YEAR{0}={1},MONTH{0}={2},DATE{0}={3},HOUR{0}={4},' \
        .format(suffix,dt.year,dt.month,dt.day,dt.hour)

def make_rundir(rd, rundir):
    ret = True

    # output line sections
    parameters = []
    data_files = []
    data_lines = []
    inputz = []
    inputz_cold = []

    # Organize parameters into ModelE sections
    for param in sorted(list(rd.params.values())):
        pname = param.pname
        if len(pname) == 1:
            if (id(param.type) == id(rundeck.FILE)):
                if param.value is not None:
                    data_lines.append(" _file_{0}='{1}'".format(pname[0], param.value))
                    data_files.append((pname[0], param.value))
#                else:
#                    parameters.append("! Not Found: {0}={1}".format(pname[0], param.sval))

            elif (id(param.type) == id(rundeck.GENERAL)):
                parameters.append(' %s=%s' % (param.pname[0], param.value))
            elif (id(param.type) == id(rundeck.DATETIME)):
                raise ValueError('Cannot put DATETIME values into parameters section of rundeck.')
            else:
                raise ValueError('Unknown parameter type %s' % param.type)
        elif len(pname) == 2:
            if pname[0].lower() == 'inputz':
                iz = inputz
            elif pname[0].lower() == 'inputz_cold':
                iz = inputz_cold
            else:
                raise ValueError('Unknown compund name: {0}'.format(pname))

            if pname[1].upper() == 'END_TIME':
                iz.append(namelist_time('E', param.value))
            elif pname[1].upper() == 'START_TIME':
                iz.append(namelist_time('I', param.value))
            else:
                iz.append('{0}={1},'.format(pname[1],param.value))



    # ------- Make the rundir
    try:
        os.makedirs(rundir)
    except OSError:
        pass
    try:
        os.remove(os.path.join(rundir, 'I'))
    except OSError:
        pass

    # -------- Remove old symlinks
    for label, fname in data_files:
        try:
            os.remove(os.path.join(rundir, label))
        except OSError:
            pass

    # -------- Link data files
    for label, fname in data_files:
        os.symlink(fname, os.path.join(rundir, label))

    # Write them out to the I file
    fname = os.path.join(rundir, 'I')
    out = open(fname, 'w')
    out.write(rd.preamble[0])    # First line of preamble
    out.write('\n')

    out.write('&&PARAMETERS\n')
    out.write('\n'.join(parameters))
    out.write('\n')
    out.write('\n'.join(data_lines))
    out.write('\n&&END_PARAMETERS\n')

    out.write('\n&INPUTZ\n')
    out.write('\n'.join(inputz))
    out.write('\n/\n\n')

    out.write('&INPUTZ_cold\n')
    out.write('\n'.join(inputz_cold))
    out.write('\n/\n')
__EOF__
======================== FILE ./python/lib/modele/tests/__init__.py
FILE: ./python/lib/modele/tests/__init__.py
__EOF__
======================== FILE ./python/lib/modele/tests/rundeck1a.R
FILE: ./python/lib/modele/tests/rundeck1a.R
e4f40.R GISS Model E  1850 ocn/atm          larissa        04/15/2010

!! E4F40 is for NIsurf=1 (U00a=0.72; U00b=1.68)

!! delete lines starting with '!!' unless E4F40 prepares a q-flux ocean run
!! E4qsF40.R GISS Model E  1850 atm, ocn: q-flux 65m             rar 07/15/2009

!! E4qsF40 = E4F40 with 65m q-flux ocean
e4f40 = modelE as frozen in April 2010:
modelE1 (3.0) 2x2.5 hor. grid with 40 lyrs, top at .1 mb (+ 3 rad.lyrs)
atmospheric composition from year 1850
ocean data: prescribed, 1876-1885 climatology
uses turbulence scheme (no dry conv), grav.wave drag
time steps: dynamics 3.75 min leap frog; physics 30 min.; radiation 2.5 hrs
filters: U,V in E-W and N-S direction (after every physics time step)
         U,V in E-W direction near poles (after every dynamics time step)
         sea level pressure (after every physics time step)

Preprocessor Options
#define NEW_IO                   ! new I/O (netcdf) on
#define USE_ENT                  ! include dynamic vegetation model
#define SWFIX_20151201
#define NO_HDIURN                ! exclude hdiurn diagnostics
#define MODIS_LAI
End Preprocessor Options

Object modules:
     ! resolution-specific source codes
Atm144x90                           ! horizontal resolution is 144x90 -> 2x2.5deg
AtmL40                              ! vertical resolution is 40 layers -> 0.1mb
DIAG_RES_F                          ! diagnostics
FFT144                              ! Fast Fourier Transform

IO_DRV                              ! new i/o

     ! GISS dynamics with gravity wave drag
ATMDYN MOMEN2ND                     ! atmospheric dynamics
QUS_DRV QUS3D                       ! advection of Q/tracers
STRATDYN STRAT_DIAG                 ! stratospheric dynamics (incl. gw drag)

    ! lat-lon grid specific source codes
AtmRes
GEOM_B                              ! model geometry
DIAG_ZONAL GCDIAGb                  ! grid-dependent code for lat-circle diags
DIAG_PRT POUT                       ! diagn/post-processing output
MODEL_COM                           ! calendar, timing variables
MODELE_DRV                          ! ModelE cap
MODELE                              ! initialization and main loop
ATM_COM                             ! main atmospheric variables
ATM_DRV                             ! driver for atmosphere-grid components
ATMDYN_COM                          ! atmospheric dynamics
ATM_UTILS                           ! utilities for some atmospheric quantities
QUS_COM QUSDEF                      ! T/Q moments, 1D QUS
CLOUDS2 CLOUDS2_DRV CLOUDS_COM      ! clouds modules
SURFACE SURFACE_LANDICE FLUXES      ! surface calculation and fluxes
GHY_COM GHY_DRV    ! + giss_LSM     ! land surface and soils + snow model
VEG_DRV                             ! vegetation
! VEG_COM VEGETATION                ! old vegetation
ENT_DRV  ENT_COM   ! + Ent          ! new vegetation
PBL_COM PBL_DRV PBL                 ! atmospheric pbl
ATURB                               ! turbulence in whole atmosphere
LAKES_COM LAKES                     ! lake modules
SEAICE SEAICE_DRV                   ! seaice modules
LANDICE LANDICE_COM LANDICE_DRV     ! land ice modules
ICEDYN_DRV ICEDYN                   ! ice dynamics modules
RAD_COM RAD_DRV RADIATION           ! radiation modules
RAD_UTILS ALBEDO READ_AERO ocalbedo ! radiation and albedo
DIAG_COM DIAG DEFACC                ! diagnostics
OCN_DRV                             ! driver for ocean-grid components
OCEAN OCNML                         ! ocean modules

Components:
shared MPI_Support solvers giss_LSM 
dd2d
Ent

Component Options:
OPTS_Ent = ONLINE=YES PS_MODEL=FBB PFT_MODEL=ENT 
OPTS_giss_LSM = USE_ENT=YES           
OPTS_dd2d = NC_IO=PNETCDF

Data input files:
    ! start from the restart file of an earlier run ...                 ISTART=8
! AIC=1....rsfE... ! initial conditions, no GIC needed, use
!! AIC=1JAN1961.rsfE4F40.MXL65m  ! end of run with KOCEAN=0

    ! start from observed conditions AIC(,OIC), model ground data GIC   ISTART=2
AIC=AIC.RES_F40.D771201.nc      ! observed init cond (atm. only)
!AIC=NCARIC.144x90.D7712010_ext.nc ! AIC for automatic relayering to model vertical grid
GIC=GIC.144X90.DEC01.1.ext_1.nc ! initial ground conditions
! prescr. climatological ocean (1 yr of data)
OSST=OST_144x90.1876-1885avg.HadISST1.1.nc
! prescr. climatological sea ice
SICE=SICE_144x90.1876-1885avg.HadISST1.1.nc
ZSIFAC=SICE_144x90.1876-1885avg.HadISST1.1.nc
!! q-flux ocean: use the next line instead,       set KOCEAN=1
!! OHT=OTSPEC.E4F40.MXL65m.1956-1960            ! ocean horizontal heat transports
!! OCNML is not used if KOCEAN=0, but needed in and to prepare for q-flux model
OCNML=Z1O.B144x90.nc                               ! mixed layer depth
TOPO=Z2HX2fromZ1QX1N.nc

RVR=RD_Fb.nc             ! river direction file
NAMERVR=RD_Fb.names.txt  ! named river outlets

CDN=CD144X90.ext.nc
VEG=V144x90_EntMM16_lc_max_trimmed_scaled_nocrops.nc
LAIMAX=V144x90_EntMM16_lai_max_trimmed_scaled_ext1.nc
HITEent=V144x90_EntMM16_height_trimmed_scaled_ext1.nc
LAI=V144x90_EntMM16_lai_trimmed_scaled_ext1.nc
CROPS=CROPS_and_pastures_Pongratz_to_Hurtt_144X90N_nocasp.nc
SOIL=S144X900098M.ext.nc
TOP_INDEX=top_index_144x90_a.ij.ext.nc
ZVAR=ZVAR2X25A.nc             ! topographic variation for gwdrag
! probably need these (should convert to 144x90)
soil_textures=soil_textures_top30cm_2x2.5
SOILCARB_global=soilcarb_top30cm_2x2.5.nc
GLMELT=GLMELT_144X90_gas.OCN.nc
RADN1=sgpgxg.table8                           ! rad.tables and history files
RADN2=LWTables33k_lowH2O_CO2_O3_planck_1-800  ! rad.tables and history files
RADN4=LWCorrTables33k                         ! rad.tables and history files
RADN5=H2Ocont_MT_CKD  ! Mlawer/Tobin_Clough/Kneizys/Davies H2O continuum table
! other available H2O continuum tables:
!    RADN5=H2Ocont_Ma_2000
!    RADN5=H2Ocont_Ma_2004
!    RADN5=H2Ocont_Roberts
!    RADN5=H2Ocont_MT_CKD  ! Mlawer/Tobin_Clough/Kneizys/Davies
RADN3=miescatpar.abcdv2

RH_QG_Mie=oct2003.relhum.nr.Q633G633.table
RADN7=STRATAER.VOL.1850-2012.May13_hdr
RADN8=cloud.epsilon4.72x46
RADN9=solar.lean2015.ann1610-2014_hdr ! need KSOLAR=2
RADNE=topcld.trscat8

ISCCP=ISCCP.tautables
GHG=GHG_RCP45.txt ! use GHG.Jul2009.txt for runs that start before 1850
dH2O=dH2O_by_CH4_monthly
DUSTaer=dust_mass_CakmurMillerJGR06_144x90x20x7x12.nc
BC_dep=BC.Dry+Wet.depositions.ann_144x90.nc
! updated aerosols need MADAER=3
TAero_SUL=SUL_Koch2008_kg_m2_144x90x20_1890-2000h.nc
TAero_SSA=SSA_Koch2008_kg_m2_144x90x20h.nc
TAero_NIT=NIT_Bauer2008_kg_m2_144x90x20_1890-2000h.nc
TAero_OCA=OCA_Koch2008_kg_m2_144x90x20_1890-2000h.nc
TAero_BCA=BCA_Koch2008_kg_m2_144x90x20_1890-2000h.nc
TAero_BCB=BCB_Koch2008_kg_m2_144x90x20_1890-2000h.nc
O3file=o3_2010_shindell_144x90x49_1850-2000.nc

MSU_wts=MSU.RSS.weights.data      ! MSU-diag
REG=REG2X2.5                      ! special regions-diag

Label and Namelist:  (next 2 lines)
e4f40 (NIsurf=2; modelE as frozen in June 2009, 1850 atmosph. cond., Ent veget.,
with gravity wave drag, prescribed ocean)

&&PARAMETERS
! parameters set for choice of ocean model:
KOCEAN=0        ! ocean is prescribed
!! KOCEAN=1        ! ocean is computed
Kvflxo=0        ! usually set to 1 only during a prescr.ocn run by editing "I"
!  Kvflxo=1     ! saves VFLXO files to prepare for q-flux runs (mkOTSPEC)

variable_lk=1   ! variable lakes

! drag params if grav.wave drag is not used and top is at .01mb
X_SDRAG=.002,.0002  ! used above P(P)_sdrag mb (and in top layer)
C_SDRAG=.0002       ! constant SDRAG above PTOP=150mb
P_sdrag=1.          ! linear SDRAG only above 1mb (except near poles)
PP_sdrag=1.         ! linear SDRAG above PP_sdrag mb near poles
P_CSDRAG=1.         ! increase CSDRAG above P_CSDRAG to approach lin. drag
Wc_JDRAG=30.        ! crit.wind speed for J-drag (Judith/Jim)
ANG_sdrag=1     ! if 1: SDRAG conserves ang.momentum by adding loss below PTOP
! vsdragl is a tuning coefficient for SDRAG starting at LS1
! layer:   24    25    26    27   28    29    30    31   32   33     34   35   36  37  38   39 40
vsdragl=0.000,0.000,0.000,0.000,0.00,0.000,0.000,0.000,0.00,0.00,  0.00,0.00,0.00,0.3,0.6,0.83,1.

! Gravity wave parameters
PBREAK = 200.  ! The level for GW breaking above.
DEFTHRESH=0.000055 ! threshold (1/s) for triggering deformation waves
PCONPEN=400.   ! penetrating convection defn for GWDRAG
CMC = 0.0000002 ! parameter for GW Moist Convective drag
CSHEAR=10.     ! Shear drag coefficient
CMTN=0.1       ! default is 0.5
CDEF=1.6       ! tuning factor for deformation -> momentum flux
XCDNST=400.,10000.   ! strat. gw drag parameters
QGWMTN=1 ! mountain waves ON
QGWDEF=1 ! deformation waves ON
QGWSHR=0 ! shear drag OFF
QGWCNV=0 ! convective drag OFF


! cond_scheme=2   ! newer conductance scheme (N. Kiang) ! not used with Ent

! The following two lines are only used when aerosol/radiation interactions are off
FS8OPX=1.,1.,1.,1.,1.5,1.5,1.,1.
FT8OPX=1.,1.,1.,1.,1.,1.,1.,1.

! Increasing U00a decreases the high cloud cover; increasing U00b decreases net rad at TOA
U00a=0.72 ! above 850mb w/o MC region;  tune this first to get 30-35% high clouds
U00b=1.68 ! below 850mb and MC regions; tune this last  to get rad.balance
WMUI_multiplier = 1.
use_vmp=1
radius_multiplier=1.1

PTLISO=15.       ! press(mb) above which rad. assumes isothermal layers
H2ObyCH4=1.      ! activates strat.H2O generated by CH4
KSOLAR=2         ! 2: use long annual mean file ; 1: use short monthly file

! parameters that control the atmospheric/boundary conditions
! if set to 0, the current (day/) year is used: transient run
master_yr=1850
!crops_yr=1850  ! if -1, crops in VEG-file is used
!s0_yr=1850
!s0_day=182
!ghg_yr=1850
!ghg_day=182
volc_yr=-1
!volc_day=182
!aero_yr=1850
od_cdncx=0.        ! don't include 1st indirect effect
cc_cdncx=0.        ! don't include 2nd indirect effect (used 0.0036)
!albsn_yr=1850
dalbsnX=.024
!o3_yr=-1850
!aer_int_yr=1850    !select desired aerosol emissions year or 0 to use JYEAR
! atmCO2=368.6          !uatm for year 2000 - enable for CO2 tracer runs

!variable_orb_par=0
!orb_par_year_bp=100  !  BP i.e. 1950-orb_par_year_bp AD = 1850 AD
madaer=3         ! 3: updated aerosols          ; 1: default sulfates/aerosols

DTsrc=1800.      ! cannot be changed after a run has been started
DT=225.
! parameters that control the Shapiro filter
DT_XUfilter=225. ! Shapiro filter on U in E-W direction; usually same as DT
DT_XVfilter=225. ! Shapiro filter on V in E-W direction; usually same as DT
DT_YVfilter=0.   ! Shapiro filter on V in N-S direction
DT_YUfilter=0.   ! Shapiro filter on U in N-S direction

NIsurf=2         ! (surf.interaction NIsurf times per physics time step)
NRAD=5           ! radiation (every NRAD'th physics time step)
! parameters that affect at most diagn. output:  standard if DTsrc=1800. (sec)
aer_rad_forc=0   ! if set =1, radiation is called numerous times - slow !!
cloud_rad_forc=1 ! calls radiation twice; use =0 to save cpu time
SUBDD=' '        ! no sub-daily frequency diags
NSUBDD=0         ! saving sub-daily diags every NSUBDD-th physics time step (1/2 hr)
KCOPY=2          ! saving acc + rsf
isccp_diags=1    ! use =0 to save cpu time, but you lose some key diagnostics
nda5d=13         ! use =1 to get more accurate energy cons. diag (increases CPU time)
nda5s=13         ! use =1 to get more accurate energy cons. diag (increases CPU time)
ndaa=13
nda5k=13
nda4=48          ! to get daily energy history use nda4=24*3600/DTsrc

Nssw=2           ! until diurnal diags are fixed, Nssw has to be even
Ndisk=960
&&END_PARAMETERS

 &INPUTZ
 YEARI=1949,MONTHI=12,DATEI=1,HOURI=0, ! pick IYEAR1=YEARI (default) or < YEARI
 YEARE=1960,MONTHE=1,DATEE=2,HOURE=0,     KDIAG=12*0,9,
 ISTART=2,IRANDI=0, YEARE=1960,MONTHE=1,DATEE=2,HOURE=0,
!! suggested settings for E4qsF40:
!! YEARI=1901,MONTHI=1,DATEI=1,HOURI=0,
!! YEARE=1931,MONTHE=1,DATEE=1,HOURE=0,     KDIAG=12*0,9,
!! ISTART=8,IRANDI=0, YEARE=1901,MONTHE=1,DATEE=1,HOURE=1,
/
__EOF__
======================== FILE ./python/lib/modele/tests/rundeck1b.R
FILE: ./python/lib/modele/tests/rundeck1b.R
e4f40.R GISS Model E  1850 ocn/atm          larissa-modified        04/15/2010

!! E4F40 is for NIsurf=1 (U00a=0.72; U00b=1.68)

!! delete lines starting with '!!' unless E4F40 prepares a q-flux ocean run
!! E4qsF40.R GISS Model E  1850 atm, ocn: q-flux 65m             rar 07/15/2009

!! E4qsF40 = E4F40 with 65m q-flux ocean
e4f40 = modelE as frozen in April 2010:
modelE1 (3.0) 2x2.5 hor. grid with 40 lyrs, top at .1 mb (+ 3 rad.lyrs)
atmospheric composition from year 1850
ocean data: prescribed, 1876-1885 climatology
uses turbulence scheme (no dry conv), grav.wave drag
time steps: dynamics 3.75 min leap frog; physics 30 min.; radiation 2.5 hrs
filters: U,V in E-W and N-S direction (after every physics time step)
         U,V in E-W direction near poles (after every dynamics time step)
         sea level pressure (after every physics time step)

Preprocessor Options
#define USE_ENT                  ! include dynamic vegetation model
#define NO_HDIURN                ! exclude hdiurn diagnostics
#define SWFIX_20151201
#define MODIS_LAI
#define NEW_IO                   ! new I/O (netcdf) on
End Preprocessor Options

Object modules:
     ! resolution-specific source codes
Atm144x90                           ! horizontal resolution is 144x90 -> 2x2.5deg
AtmL40                              ! vertical resolution is 40 layers -> 0.1mb
DIAG_RES_F                          ! diagnostics
FFT144                              ! Fast Fourier Transform

IO_DRV                              ! new i/o

     ! GISS dynamics with gravity wave drag
ATMDYN MOMEN2ND                     ! atmospheric dynamics
QUS_DRV QUS3D                       ! advection of Q/tracers
STRATDYN STRAT_DIAG                 ! stratospheric dynamics (incl. gw drag)

    ! lat-lon grid specific source codes
AtmRes
GEOM_B                              ! model geometry
DIAG_ZONAL GCDIAGb                  ! grid-dependent code for lat-circle diags
DIAG_PRT POUT                       ! diagn/post-processing output
MODELE_DRV                          ! ModelE cap
MODELE                              ! initialization and main loop
ATM_COM                             ! main atmospheric variables
ATM_DRV                             ! driver for atmosphere-grid components
ATMDYN_COM                          ! atmospheric dynamics
ATM_UTILS                           ! utilities for some atmospheric quantities
QUS_COM QUSDEF                      ! T/Q moments, 1D QUS
SURFACE SURFACE_LANDICE FLUXES      ! surface calculation and fluxes
CLOUDS2 CLOUDS2_DRV CLOUDS_COM      ! clouds modules
GHY_COM GHY_DRV    ! + giss_LSM     ! land surface and soils + snow model
VEG_DRV                             ! vegetation
! VEG_COM VEGETATION                ! old vegetation
ENT_DRV  ENT_COM   ! + Ent          ! new vegetation
PBL_COM PBL_DRV PBL                 ! atmospheric pbl
ATURB                               ! turbulence in whole atmosphere
LAKES_COM LAKES                     ! lake modules
SEAICE SEAICE_DRV                   ! seaice modules
MODEL_COM                           ! calendar, timing variables
LANDICE LANDICE_COM LANDICE_DRV     ! land ice modules
ICEDYN_DRV ICEDYN                   ! ice dynamics modules
RAD_COM RAD_DRV RADIATION           ! radiation modules
RAD_UTILS ALBEDO READ_AERO ocalbedo ! radiation and albedo
DIAG_COM DIAG DEFACC                ! diagnostics
OCN_DRV                             ! driver for ocean-grid components
OCEAN OCNML                         ! ocean modules

Components:
dd2d
shared MPI_Support solvers giss_LSM 
Ent

Component Options:
OPTS_Ent = PS_MODEL=FBB ONLINE=YES PFT_MODEL=ENT 
OPTS_giss_LSM = USE_ENT=YES           
OPTS_dd2d = NC_IO=PNETCDF

Data input files:
    ! start from the restart file of an earlier run ...                 ISTART=8
! AIC=1....rsfE... ! initial conditions, no GIC needed, use
!! AIC=1JAN1961.rsfE4F40.MXL65m  ! end of run with KOCEAN=0

    ! start from observed conditions AIC(,OIC), model ground data GIC   ISTART=2
AIC=AIC.RES_F40.D771201.nc      ! observed init cond (atm. only)
!AIC=NCARIC.144x90.D7712010_ext.nc ! AIC for automatic relayering to model vertical grid
GIC=GIC.144X90.DEC01.1.ext_1.nc ! initial ground conditions
! prescr. climatological ocean (1 yr of data)
OSST=OST_144x90.1876-1885avg.HadISST1.1.nc
! prescr. climatological sea ice
SICE=SICE_144x90.1876-1885avg.HadISST1.1.nc
ZSIFAC=SICE_144x90.1876-1885avg.HadISST1.1.nc
!! q-flux ocean: use the next line instead,       set KOCEAN=1
!! OHT=OTSPEC.E4F40.MXL65m.1956-1960            ! ocean horizontal heat transports
!! OCNML is not used if KOCEAN=0, but needed in and to prepare for q-flux model
OCNML=Z1O.B144x90.nc                               ! mixed layer depth
TOPO=Z2HX2fromZ1QX1N-changed.nc

RVR=RD_Fb.nc             ! river direction file
NAMERVR=RD_Fb.names.txt  ! named river outlets

CDN=CD144X90.ext.nc
VEG=V144x90_EntMM16_lc_max_trimmed_scaled_nocrops.nc
LAIMAX=V144x90_EntMM16_lai_max_trimmed_scaled_ext1.nc
HITEent=V144x90_EntMM16_height_trimmed_scaled_ext1.nc
LAI=V144x90_EntMM16_lai_trimmed_scaled_ext1.nc
CROPS=CROPS_and_pastures_Pongratz_to_Hurtt_144X90N_nocasp.nc
SOIL=S144X900098M.ext.nc
TOP_INDEX=top_index_144x90_a.ij.ext.nc
ZVAR=ZVAR2X25A.nc             ! topographic variation for gwdrag
! probably need these (should convert to 144x90)
soil_textures=soil_textures_top30cm_2x2.5
SOILCARB_global=soilcarb_top30cm_2x2.5.nc
GLMELT=GLMELT_144X90_gas.OCN.nc
RADN1=sgpgxg.table8                           ! rad.tables and history files
RADN2=LWTables33k_lowH2O_CO2_O3_planck_1-800  ! rad.tables and history files
RADN4=LWCorrTables33k                         ! rad.tables and history files
RADN5=H2Ocont_MT_CKD  ! Mlawer/Tobin_Clough/Kneizys/Davies H2O continuum table
! other available H2O continuum tables:
!    RADN5=H2Ocont_Ma_2000
!    RADN5=H2Ocont_Ma_2004
!    RADN5=H2Ocont_Roberts
!    RADN5=H2Ocont_MT_CKD  ! Mlawer/Tobin_Clough/Kneizys/Davies
RADN3=miescatpar.abcdv2

RH_QG_Mie=oct2003.relhum.nr.Q633G633.table
RADN7=STRATAER.VOL.1850-2012.May13_hdr
RADN8=cloud.epsilon4.72x46
RADN9=solar.lean2015.ann1610-2014_hdr ! need KSOLAR=2
RADNE=topcld.trscat8

ISCCP=ISCCP.tautables
GHG=GHG_RCP45.txt ! use GHG.Jul2009.txt for runs that start before 1850
dH2O=dH2O_by_CH4_monthly
DUSTaer=dust_mass_CakmurMillerJGR06_144x90x20x7x12.nc
BC_dep=BC.Dry+Wet.depositions.ann_144x90.nc
! updated aerosols need MADAER=3
TAero_SUL=SUL_Koch2008_kg_m2_144x90x20_1890-2000h.nc
TAero_SSA=SSA_Koch2008_kg_m2_144x90x20h.nc
TAero_NIT=NIT_Bauer2008_kg_m2_144x90x20_1890-2000h.nc
TAero_OCA=OCA_Koch2008_kg_m2_144x90x20_1890-2000h.nc
TAero_BCA=BCA_Koch2008_kg_m2_144x90x20_1890-2000h.nc
TAero_BCB=BCB_Koch2008_kg_m2_144x90x20_1890-2000h.nc
O3file=o3_2010_shindell_144x90x49_1850-2000.nc

MSU_wts=MSU.RSS.weights.data      ! MSU-diag
REG=REG2X2.5                      ! special regions-diag

Label and Namelist:  (next 2 lines)
e4f40 (NIsurf=2; modelE as frozen in June 2009, 1850 atmosph. cond., Ent veget.,
with gravity wave drag, prescribed ocean)

&&PARAMETERS
! parameters set for choice of ocean model:
KOCEAN=0        ! ocean is prescribed
!! KOCEAN=1        ! ocean is computed
Kvflxo=0        ! usually set to 1 only during a prescr.ocn run by editing "I"
!  Kvflxo=1     ! saves VFLXO files to prepare for q-flux runs (mkOTSPEC)

variable_lk=1   ! variable lakes

! drag params if grav.wave drag is not used and top is at .01mb
X_SDRAG=.002,.0002  ! used above P(P)_sdrag mb (and in top layer)
C_SDRAG=.0002       ! constant SDRAG above PTOP=150mb
P_sdrag=1.          ! linear SDRAG only above 1mb (except near poles)
PP_sdrag=1.         ! linear SDRAG above PP_sdrag mb near poles
P_CSDRAG=1.         ! increase CSDRAG above P_CSDRAG to approach lin. drag
Wc_JDRAG=30.        ! crit.wind speed for J-drag (Judith/Jim)
ANG_sdrag=1     ! if 1: SDRAG conserves ang.momentum by adding loss below PTOP
! vsdragl is a tuning coefficient for SDRAG starting at LS1
! layer:   24    25    26    27   28    29    30    31   32   33     34   35   36  37  38   39 40
vsdragl=0.000,0.000,0.000,0.000,0.00,0.000,0.000,0.000,0.00,0.00,  0.00,0.00,0.00,0.3,0.6,0.83,1.

! Gravity wave parameters
PBREAK = 200.  ! The level for GW breaking above.
DEFTHRESH=0.000055 ! threshold (1/s) for triggering deformation waves
PCONPEN=400.   ! penetrating convection defn for GWDRAG
CMC = 0.0000002 ! parameter for GW Moist Convective drag
CSHEAR=10.     ! Shear drag coefficient
CMTN=0.1       ! default is 0.5
CDEF=1.6       ! tuning factor for deformation -> momentum flux
XCDNST=400.,10000.   ! strat. gw drag parameters
QGWMTN=1 ! mountain waves ON
QGWDEF=1 ! deformation waves ON
QGWSHR=0 ! shear drag OFF
QGWCNV=0 ! convective drag OFF


! cond_scheme=2   ! newer conductance scheme (N. Kiang) ! not used with Ent

! The following two lines are only used when aerosol/radiation interactions are off
FS8OPX=1.,1.,1.,1.,1.5,1.5,1.,1.
FT8OPX=1.,1.,1.,1.,1.,1.,1.,1.

! Increasing U00a decreases the high cloud cover; increasing U00b decreases net rad at TOA
U00a=0.72 ! above 850mb w/o MC region;  tune this first to get 30-35% high clouds
U00b=1.68 ! below 850mb and MC regions; tune this last  to get rad.balance
WMUI_multiplier = 1.
use_vmp=1
radius_multiplier=1.1

PTLISO=15.       ! press(mb) above which rad. assumes isothermal layers
H2ObyCH4=1.      ! activates strat.H2O generated by CH4
KSOLAR=2         ! 2: use long annual mean file ; 1: use short monthly file

! parameters that control the atmospheric/boundary conditions
! if set to 0, the current (day/) year is used: transient run
master_yr=1850
!crops_yr=1850  ! if -1, crops in VEG-file is used
!s0_yr=1850
!s0_day=182
!ghg_yr=1850
!ghg_day=182
volc_yr=-1
!volc_day=182
!aero_yr=1850
od_cdncx=0.        ! don't include 1st indirect effect
cc_cdncx=0.        ! don't include 2nd indirect effect (used 0.0036)
!albsn_yr=1850
dalbsnX=.024
!o3_yr=-1850
!aer_int_yr=1850    !select desired aerosol emissions year or 0 to use JYEAR
! atmCO2=368.6          !uatm for year 2000 - enable for CO2 tracer runs

!variable_orb_par=0
!orb_par_year_bp=100  !  BP i.e. 1950-orb_par_year_bp AD = 1850 AD
madaer=3         ! 3: updated aerosols          ; 1: default sulfates/aerosols

DTsrc=1800.      ! cannot be changed after a run has been started
DT=225.
! parameters that control the Shapiro filter
DT_XUfilter=225. ! Shapiro filter on U in E-W direction; usually same as DT
DT_XVfilter=225. ! Shapiro filter on V in E-W direction; usually same as DT
DT_YVfilter=0.   ! Shapiro filter on V in N-S direction
DT_YUfilter=0.   ! Shapiro filter on U in N-S direction

NIsurf=2         ! (surf.interaction NIsurf times per physics time step)
NRAD=544           ! radiation (every NRAD'th physics time step)
! parameters that affect at most diagn. output:  standard if DTsrc=1800. (sec)
aer_rad_forc=0   ! if set =1, radiation is called numerous times - slow !!
cloud_rad_forc=1 ! calls radiation twice; use =0 to save cpu time
SUBDD=' '        ! no sub-daily frequency diags
NSUBDD=0         ! saving sub-daily diags every NSUBDD-th physics time step (1/2 hr)
KCOPY=2          ! saving acc + rsf
isccp_diags=1    ! use =0 to save cpu time, but you lose some key diagnostics
nda5d=13         ! use =1 to get more accurate energy cons. diag (increases CPU time)
nda5s=13         ! use =1 to get more accurate energy cons. diag (increases CPU time)
ndaa=13
nda5k=13
nda4=48          ! to get daily energy history use nda4=24*3600/DTsrc

Nssw=2           ! until diurnal diags are fixed, Nssw has to be even
Ndisk=960
&&END_PARAMETERS

 &INPUTZ
 YEARI=1955,MONTHI=12,DATEI=1,HOURI=0, ! pick IYEAR1=YEARI (default) or < YEARI
 YEARE=1960,MONTHE=1,DATEE=2,HOURE=0,     KDIAG=12*0,9,
 ISTART=2,IRANDI=0, YEARE=1960,MONTHE=1,DATEE=2,HOURE=0,
!! suggested settings for E4qsF40:
!! YEARI=1901,MONTHI=1,DATEI=1,HOURI=0,
!! YEARE=1931,MONTHE=1,DATEE=1,HOURE=0,     KDIAG=12*0,9,
!! ISTART=8,IRANDI=0, YEARE=1901,MONTHE=1,DATEE=1,HOURE=1,
/
__EOF__
======================== FILE ./python/lib/modele/tests/rundeck2.R
FILE: ./python/lib/modele/tests/rundeck2.R
e4f40.R GISS Model E  1850 ocn/atm          larissa        04/15/2010

!! E4F40 is for NIsurf=1 (U00a=0.72; U00b=1.68)

!! delete lines starting with '!!' unless E4F40 prepares a q-flux ocean run
!! E4qsF40.R GISS Model E  1850 atm, ocn: q-flux 65m             rar 07/15/2009

!! E4qsF40 = E4F40 with 65m q-flux ocean
e4f40 = modelE as frozen in April 2010:
modelE1 (3.0) 2x2.5 hor. grid with 40 lyrs, top at .1 mb (+ 3 rad.lyrs)
atmospheric composition from year 1850
ocean data: prescribed, 1876-1885 climatology
uses turbulence scheme (no dry conv), grav.wave drag
time steps: dynamics 3.75 min leap frog; physics 30 min.; radiation 2.5 hrs
filters: U,V in E-W and N-S direction (after every physics time step)
         U,V in E-W direction near poles (after every dynamics time step)
         sea level pressure (after every physics time step)

Preprocessor Options
#define NEW_IO                   ! new I/O (netcdf) on
#define USE_ENT                  ! include dynamic vegetation model
#define SWFIX_20151201
#define NO_HDIURN                ! exclude hdiurn diagnostics
#define MODIS_LAI
End Preprocessor Options

Object modules:
     ! resolution-specific source codes
Atm144x90                           ! horizontal resolution is 144x90 -> 2x2.5deg
AtmL40                              ! vertical resolution is 40 layers -> 0.1mb
DIAG_RES_F                          ! diagnostics
FFT144                              ! Fast Fourier Transform

IO_DRV                              ! new i/o

     ! GISS dynamics with gravity wave drag
ATMDYN MOMEN2ND                     ! atmospheric dynamics
QUS_DRV QUS3D                       ! advection of Q/tracers
STRATDYN STRAT_DIAG                 ! stratospheric dynamics (incl. gw drag)

    ! lat-lon grid specific source codes
AtmRes
GEOM_B                              ! model geometry
DIAG_ZONAL GCDIAGb                  ! grid-dependent code for lat-circle diags
DIAG_PRT POUT                       ! diagn/post-processing output
MODEL_COM                           ! calendar, timing variables
MODELE_DRV                          ! ModelE cap
MODELE                              ! initialization and main loop
ATM_COM                             ! main atmospheric variables
ATM_DRV                             ! driver for atmosphere-grid components
ATMDYN_COM                          ! atmospheric dynamics
ATM_UTILS                           ! utilities for some atmospheric quantities
QUS_COM QUSDEF                      ! T/Q moments, 1D QUS
CLOUDS2 CLOUDS2_DRV CLOUDS_COM      ! clouds modules
SURFACE SURFACE_LANDICE FLUXES      ! surface calculation and fluxes
GHY_COM GHY_DRV    ! + giss_LSM     ! land surface and soils + snow model
VEG_DRV                             ! vegetation
! VEG_COM VEGETATION                ! old vegetation
ENT_DRV  ENT_COM   ! + Ent          ! new vegetation
PBL_COM PBL_DRV PBL                 ! atmospheric pbl
ATURB                               ! turbulence in whole atmosphere
LAKES_COM LAKES                     ! lake modules
SEAICE SEAICE_DRV                   ! seaice modules
LANDICE LANDICE_IO LANDICE_COM LANDICE_DRV     ! land ice modules
ICEDYN_DRV ICEDYN                   ! ice dynamics modules
RAD_COM RAD_DRV RADIATION           ! radiation modules
RAD_UTILS ALBEDO READ_AERO ocalbedo ! radiation and albedo
DIAG_COM DIAG DEFACC                ! diagnostics
OCN_DRV                             ! driver for ocean-grid components
OCEAN OCNML                         ! ocean modules

Components:
shared MPI_Support solvers giss_LSM 
dd2d
Ent

Component Options:
OPTS_Ent = ONLINE=YES PS_MODEL=FBB PFT_MODEL=ENT 
OPTS_giss_LSM = USE_ENT=YES           
OPTS_dd2d = NC_IO=PNETCDF

Data input files:
    ! start from the restart file of an earlier run ...                 ISTART=8
! AIC=1....rsfE... ! initial conditions, no GIC needed, use
!! AIC=1JAN1961.rsfE4F40.MXL65m  ! end of run with KOCEAN=0

    ! start from observed conditions AIC(,OIC), model ground data GIC   ISTART=2
AIC=AIC.RES_F40.D771201.nc      ! observed init cond (atm. only)
!AIC=NCARIC.144x90.D7712010_ext.nc ! AIC for automatic relayering to model vertical grid
GIC=GIC.144X90.DEC01.1.ext_1.nc ! initial ground conditions
! prescr. climatological ocean (1 yr of data)
OSST=OST_144x90.1876-1885avg.HadISST1.1.nc
! prescr. climatological sea ice
SICE=SICE_144x90.1876-1885avg.HadISST1.1.nc
ZSIFAC=SICE_144x90.1876-1885avg.HadISST1.1.nc
!! q-flux ocean: use the next line instead,       set KOCEAN=1
!! OHT=OTSPEC.E4F40.MXL65m.1956-1960            ! ocean horizontal heat transports
!! OCNML is not used if KOCEAN=0, but needed in and to prepare for q-flux model
OCNML=Z1O.B144x90.nc                               ! mixed layer depth
TOPO=Z2HX2fromZ1QX1N.nc

RVR=RD_Fb.nc             ! river direction file
NAMERVR=RD_Fb.names.txt  ! named river outlets

CDN=CD144X90.ext.nc
VEG=V144x90_EntMM16_lc_max_trimmed_scaled_nocrops.nc
LAIMAX=V144x90_EntMM16_lai_max_trimmed_scaled_ext1.nc
HITEent=V144x90_EntMM16_height_trimmed_scaled_ext1.nc
LAI=V144x90_EntMM16_lai_trimmed_scaled_ext1.nc
CROPS=CROPS_and_pastures_Pongratz_to_Hurtt_144X90N_nocasp.nc
SOIL=S144X900098M.ext.nc
TOP_INDEX=top_index_144x90_a.ij.ext.nc
ZVAR=ZVAR2X25A.nc             ! topographic variation for gwdrag
! probably need these (should convert to 144x90)
soil_textures=soil_textures_top30cm_2x2.5
SOILCARB_global=soilcarb_top30cm_2x2.5.nc
GLMELT=GLMELT_144X90_gas.OCN.nc
RADN1=sgpgxg.table8                           ! rad.tables and history files
RADN2=LWTables33k_lowH2O_CO2_O3_planck_1-800  ! rad.tables and history files
RADN4=LWCorrTables33k                         ! rad.tables and history files
RADN5=H2Ocont_MT_CKD  ! Mlawer/Tobin_Clough/Kneizys/Davies H2O continuum table
! other available H2O continuum tables:
!    RADN5=H2Ocont_Ma_2000
!    RADN5=H2Ocont_Ma_2004
!    RADN5=H2Ocont_Roberts
!    RADN5=H2Ocont_MT_CKD  ! Mlawer/Tobin_Clough/Kneizys/Davies
RADN3=miescatpar.abcdv2

RH_QG_Mie=oct2003.relhum.nr.Q633G633.table
RADN7=STRATAER.VOL.1850-2012.May13_hdr
RADN8=cloud.epsilon4.72x46
RADN9=solar.lean2015.ann1610-2014_hdr ! need KSOLAR=2
RADNE=topcld.trscat8

ISCCP=ISCCP.tautables
GHG=GHG_RCP45.txt ! use GHG.Jul2009.txt for runs that start before 1850
dH2O=dH2O_by_CH4_monthly
DUSTaer=dust_mass_CakmurMillerJGR06_144x90x20x7x12.nc
BC_dep=BC.Dry+Wet.depositions.ann_144x90.nc
! updated aerosols need MADAER=3
TAero_SUL=SUL_Koch2008_kg_m2_144x90x20_1890-2000h.nc
TAero_SSA=SSA_Koch2008_kg_m2_144x90x20h.nc
TAero_NIT=NIT_Bauer2008_kg_m2_144x90x20_1890-2000h.nc
TAero_OCA=OCA_Koch2008_kg_m2_144x90x20_1890-2000h.nc
TAero_BCA=BCA_Koch2008_kg_m2_144x90x20_1890-2000h.nc
TAero_BCB=BCB_Koch2008_kg_m2_144x90x20_1890-2000h.nc
O3file=o3_2010_shindell_144x90x49_1850-2000.nc

MSU_wts=MSU.RSS.weights.data      ! MSU-diag
REG=REG2X2.5                      ! special regions-diag

Label and Namelist:  (next 2 lines)
e4f40 (NIsurf=2; modelE as frozen in June 2009, 1850 atmosph. cond., Ent veget.,
with gravity wave drag, prescribed ocean)

&&PARAMETERS
! parameters set for choice of ocean model:
KOCEAN=0        ! ocean is prescribed
!! KOCEAN=1        ! ocean is computed
Kvflxo=0        ! usually set to 1 only during a prescr.ocn run by editing "I"
!  Kvflxo=1     ! saves VFLXO files to prepare for q-flux runs (mkOTSPEC)

variable_lk=1   ! variable lakes

! drag params if grav.wave drag is not used and top is at .01mb
X_SDRAG=.002,.0002  ! used above P(P)_sdrag mb (and in top layer)
C_SDRAG=.0002       ! constant SDRAG above PTOP=150mb
P_sdrag=1.          ! linear SDRAG only above 1mb (except near poles)
PP_sdrag=1.         ! linear SDRAG above PP_sdrag mb near poles
P_CSDRAG=1.         ! increase CSDRAG above P_CSDRAG to approach lin. drag
Wc_JDRAG=30.        ! crit.wind speed for J-drag (Judith/Jim)
ANG_sdrag=1     ! if 1: SDRAG conserves ang.momentum by adding loss below PTOP
! vsdragl is a tuning coefficient for SDRAG starting at LS1
! layer:   24    25    26    27   28    29    30    31   32   33     34   35   36  37  38   39 40
vsdragl=0.000,0.000,0.000,0.000,0.00,0.000,0.000,0.000,0.00,0.00,  0.00,0.00,0.00,0.3,0.6,0.83,1.

! Gravity wave parameters
PBREAK = 200.  ! The level for GW breaking above.
DEFTHRESH=0.000055 ! threshold (1/s) for triggering deformation waves
PCONPEN=400.   ! penetrating convection defn for GWDRAG
CMC = 0.0000002 ! parameter for GW Moist Convective drag
CSHEAR=10.     ! Shear drag coefficient
CMTN=0.1       ! default is 0.5
CDEF=1.6       ! tuning factor for deformation -> momentum flux
XCDNST=400.,10000.   ! strat. gw drag parameters
QGWMTN=1 ! mountain waves ON
QGWDEF=1 ! deformation waves ON
QGWSHR=0 ! shear drag OFF
QGWCNV=0 ! convective drag OFF


! cond_scheme=2   ! newer conductance scheme (N. Kiang) ! not used with Ent

! The following two lines are only used when aerosol/radiation interactions are off
FS8OPX=1.,1.,1.,1.,1.5,1.5,1.,1.
FT8OPX=1.,1.,1.,1.,1.,1.,1.,1.

! Increasing U00a decreases the high cloud cover; increasing U00b decreases net rad at TOA
U00a=0.72 ! above 850mb w/o MC region;  tune this first to get 30-35% high clouds
U00b=1.68 ! below 850mb and MC regions; tune this last  to get rad.balance
WMUI_multiplier = 1.
use_vmp=1
radius_multiplier=1.1

PTLISO=15.       ! press(mb) above which rad. assumes isothermal layers
H2ObyCH4=1.      ! activates strat.H2O generated by CH4
KSOLAR=2         ! 2: use long annual mean file ; 1: use short monthly file

! parameters that control the atmospheric/boundary conditions
! if set to 0, the current (day/) year is used: transient run
master_yr=1850
!crops_yr=1850  ! if -1, crops in VEG-file is used
!s0_yr=1850
!s0_day=182
!ghg_yr=1850
!ghg_day=182
volc_yr=-1
!volc_day=182
!aero_yr=1850
od_cdncx=0.        ! don't include 1st indirect effect
cc_cdncx=0.        ! don't include 2nd indirect effect (used 0.0036)
!albsn_yr=1850
dalbsnX=.024
!o3_yr=-1850
!aer_int_yr=1850    !select desired aerosol emissions year or 0 to use JYEAR
! atmCO2=368.6          !uatm for year 2000 - enable for CO2 tracer runs

!variable_orb_par=0
!orb_par_year_bp=100  !  BP i.e. 1950-orb_par_year_bp AD = 1850 AD
madaer=3         ! 3: updated aerosols          ; 1: default sulfates/aerosols

DTsrc=1800.      ! cannot be changed after a run has been started
DT=225.
! parameters that control the Shapiro filter
DT_XUfilter=225. ! Shapiro filter on U in E-W direction; usually same as DT
DT_XVfilter=225. ! Shapiro filter on V in E-W direction; usually same as DT
DT_YVfilter=0.   ! Shapiro filter on V in N-S direction
DT_YUfilter=0.   ! Shapiro filter on U in N-S direction

NIsurf=2         ! (surf.interaction NIsurf times per physics time step)
NRAD=5           ! radiation (every NRAD'th physics time step)
! parameters that affect at most diagn. output:  standard if DTsrc=1800. (sec)
aer_rad_forc=0   ! if set =1, radiation is called numerous times - slow !!
cloud_rad_forc=1 ! calls radiation twice; use =0 to save cpu time
SUBDD=' '        ! no sub-daily frequency diags
NSUBDD=0         ! saving sub-daily diags every NSUBDD-th physics time step (1/2 hr)
KCOPY=2          ! saving acc + rsf
isccp_diags=1    ! use =0 to save cpu time, but you lose some key diagnostics
nda5d=13         ! use =1 to get more accurate energy cons. diag (increases CPU time)
nda5s=13         ! use =1 to get more accurate energy cons. diag (increases CPU time)
ndaa=13
nda5k=13
nda4=48          ! to get daily energy history use nda4=24*3600/DTsrc

Nssw=2           ! until diurnal diags are fixed, Nssw has to be even
Ndisk=960
&&END_PARAMETERS

 &INPUTZ
 YEARI=1949,MONTHI=12,DATEI=1,HOURI=0, ! pick IYEAR1=YEARI (default) or < YEARI
 YEARE=1960,MONTHE=1,DATEE=2,HOURE=0,     KDIAG=12*0,9,
 ISTART=2,IRANDI=0, YEARE=1960,MONTHE=1,DATEE=2,HOURE=0,
!! suggested settings for E4qsF40:
!! YEARI=1901,MONTHI=1,DATEI=1,HOURI=0,
!! YEARE=1931,MONTHE=1,DATEE=1,HOURE=0,     KDIAG=12*0,9,
!! ISTART=8,IRANDI=0, YEARE=1901,MONTHE=1,DATEE=1,HOURE=1,
/
__EOF__
======================== FILE ./python/lib/modele/tests/test_hash.py
FILE: ./python/lib/modele/tests/test_hash.py
from modele import xhash,rundeck
import hashlib
import unittest
import os

srcdir = os.path.dirname(os.path.abspath(__file__))

class TestHash(unittest.TestCase):

    def test_simple_hash(self):
        """Just tests that the hash algorithm runs"""
        hash = hashlib.md5()
        xhash.update({'a' : 5, 'b' : 4}, hash)
        xhash.update(17, hash)
        xhash.update(('foo', 'bar'), hash)

    def test_hash_rundeck(self):
        hash1a = xhash.hexdigest(rundeck.load_rundeck(os.path.join(srcdir, 'rundeck1a.R')))
        hash1b = xhash.hexdigest(rundeck.load_rundeck(os.path.join(srcdir, 'rundeck1b.R')))
        hash2 = xhash.hexdigest(rundeck.load_rundeck(os.path.join(srcdir, 'rundeck2.R')))

        self.assertEqual(hash1a, hash1b)
        self.assertNotEqual(hash1a, hash2)


if __name__ == "__main__":
    unittest.main()
__EOF__
======================== FILE ./python/lib/modele/xhash.py
FILE: ./python/lib/modele/xhash.py
import hashlib
import pickle
import types

def _update_int(myint, hash):
    hash.update(str(myint).encode())

def _update_str(mystr, hash):
    hash.update(mystr.encode())

def _update_bytes(mybytestr, hash):
    hash.update(mybytestr)

def _update_iterable(items, hash):
    for item in items:
        update(item, hash)

def _update_dict(mydict, hash):
    items = sorted(mydict.items())
    _update_iterable(items, hash)

def _update_set(myset, hash):
    _update_iterable(sorted(myset), hash)

def _update_module(mymodule, hash):
    hash.update(mymodule.__name__.encode())

def _update_function(myfunction, hash):
    hash.update(myfunction.__module__.encode())
    hash.update(myfunction.__name__.encode())


update_by_type = { \
    int : _update_int,
    str : _update_str,
    bytes : _update_bytes,
    list : _update_iterable,
    tuple : _update_iterable,
    dict : _update_dict,
    set : _update_set,
    types.ModuleType : _update_module,
    types.FunctionType : _update_function,
}


def update(obj, hash):
    typ = type(obj)
    hash.update(typ.__module__.encode())
    hash.update(typ.__name__.encode())

    try:
        updater = update_by_type[typ]
        updater(obj,hash)
    except KeyError:
        try:
            obj.update_hash(hash)
        except AttributeError:
            # Try different collection update methods
            if isinstance(obj, dict):
                _update_dict(obj, hash)
            elif isinstance(obj, set):
                _update_set(obj, hash)

def hexdigest(obj, hash_type='md5'):
    hash = getattr(hashlib, hash_type)()
    update(obj, hash)
    return hash.hexdigest()
__EOF__
======================== FILE ./tests/CMakeLists.txt
FILE: ./tests/CMakeLists.txt
# modelE unit tests

set (SOURCE_DIR 
   ${CMAKE_SOURCE_DIR}/model
)

# Unfortunately COMPILER is defined differently in modelE (gfortran)
# than in PFUNIT (GNU). So, we rename here to inherit the correct PFUNIT
# configuration.
if (${COMPILER} MATCHES gfortran)
   set(COMPILER GNU)
endif()
# NAG note: PFUNIT must be compiled with -kind=byte
if (${COMPILER} MATCHES gfortran)
   set(F90FLAGS "${F90FLAGS} -kind=byte")
endif()

list(APPEND TESTDIRS shared)
list(APPEND TESTDIRS profiler)
if (${USE_TRACERS} MATCHES YES)
   list(APPEND TESTDIRS tracers)
endif()
if (MPI MATCHES YES)
   list(APPEND TESTDIRS MPI_Support)
   
endif()

foreach(dir ${TESTDIRS})
   list(APPEND TESTLIBS ${dir}_tests)
   list(APPEND MODELLIBS ${dir})
   list(APPEND INCDIRS ${CMAKE_SOURCE_DIR}/tests/${dir})
   add_subdirectory(${dir})
endforeach()

include_directories(${INCDIRS})

# TARGETS

set(TEST_EXE tests.x)
add_executable(${TEST_EXE} $ENV{PFUNIT}/include/driver.F90 testSuites.inc)
target_link_libraries(${TEST_EXE}
   ${TESTLIBS}
   ${MODELLIBS}
   netcdf
   pfunit
)

if (MPI MATCHES YES)
   target_link_libraries(${TEST_EXE} pnetcdf ${MPI_Fortran_LIBRARIES})
   add_custom_target(tests
      COMMAND mpirun -np 12 ${TEST_EXE}
      DEPENDS ${TEST_EXE}
      WORKING_DIRECTORY ${CMAKE_CURRENT_BINARY_DIR}
      COMMENT "MPI run ${TEST_EXE}"
   )
else()
   add_custom_target(tests
      COMMAND ${TEST_EXE}
      DEPENDS ${TEST_EXE}
      WORKING_DIRECTORY ${CMAKE_CURRENT_BINARY_DIR}
      COMMENT "run ${TEST_EXE}"
   )
endif()

__EOF__
======================== FILE ./tests/MPI_Support/CMakeLists.txt
FILE: ./tests/MPI_Support/CMakeLists.txt
# modelE unit tests for MPI_Support component

get_filename_component(DIRNAME "${CMAKE_CURRENT_SOURCE_DIR}" NAME)
set(THIS ${DIRNAME}_tests)

# Pre-process pf files - output is in build directory
file(GLOB pfiles "*.pf")
foreach(file ${pfiles})
   get_filename_component(basename ${file} NAME_WE)
   add_custom_command (
      OUTPUT ${CMAKE_CURRENT_BINARY_DIR}/${basename}.F90
      COMMAND python2
      ARGS $ENV{PFUNIT}/bin/pFUnitParser.py ${file} 
      ${CMAKE_CURRENT_BINARY_DIR}/${basename}.F90
      DEPENDS ${file}
   )
endforeach()

set (SOURCES
   Test_DistGrid.F90
   Test_GatherScatter.F90
   Test_GlobalSum.F90
   Test_Halo.F90
)

set_source_files_properties(
   ${SOURCES}
   PROPERTIES COMPILE_FLAGS
   "${F90FLAGS}"
   GENERATED TRUE
)

include_directories(
   ${CMAKE_BINARY_DIR}/model/shared
   ${CMAKE_BINARY_DIR}/model/MPI_Support
   $ENV{PFUNIT}/include
   $ENV{PFUNIT}/mod
)

# Targets

add_library(${THIS} ${SOURCES})
target_link_libraries(${THIS} shared MPI_Support)


__EOF__
======================== FILE ./tests/profiler/CMakeLists.txt
FILE: ./tests/profiler/CMakeLists.txt
# modelE unit tests for profiler component

get_filename_component(DIRNAME "${CMAKE_CURRENT_SOURCE_DIR}" NAME)
set(THIS ${DIRNAME}_tests)

# Pre-process pf files - output is in build directory
file(GLOB pfiles "*.pf")
foreach(file ${pfiles})
   get_filename_component(basename ${file} NAME_WE)
   add_custom_command (
      OUTPUT ${CMAKE_CURRENT_BINARY_DIR}/${basename}.F90
      COMMAND python2
      ARGS $ENV{PFUNIT}/bin/pFUnitParser.py ${file} 
      ${CMAKE_CURRENT_BINARY_DIR}/${basename}.F90
      DEPENDS ${file}
   )
endforeach()

set (SOURCES
   Test_ProfileReport.F90
   Test_ReportColumn.F90
   Test_TimeFormatUtilities.F90
   Test_Timer.F90
   Test_TimerList.F90
)

if (MPI MATCHES YES)
   set (SOURCES
      ${SOURCES}
      Test_TimerParallel.F90
   )
endif()

set_source_files_properties(
   ${SOURCES}
   PROPERTIES COMPILE_FLAGS
   "${F90FLAGS}"
   GENERATED TRUE
)

include_directories(
   ${CMAKE_BINARY_DIR}/model/shared
   ${CMAKE_BINARY_DIR}/model/profiler
   $ENV{PFUNIT}/include
   $ENV{PFUNIT}/mod
)

# Targets
add_library(${THIS} ${SOURCES})
target_link_libraries(${THIS} shared profiler)


__EOF__
======================== FILE ./tests/shared/CMakeLists.txt
FILE: ./tests/shared/CMakeLists.txt
# modelE unit tests for shared component

get_filename_component(DIRNAME "${CMAKE_CURRENT_SOURCE_DIR}" NAME)
set(THIS ${DIRNAME}_tests)

# Pre-process pf files - output is in build directory
file(GLOB pfiles "*.pf")
foreach(file ${pfiles})
   get_filename_component(basename ${file} NAME_WE)
   add_custom_command (
      OUTPUT ${CMAKE_CURRENT_BINARY_DIR}/${basename}.F90
      COMMAND python2
      ARGS $ENV{PFUNIT}/bin/pFUnitParser.py ${file}  
      ${CMAKE_CURRENT_BINARY_DIR}/${basename}.F90
      DEPENDS ${file}
   )
endforeach()

# Preprocess Foo modules
add_custom_command(
   OUTPUT ${CMAKE_CURRENT_BINARY_DIR}/FooHashMap.F90
   COMMAND ${CPP}
   ARGS -E -P -I${CMAKE_SOURCE_DIR}/model/include -I${CMAKE_SOURCE_DIR}/model/shared
   ${CMAKE_CURRENT_SOURCE_DIR}/FooHashMap.F90 >
   ${CMAKE_CURRENT_BINARY_DIR}/FooHashMap.F90
   DEPENDS ${CMAKE_CURRENT_SOURCE_DIR}/FooHashMap.F90
   OUTPUT ${CMAKE_CURRENT_BINARY_DIR}/FooAssociativeArray.F90
   COMMAND ${CPP}
   ARGS -E -P -I${CMAKE_SOURCE_DIR}/model/include -I${CMAKE_SOURCE_DIR}/model/shared
   ${CMAKE_CURRENT_SOURCE_DIR}/FooAssociativeArray.F90 >
   ${CMAKE_CURRENT_BINARY_DIR}/FooAssociativeArray.F90
   DEPENDS ${CMAKE_CURRENT_SOURCE_DIR}/FooAssociativeArray.F90 
)

set (SOURCES
   ${CMAKE_CURRENT_BINARY_DIR}/FooAssociativeArray.F90 
   ${CMAKE_CURRENT_BINARY_DIR}/FooHashMap.F90
)

set (PFSOURCES
   Test_AssociativeArray.F90
   Test_AssociativeArrayIterator.F90
   Test_AttributeAssociativeArray.F90
   Test_AttributeDictionary.F90
   Test_BaseTime.F90
   Test_CalendarDateHashMap.F90
   Test_Dictionary.F90
   Test_GenericType.F90
   Test_Geometry.F90
   Test_HashMap.F90
   Test_HashMapIterator.F90
   Test_JulianCalendar.F90
   Test_KeyValuePair.F90
   Test_OrbitUtilities.F90
   Test_Parser.F90
   Test_Random.F90
   Test_Rational.F90
   Test_StringUtilities.F90
   Test_Time.F90
)

set(ALLSOURCES
   ${PFSOURCES}
   ${SOURCES}
)
set_source_files_properties(
   ${SOURCES}
   PROPERTIES COMPILE_FLAGS
   "${F90FLAGS}"
)

set_source_files_properties(
   ${PFSOURCES}
   PROPERTIES COMPILE_FLAGS
   "${F90FLAGS}"
   GENERATED TRUE
)

include_directories(
   ${CMAKE_BINARY_DIR}/model
   ${CMAKE_BINARY_DIR}/model/shared
   ${CMAKE_SOURCE_DIR}/model/include
   $ENV{PFUNIT}/include
   $ENV{PFUNIT}/mod
)

# Targets
add_library(${THIS} ${ALLSOURCES})
target_link_libraries(${THIS} shared)



__EOF__
======================== FILE ./tests/tracers/CMakeLists.txt
FILE: ./tests/tracers/CMakeLists.txt
# modelE unit tests for tracers component

get_filename_component(DIRNAME "${CMAKE_CURRENT_SOURCE_DIR}" NAME)
set(THIS ${DIRNAME}_tests)

# Pre-process pf files - output is in build directory
file(GLOB pfiles "*.pf")
foreach(file ${pfiles})
   get_filename_component(basename ${file} NAME_WE)
   add_custom_command (
      OUTPUT ${CMAKE_CURRENT_BINARY_DIR}/${basename}.F90
      COMMAND python2
      ARGS $ENV{PFUNIT}/bin/pFUnitParser.py ${file} 
      ${CMAKE_CURRENT_BINARY_DIR}/${basename}.F90
      DEPENDS ${file}
   )
endforeach()

set (SOURCES
   Test_Tracer.F90
   Test_TracerBundle.F90
   Test_TracerIO.F90
   Test_TracerSurfaceSource.F90
)

set_source_files_properties(
   ${SOURCES}
   PROPERTIES COMPILE_FLAGS
   "${F90FLAGS}"
   GENERATED TRUE
)

include_directories(
   ${CMAKE_BINARY_DIR}/model/shared
   ${CMAKE_BINARY_DIR}/model/tracers
   $ENV{PFUNIT}/include
   $ENV{PFUNIT}/mod
)

# Targets

add_library(${THIS} ${SOURCES})
target_link_libraries(${THIS} shared tracers)

__EOF__
